{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 - Measuring Meaning & Sampling\n",
    "This week, we begin by \"begging, borrowing and stealing\" text from several\n",
    "contexts of human communication (e.g., PDFs, HTML, Word) and preparing it for\n",
    "machines to \"read\" and analyze so that we can begin to build our sample. This notebook outlines scraping text from the web, PDF and Word documents. Then we detail \"spidering\" or walking\n",
    "through hyperlinks to build samples of online content, and using APIs,\n",
    "Application Programming Interfaces, provided by webservices to access their\n",
    "content. Along the way, we will use regular expressions, outlined in the\n",
    "reading, to remove unwanted formatting and ornamentation. Next, we discuss\n",
    "various text encodings, filtering and data structures in which text can be\n",
    "placed for analysis. Finally, we ask you to begin building a corpus for preliminary analysis and articulate what your sample represents in context of your final project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made a python package just for this course: lucem_illud. If you haven't installed this package, you should run the following code first. You don't need to install the package later; all you need to do is just to import the package with: import lucem_illud. For your final projects, you may find it useful to [read the lucem_illud source code](https://github.com/UChicago-Computational-Content-Analysis/lucem_illud/tree/main/lucem_illud) and modify your code for your own interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
      "  Cloning git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git to /private/var/folders/5k/y_c_3dn11vz1l1xv724bslpc0000gn/T/pip-req-build-y65xuqc1\n",
      "  Running command git clone -q git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git /private/var/folders/5k/y_c_3dn11vz1l1xv724bslpc0000gn/T/pip-req-build-y65xuqc1\n",
      "Requirement already satisfied (use --upgrade to upgrade): lucem-illud==8.0.1 from git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git in /Users/nyjiang/.local/lib/python3.8/site-packages\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (1.22.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (2.24.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (1.0.5)\n",
      "Requirement already satisfied: python-docx in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (0.8.11)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (7.2.0)\n",
      "Requirement already satisfied: pdfminer2 in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (20151206)\n",
      "Requirement already satisfied: GitPython in /Users/nyjiang/.local/lib/python3.8/site-packages (from lucem-illud==8.0.1) (3.1.26)\n",
      "Requirement already satisfied: wordcloud in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (1.8.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (1.5.0)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (0.10.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (0.23.1)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (3.5)\n",
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (4.1.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (3.2.2)\n",
      "Requirement already satisfied: pyanno3 in /Users/nyjiang/.local/lib/python3.8/site-packages (from lucem-illud==8.0.1) (2.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (4.9.1)\n",
      "Requirement already satisfied: graphviz in /Users/nyjiang/.local/lib/python3.8/site-packages (from lucem-illud==8.0.1) (0.19.1)\n",
      "Requirement already satisfied: boto3 in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (1.20.5)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (2.4)\n",
      "Requirement already satisfied: pydub in /Users/nyjiang/.local/lib/python3.8/site-packages (from lucem-illud==8.0.1) (0.25.1)\n",
      "Requirement already satisfied: speechrecognition in /Users/nyjiang/.local/lib/python3.8/site-packages (from lucem-illud==8.0.1) (3.8.1)\n",
      "Requirement already satisfied: pysoundfile in /Users/nyjiang/.local/lib/python3.8/site-packages (from lucem-illud==8.0.1) (0.9.0.post1)\n",
      "Requirement already satisfied: scikit-image in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (0.16.2)\n",
      "Requirement already satisfied: IPython in /opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (7.16.1)\n",
      "Requirement already satisfied: spacy in /Users/nyjiang/.local/lib/python3.8/site-packages (from lucem-illud==8.0.1) (3.2.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->lucem-illud==8.0.1) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->lucem-illud==8.0.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->lucem-illud==8.0.1) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->lucem-illud==8.0.1) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->lucem-illud==8.0.1) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->lucem-illud==8.0.1) (2.8.1)\n",
      "Requirement already satisfied: lxml>=2.3.2 in /opt/anaconda3/lib/python3.8/site-packages (from python-docx->lucem-illud==8.0.1) (4.5.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from pdfminer2->lucem-illud==8.0.1) (1.15.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/nyjiang/.local/lib/python3.8/site-packages (from GitPython->lucem-illud==8.0.1) (4.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->lucem-illud==8.0.1) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->lucem-illud==8.0.1) (0.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from nltk->lucem-illud==8.0.1) (4.47.0)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.8/site-packages (from nltk->lucem-illud==8.0.1) (2020.6.8)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from nltk->lucem-illud==8.0.1) (7.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.8/site-packages (from gensim->lucem-illud==8.0.1) (5.2.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lucem-illud==8.0.1) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lucem-illud==8.0.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lucem-illud==8.0.1) (1.2.0)\n",
      "Requirement already satisfied: traits in /Users/nyjiang/.local/lib/python3.8/site-packages (from pyanno3->lucem-illud==8.0.1) (6.3.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->lucem-illud==8.0.1) (2.0.1)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/anaconda3/lib/python3.8/site-packages (from boto3->lucem-illud==8.0.1) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/anaconda3/lib/python3.8/site-packages (from boto3->lucem-illud==8.0.1) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.5 in /opt/anaconda3/lib/python3.8/site-packages (from boto3->lucem-illud==8.0.1) (1.23.22)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from networkx->lucem-illud==8.0.1) (4.4.2)\n",
      "Requirement already satisfied: cffi>=0.6 in /opt/anaconda3/lib/python3.8/site-packages (from pysoundfile->lucem-illud==8.0.1) (1.14.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-image->lucem-illud==8.0.1) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-image->lucem-illud==8.0.1) (2.9.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (4.3.3)\n",
      "Requirement already satisfied: pygments in /opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (2.6.1)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (0.1.0)\n",
      "Requirement already satisfied: backcall in /opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (3.0.5)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (0.17.1)\n",
      "Requirement already satisfied: pickleshare in /opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (49.2.0.post20200714)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (4.8.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (0.7.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (1.0.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (2.11.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (8.0.13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (0.9.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (20.4)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (0.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (1.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (3.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (0.6.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/nyjiang/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython->lucem-illud==8.0.1) (5.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.8/site-packages (from cffi>=0.6->pysoundfile->lucem-illud==8.0.1) (2.20)\n",
      "Requirement already satisfied: ipython-genutils in /opt/anaconda3/lib/python3.8/site-packages (from traitlets>=4.2->IPython->lucem-illud==8.0.1) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->lucem-illud==8.0.1) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.8/site-packages (from jedi>=0.10->IPython->lucem-illud==8.0.1) (0.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.8/site-packages (from pexpect; sys_platform != \"win32\"->IPython->lucem-illud==8.0.1) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy->lucem-illud==8.0.1) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nyjiang/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy->lucem-illud==8.0.1) (4.0.1)\n",
      "Building wheels for collected packages: lucem-illud\n",
      "  Building wheel for lucem-illud (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lucem-illud: filename=lucem_illud-8.0.1-py3-none-any.whl size=34948 sha256=d0557b10d5d91c8419486ba75c78398cb80c2d0092394f875ed85971718e8f06\n",
      "  Stored in directory: /private/var/folders/5k/y_c_3dn11vz1l1xv724bslpc0000gn/T/pip-ephem-wheel-cache-s2mrxsef/wheels/26/66/59/2c69dc2c9856ccf2d3eb274e5754cbb361d91e0a577f63c61d\n",
      "Successfully built lucem-illud\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
    "#installing lucem_illud package\n",
    "#lucem_illud is a Latin phrase meaning \"that light\", the insight we can discover in text data!\n",
    "#If you get an error like \"Access is denied\", try running the `pip` command on the command line as an administrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're not familiar with jupyter notebook, you may wonder what the exclamation mark(!) at the beginning of the command does (or even what pip means). The exclamation mark enables us to execute Terminal commands in the notebook cells (e.g., run `!ls` to display files in the current folder).\n",
    "\n",
    "For this notebook we will be using the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz (12.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from en-core-web-sm==2.2.0) (3.2.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (8.0.13)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.8.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.9.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.7.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (4.47.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.22.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.0.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.6.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.4.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.24.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/nyjiang/.local/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.11.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (20.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (49.2.0.post20200714)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nyjiang/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy>=2.2.0->en-core-web-sm==2.2.0) (4.0.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy>=2.2.0->en-core-web-sm==2.2.0) (5.2.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (2020.6.20)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy>=2.2.0->en-core-web-sm==2.2.0) (1.1.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (2.4.7)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.0-py3-none-any.whl size=12019121 sha256=3b79d147be261c345dd4e6ed86fe0e5ab68ba37e680e46d26c5b51dc41c326c9\n",
      "  Stored in directory: /Users/nyjiang/Library/Caches/pip/wheels/fc/31/e9/092e6f05b2817c9cb45804a3d1bf2b9bf6575742c01819337c\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "import lucem_illud #pip install git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "import requests #for http requests\n",
    "import bs4 #called `beautifulsoup4`, an html parser\n",
    "import pandas #gives us DataFrames\n",
    "import docx #reading MS doc files, install as `python-docx`\n",
    "\n",
    "#Stuff for pdfs\n",
    "#Install as `pdfminer2`\n",
    "import pdfminer.pdfinterp\n",
    "import pdfminer.converter\n",
    "import pdfminer.layout\n",
    "import pdfminer.pdfpage\n",
    "\n",
    "#These come with Python\n",
    "import re #for regexs\n",
    "import urllib.parse #For joining urls\n",
    "import io #for making http requests look like files\n",
    "import json #For Tumblr API responses\n",
    "import os.path #For checking if files exist\n",
    "import os #For making directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be working on the following files/urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "example_text_file = 'sometextfile.txt'\n",
    "information_extraction_pdf = 'https://github.com/Computational-Content-Analysis-2018/Data-Files/raw/master/1-intro/Content%20Analysis%2018.pdf'\n",
    "example_docx = 'https://github.com/Computational-Content-Analysis-2018/Data-Files/raw/master/1-intro/macs6000_connecting_to_midway.docx'\n",
    "example_docx_save = 'example.docx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "Before we can start analyzing content we need to obtain it. Sometimes it will be\n",
    "provided to us from a pre-curated text archive, but sometimes we will need to\n",
    "download it. As a starting example we will attempt to download the wikipedia\n",
    "page on content analysis. The page is located at [https://en.wikipedia.org/wiki/\n",
    "Content_analysis](https://en.wikipedia.org/wiki/Content_analysis) so lets start\n",
    "with that.\n",
    "\n",
    "We can do this by making an HTTP GET request to that url, a GET request is\n",
    "simply a request to the server to provide the contents given by some url. The\n",
    "other request we will be using in this class is called a POST request and\n",
    "requests the server to take some content we provide. While the Python standard\n",
    "library does have the ability do make GET requests we will be using the\n",
    "[_requests_](http://docs.python-requests.org/en/master/) package as it is _'the\n",
    "only Non-GMO HTTP library for Python'_...also it provides a nicer interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "requests.get(wikipedia_content_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'Response [200]'` means the server responded with what we asked for. If you get\n",
    "another number (e.g. 404) it likely means there was some kind of error, these\n",
    "codes are called HTTP response codes and a list of them can be found\n",
    "[here](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes). The response\n",
    "object contains all the data the server sent including the website's contents\n",
    "and the HTTP header. We are interested in the contents which we can access with\n",
    "the `.text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Content analysis - Wikipedia</title>\n",
      "<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"b2b9b7cc-e7bd-4441-8b7e-f427add33ad6\",\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Content_analysis\",\"wgTitle\":\"Content analysis\",\"wgCurRevisionId\":1065940520,\"wgRevisionId\":1065940520,\"wgArticleId\":473317,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Articles with short description\",\"Short description matches Wikidata\",\"Articles prone to spam from October 2017\",\"Articles with BNE identifiers\",\n"
     ]
    }
   ],
   "source": [
    "wikiContentRequest = requests.get(wikipedia_content_analysis)\n",
    "print(wikiContentRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not what we were looking for, because it is the start of the HTML that\n",
    "makes up the website. This is HTML and is meant to be read by computers. Luckily\n",
    "we have a computer to parse it for us. To do the parsing we will use [_Beautiful\n",
    "Soup_](https://www.crummy.com/software/BeautifulSoup/) which is a better parser\n",
    "than the one in the standard library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we proceed to Beautiful Soup, a digression about Python syntax, especially about objects and functions.\n",
    "For those who are not familiar with the syntax of python (or, if you're familiar with R programming), you might wonder what requests.get or wikiContentRequest.text mean. To understand this, you need to first understand what objects are. You may have heard that Python is an object oriented programming language (unlike the procedure oriented programming language, an example of which is R). Object is a set of variables (or, data) and functions into which you pass your data. So, in object oriented programming languages, like python, variables and functions are bunleded into objects.\n",
    "\n",
    "For example, let's look at wikiContentRequest. We use dir() function, which returns the list of attributes and functions of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__attrs__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_content',\n",
       " '_content_consumed',\n",
       " '_next',\n",
       " 'apparent_encoding',\n",
       " 'close',\n",
       " 'connection',\n",
       " 'content',\n",
       " 'cookies',\n",
       " 'elapsed',\n",
       " 'encoding',\n",
       " 'headers',\n",
       " 'history',\n",
       " 'is_permanent_redirect',\n",
       " 'is_redirect',\n",
       " 'iter_content',\n",
       " 'iter_lines',\n",
       " 'json',\n",
       " 'links',\n",
       " 'next',\n",
       " 'ok',\n",
       " 'raise_for_status',\n",
       " 'raw',\n",
       " 'reason',\n",
       " 'request',\n",
       " 'status_code',\n",
       " 'text',\n",
       " 'url']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " dir(wikiContentRequest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's 'text' here. We used 'wikiContentRequest.text' to access 'text.' In other words, we use .(dot notation) to access functions from objects. wikiContentRequest has a set of functions, as shown above, and we used 'wikiContentRequest.text' to access one of them. By the way, dot notations do not necessarily refer to functions--it refers to anything that the entity contains. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to the next step: BeautifulSoup, a Python library which extracts data from HTML and XML, and transforms HTML files into Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Content analysis - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Content analysis\n",
      "\n",
      "From Wikipedia, the free encyclopedia\n",
      "\n",
      "\n",
      "\n",
      "Jump to navigation\n",
      "Jump to search\n",
      "Research method for studying docu\n"
     ]
    }
   ],
   "source": [
    "wikiContentSoup = bs4.BeautifulSoup(wikiContentRequest.text, 'html.parser')\n",
    "print(wikiContentSoup.text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better but there's still random whitespace and we have more than just\n",
    "the text of the article. This is because what we requested is the whole webpage,\n",
    "not just the text for the article.\n",
    "\n",
    "We want to extract only the text we care about, and in order to do this we will\n",
    "need to inspect the html. One way to do this is simply to go to the website with\n",
    "a browser and use its inspection or view source tool. If javascript or other\n",
    "dynamic loading occurs on the page, however, it is likely that what Python\n",
    "receives is not what you will see, so we will need to inspect what Python\n",
    "receives. To do this we can save the html `requests` obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "\n",
    "with open(content_analysis_save, mode='w', encoding='utf-8') as f:\n",
    "    f.write(wikiContentRequest.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open() is a function which literally opens and returns the file. This function has multiple modes, and, here, we used mode as 'w', which means: open a file for writing. And then, we use 'write' function to write on the empty file (content_analysis_save) that we created using open(content_analysis_save, mode='w', encoding='utf-8').} What did we write on this file? The text we got from wikiContentRequest.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's open the file (`wikipedia_content_analysis.html`) we just created with\n",
    "a web browser. It should look sort of like the original but without the images\n",
    "and formatting.\n",
    "\n",
    "As there is very little standardization on structuring webpages, figuring out\n",
    "how best to extract what you want is an art. Looking at this page it looks like\n",
    "all the main textual content is inside `<p>`(paragraph) tags within the `<body>`\n",
    "tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Asia \n",
      "\n",
      "Middle East\n",
      "\n",
      "Europe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contentPTags = wikiContentSoup.body.findAll('p')\n",
    "for pTag in contentPTags[:3]:\n",
    "    print(pTag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p><b>South Asia </b>\n",
      "</p>, <p><b>Middle East</b>\n",
      "</p>, <p><b>Europe</b>\n",
      "</p>, <p><b>North America</b>\n",
      "</p>, <p><b>Content analysis</b> is the study of <a href=\"/wiki/Document\" title=\"Document\">documents</a> and communication artifacts, which might be texts of various formats, pictures, audio or video. Social scientists use content analysis to examine patterns in communication in a replicable and systematic manner.<sup class=\"reference\" id=\"cite_ref-1\"><a href=\"#cite_note-1\">[1]</a></sup> One of the key advantages of using content analysis to analyse social phenomena is its non-invasive nature, in contrast to simulating social experiences or collecting survey answers.\n",
      "</p>, <p>Practices and philosophies of content analysis vary between academic disciplines. They all involve systematic reading or observation of <a href=\"/wiki/Text_(literary_theory)\" title=\"Text (literary theory)\">texts</a> or artifacts which are <a href=\"/wiki/Coding_(social_sciences)\" title=\"Coding (social sciences)\">assigned labels (sometimes called codes)</a> to indicate the presence of interesting, <a href=\"/wiki/Semantics\" title=\"Semantics\">meaningful</a> pieces of content.<sup class=\"reference\" id=\"cite_ref-2\"><a href=\"#cite_note-2\">[2]</a></sup><sup class=\"reference\" id=\"cite_ref-Tipaldo_2014_42_3-0\"><a href=\"#cite_note-Tipaldo_2014_42-3\">[3]</a></sup> By systematically labeling the content of a set of <a href=\"/wiki/Text_(literary_theory)\" title=\"Text (literary theory)\">texts</a>, researchers can analyse patterns of content <a href=\"/wiki/Quantitative_research\" title=\"Quantitative research\">quantitatively</a> using <a href=\"/wiki/Statistics\" title=\"Statistics\">statistical methods</a>, or use <a href=\"/wiki/Qualitative_research\" title=\"Qualitative research\">qualitative</a> methods to analyse meanings of content within <a href=\"/wiki/Text_(literary_theory)\" title=\"Text (literary theory)\">texts</a>.\n",
      "</p>, <p>Computers are increasingly used in content analysis to automate the labeling (or coding) of documents. Simple computational techniques can provide descriptive data such as word frequencies and document lengths. <a href=\"/wiki/Machine_learning\" title=\"Machine learning\">Machine learning</a> classifiers can greatly increase the number of texts that can be labeled, but the scientific utility of doing so is a matter of debate. Further, numerous computer-aided text analysis (CATA) computer programs are available that analyze text for pre-determined linguistic, semantic, and psychological characteristics.<sup class=\"reference\" id=\"cite_ref-Neuendorf2016_4-0\"><a href=\"#cite_note-Neuendorf2016-4\">[4]</a></sup>\n",
      "</p>, <p>Content analysis is best understood as a broad family of techniques. Effective researchers choose techniques that best help them answer their substantive questions. That said, according to <a href=\"/wiki/Klaus_Krippendorff\" title=\"Klaus Krippendorff\">Klaus Krippendorff</a>, six questions must be addressed in every content analysis:<sup class=\"reference\" id=\"cite_ref-Krippendorff2004_5-0\"><a href=\"#cite_note-Krippendorff2004-5\">[5]</a></sup>\n",
      "</p>, <p>The simplest and most objective form of content analysis considers unambiguous characteristics of the text such as <a class=\"mw-redirect\" href=\"/wiki/Word_frequencies\" title=\"Word frequencies\">word frequencies</a>, the page area taken by a newspaper column, or the duration of a <a href=\"/wiki/Radio\" title=\"Radio\">radio</a> or <a href=\"/wiki/Television\" title=\"Television\">television</a> program. Analysis of simple word frequencies is limited because the meaning of a word depends on surrounding text.  <a href=\"/wiki/Key_Word_in_Context\" title=\"Key Word in Context\">Key Word In Context</a> (KWIC) routines address this by placing words in their textual context. This helps resolve ambiguities such as those introduced by <a href=\"/wiki/Synonym\" title=\"Synonym\">synonyms</a> and <a href=\"/wiki/Homonym\" title=\"Homonym\">homonyms</a>.\n",
      "</p>, <p>A further step in analysis is the distinction between dictionary-based (quantitative) approaches and qualitative approaches. Dictionary-based approaches set up a list of categories derived from the frequency list of words and control the distribution of words and their respective categories over the texts. While methods in quantitative content analysis in this way transform observations of found categories into quantitative statistical data, the qualitative content analysis focuses more on the intentionality and its implications. There are strong parallels between qualitative content analysis and <a href=\"/wiki/Thematic_analysis\" title=\"Thematic analysis\">thematic analysis</a>.<sup class=\"reference\" id=\"cite_ref-6\"><a href=\"#cite_note-6\">[6]</a></sup>\n",
      "</p>, <p>Quantitative content analysis highlights frequency counts and objective analysis of these coded frequencies.<sup class=\"reference\" id=\"cite_ref-:03_7-0\"><a href=\"#cite_note-:03-7\">[7]</a></sup> Additionally, quantitative content analysis begins with a framed hypothesis with coding decided on before the analysis begins. These coding categories are strictly relevant to the researcher's hypothesis. Quantitative analysis also takes a deductive approach.<sup class=\"reference\" id=\"cite_ref-:12_8-0\"><a href=\"#cite_note-:12-8\">[8]</a></sup>\n",
      "</p>, <p><a href=\"/wiki/Siegfried_Kracauer\" title=\"Siegfried Kracauer\">Siegfried Kracauer</a> provides a critique of quantitative analysis, asserting that it oversimplifies complex communications in order to be more reliable. On the other hand, qualitative analysis deals with the intricacies of latent interpretations, whereas quantitative has a focus on manifest meanings. He also acknowledges an \"overlap\" of qualitative and quantitative content analysis.<sup class=\"reference\" id=\"cite_ref-:03_7-1\"><a href=\"#cite_note-:03-7\">[7]</a></sup> Patterns are looked at more closely in qualitative analysis, and based on the latent meanings that the researcher may find, the course of the research could be changed. It is inductive and begins with open research questions, as opposed to a hypothesis.<sup class=\"reference\" id=\"cite_ref-:12_8-1\"><a href=\"#cite_note-:12-8\">[8]</a></sup>\n",
      "</p>, <p>With the rise of common computing facilities like PCs, computer-based methods of analysis are growing in popularity.<sup class=\"reference\" id=\"cite_ref-9\"><a href=\"#cite_note-9\">[9]</a></sup><sup class=\"reference\" id=\"cite_ref-10\"><a href=\"#cite_note-10\">[10]</a></sup><sup class=\"reference\" id=\"cite_ref-11\"><a href=\"#cite_note-11\">[11]</a></sup> Answers to open ended questions, newspaper articles, political party manifestos, medical records or systematic observations in experiments can all be subject to systematic analysis of textual data.\n",
      "</p>, <p>By having contents of communication available in form of machine readable texts, the input is analyzed for frequencies and coded into categories for building up inferences.\n",
      "</p>, <p>Computer-assisted analysis can help with large, electronic data sets by cutting out time and eliminating the need for multiple human coders to establish inter-coder reliability. However, human coders can still be employed for content analysis, as they are often more able to pick out nuanced and latent meanings in text. A study  found that human coders were able to evaluate a broader range and make inferences based on latent meanings.<sup class=\"reference\" id=\"cite_ref-12\"><a href=\"#cite_note-12\">[12]</a></sup>\n",
      "</p>, <p>Robert Weber notes: \"To make valid inferences from the text, it is important that the classification procedure be reliable in the sense of being consistent: Different people should code the same text in the same way\".<sup class=\"reference\" id=\"cite_ref-13\"><a href=\"#cite_note-13\">[13]</a></sup> The validity, inter-coder reliability and intra-coder reliability are subject to intense methodological research efforts over long years.<sup class=\"reference\" id=\"cite_ref-Krippendorff2004_5-1\"><a href=\"#cite_note-Krippendorff2004-5\">[5]</a></sup>\n",
      "Neuendorf suggests that when human coders are used in content analysis at least two independent coders should be used. Reliability of human coding is often measured using a statistical measure of <i>inter-coder reliability</i> or \"the amount of agreement or correspondence among two or more coders\".<sup class=\"reference\" id=\"cite_ref-Neuendorf2016_4-1\"><a href=\"#cite_note-Neuendorf2016-4\">[4]</a></sup> Lacy and Riffe identify the measurement of inter-coder reliability as a strength of quantitative content analysis, arguing that, if content analysts do not measure inter-coder reliability, their data are no more reliable than the subjective impressions of a single reader.<sup class=\"reference\" id=\"cite_ref-14\"><a href=\"#cite_note-14\">[14]</a></sup>\n",
      "</p>, <p>There are five types of texts in content analysis:\n",
      "</p>, <p>Content analysis is research using the categorization and classification of speech, written text, interviews, images, or other forms of communication.  In its beginnings, using the first newspapers at the end of the 19th century, analysis was done manually by measuring the number of columns given a subject. The approach can also be traced back to a university student studying patterns in Shakespeare's literature in 1893.<sup class=\"reference\" id=\"cite_ref-15\"><a href=\"#cite_note-15\">[15]</a></sup>\n",
      "</p>, <p>Over the years, content analysis has been applied to a variety of scopes. <a href=\"/wiki/Hermeneutics\" title=\"Hermeneutics\">Hermeneutics</a> and <a href=\"/wiki/Philology\" title=\"Philology\">philology</a> have long used content analysis to interpret sacred and profane texts and, in many cases, to attribute texts' <a class=\"mw-redirect\" href=\"/wiki/Authorship\" title=\"Authorship\">authorship</a> and <a href=\"/wiki/Authentication\" title=\"Authentication\">authenticity</a>.<sup class=\"reference\" id=\"cite_ref-Tipaldo_2014_42_3-1\"><a href=\"#cite_note-Tipaldo_2014_42-3\">[3]</a></sup><sup class=\"reference\" id=\"cite_ref-Krippendorff2004_5-2\"><a href=\"#cite_note-Krippendorff2004-5\">[5]</a></sup>\n",
      "</p>, <p>In recent times, particularly with the advent of <a href=\"/wiki/Mass_communication\" title=\"Mass communication\">mass communication</a>, content analysis has known an increasing use to deeply analyze and understand media content and <a class=\"new\" href=\"/w/index.php?title=Media_logic&amp;action=edit&amp;redlink=1\" title=\"Media logic (page does not exist)\">media logic</a>. \n",
      "The political scientist <a href=\"/wiki/Harold_Lasswell\" title=\"Harold Lasswell\">Harold Lasswell</a> formulated the core questions of content analysis in its early-mid 20th-century mainstream version: \"Who says what, to whom, why, to what extent and with what effect?\".<sup class=\"reference\" id=\"cite_ref-16\"><a href=\"#cite_note-16\">[16]</a></sup> The strong emphasis for a quantitative approach started up by Lasswell was finally carried out by another \"father\" of content analysis, <a href=\"/wiki/Bernard_Berelson\" title=\"Bernard Berelson\">Bernard Berelson</a>, who proposed a definition of content analysis which, from this point of view, is emblematic: \"a research technique for the objective, systematic and quantitative description of the manifest content of communication\".<sup class=\"reference\" id=\"cite_ref-Berelson1952_17-0\"><a href=\"#cite_note-Berelson1952-17\">[17]</a></sup>\n",
      "</p>, <p>Quantitative content analysis has enjoyed a renewed popularity in recent years thanks to technological advances and fruitful application in of mass communication and personal communication research. Content analysis of textual <a href=\"/wiki/Big_data\" title=\"Big data\">big data</a> produced by <a href=\"/wiki/New_media\" title=\"New media\">new media</a>, particularly <a href=\"/wiki/Social_media\" title=\"Social media\">social media</a> and <a class=\"mw-redirect\" href=\"/wiki/Mobile_devices\" title=\"Mobile devices\">mobile devices</a> has become popular. These approaches take a simplified view of language that ignores the complexity of semiosis, the process by which meaning is formed out of language. Quantitative content analysts have been criticized for limiting the scope of content analysis to simple counting, and for applying the measurement methodologies of the natural sciences without reflecting critically on their appropriateness to social science.<sup class=\"reference\" id=\"cite_ref-:0_18-0\"><a href=\"#cite_note-:0-18\">[18]</a></sup> Conversely, qualitative content analysts have been criticized for being insufficiently systematic and too impressionistic.<sup class=\"reference\" id=\"cite_ref-:0_18-1\"><a href=\"#cite_note-:0-18\">[18]</a></sup> Krippendorff argues that quantitative and qualitative approaches to content analysis tend to overlap, and that there can be no generalisable conclusion as to which approach is superior.<sup class=\"reference\" id=\"cite_ref-:0_18-2\"><a href=\"#cite_note-:0-18\">[18]</a></sup>\n",
      "</p>, <p>Content analysis can also be described as studying <a href=\"/wiki/Trace_evidence\" title=\"Trace evidence\">traces</a>, which are documents from past times, and artifacts, which are non-linguistic documents. Texts are understood to be produced by communication processes in a broad sense of that phrase—often gaining mean through <a href=\"/wiki/Abductive_reasoning\" title=\"Abductive reasoning\">abduction</a>.<sup class=\"reference\" id=\"cite_ref-Tipaldo_2014_42_3-2\"><a href=\"#cite_note-Tipaldo_2014_42-3\">[3]</a></sup><sup class=\"reference\" id=\"cite_ref-19\"><a href=\"#cite_note-19\">[19]</a></sup>\n",
      "</p>, <p>Manifest content is readily understandable at its face value. Its meaning is direct. Latent content is not as overt, and requires interpretation to uncover the meaning or implication.<sup class=\"reference\" id=\"cite_ref-20\"><a href=\"#cite_note-20\">[20]</a></sup>\n",
      "</p>, <p>Holsti groups fifteen uses of content analysis into three basic <a class=\"mw-redirect\" href=\"/wiki/Categorisation\" title=\"Categorisation\">categories</a>:<sup class=\"reference\" id=\"cite_ref-Holsti1969_21-0\"><a href=\"#cite_note-Holsti1969-21\">[21]</a></sup>\n",
      "</p>, <p>He also places these uses into the context of the basic communication <a href=\"/wiki/Paradigm\" title=\"Paradigm\">paradigm</a>.\n",
      "</p>, <p>The following table shows fifteen uses of content analysis in terms of their general purpose, element of the communication paradigm to which they apply, and the general question they are intended to answer.\n",
      "</p>, <p>As a counterpoint, there are limits to the scope of use for the procedures that characterize content analysis. In particular, if access to the goal of analysis can be obtained by direct means without material interference, then direct measurement techniques yield better data.<sup class=\"reference\" id=\"cite_ref-23\"><a href=\"#cite_note-23\">[23]</a></sup> Thus, while content analysis attempts to quantifiably describe <em>communications</em> whose features are primarily categorical——limited usually to a nominal or ordinal scale——via selected conceptual units (the <em>unitization</em>) which are assigned values (the <em>categorization</em>) for <em>enumeration</em> while monitoring <em>intercoder reliability</em>, if instead the target quantity manifestly is already directly measurable——typically on an interval or ratio scale——especially a continuous physical quantity, then such targets usually are not listed among those needing the \"subjective\" selections and formulations of content analysis.<sup class=\"reference\" id=\"cite_ref-24\"><a href=\"#cite_note-24\">[24]</a></sup><sup class=\"reference\" id=\"cite_ref-25\"><a href=\"#cite_note-25\">[25]</a></sup><sup class=\"reference\" id=\"cite_ref-26\"><a href=\"#cite_note-26\">[26]</a></sup><sup class=\"reference\" id=\"cite_ref-27\"><a href=\"#cite_note-27\">[27]</a></sup><sup class=\"reference\" id=\"cite_ref-28\"><a href=\"#cite_note-28\">[28]</a></sup><sup class=\"reference\" id=\"cite_ref-29\"><a href=\"#cite_note-29\">[29]</a></sup><sup class=\"reference\" id=\"cite_ref-30\"><a href=\"#cite_note-30\">[30]</a></sup><sup class=\"reference\" id=\"cite_ref-31\"><a href=\"#cite_note-31\">[31]</a></sup> For example (from mixed research and clinical application), as medical images <em>communicate</em> diagnostic features to physicians, <a href=\"/wiki/Neuroimaging\" title=\"Neuroimaging\">neuroimaging</a>'s <a href=\"/wiki/Stroke\" title=\"Stroke\">stroke</a> (infarct) volume scale called ASPECTS is <em>unitized</em> as 10 qualitatively delineated (unequal) brain regions in the <a href=\"/wiki/Middle_cerebral_artery\" title=\"Middle cerebral artery\">middle cerebral artery</a> territory, which it <em>categorizes</em> as being at least partly versus not at all infarcted in order to <em>enumerate</em> the latter, with published series often assessing <em>intercoder reliability</em> by <a href=\"/wiki/Cohen%27s_kappa\" title=\"Cohen's kappa\">Cohen's kappa</a>. The foregoing <em>italicized operations</em> impose the uncredited <em>form</em> of content analysis onto an estimation of infarct extent, which instead is easily enough and more accurately measured as a volume directly on the images.<sup class=\"reference\" id=\"cite_ref-32\"><a href=\"#cite_note-32\">[32]</a></sup><sup class=\"reference\" id=\"cite_ref-33\"><a href=\"#cite_note-33\">[33]</a></sup> (\"Accuracy ... is the highest form of reliability.\"<sup class=\"reference\" id=\"cite_ref-34\"><a href=\"#cite_note-34\">[34]</a></sup>) The concomitant clinical assessment, however, by the <a href=\"/wiki/National_Institutes_of_Health_Stroke_Scale\" title=\"National Institutes of Health Stroke Scale\">National Institutes of Health Stroke Scale</a> (NIHSS) or the <a href=\"/wiki/Modified_Rankin_Scale\" title=\"Modified Rankin Scale\">modified Rankin Scale</a> (mRS), retains the necessary form of content analysis. Recognizing potential limits of content analysis across the contents of language and images alike, <a href=\"/wiki/Klaus_Krippendorff\" title=\"Klaus Krippendorff\">Klaus Krippendorff</a> affirms that \"comprehen[sion] ... may ... not conform at all to the process of classification and/or counting by which most content analyses proceed,\"<sup class=\"reference\" id=\"cite_ref-35\"><a href=\"#cite_note-35\">[35]</a></sup> suggesting that content analysis might materially distort a message.\n",
      "</p>, <p>The process of the initial coding scheme or approach to coding is contingent on the particular content analysis approach selected. Through a directed content analysis, the scholars draft a preliminary coding scheme from pre-existing theory or assumptions. While with the conventional content analysis approach, the initial coding scheme developed from the data.\n",
      "</p>, <p>With either approach above, immersing oneself into the data to obtain an overall picture is recommendable for researchers to conduct. Furthermore, identifying a consistent and clear unit of coding is vital, and researchers' choices range from a single word to several paragraphs, from texts to iconic symbols. Last, constructing the relationships between codes by sorting out them within specific categories or themes.<sup class=\"reference\" id=\"cite_ref-36\"><a href=\"#cite_note-36\">[36]</a></sup>\n",
      "</p>, <p><br/>\n",
      "</p>]\n"
     ]
    }
   ],
   "source": [
    "print(contentPTags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another excursion for those who are not familiar with programming: for loop. For loop is used to iterate over a sequence. \"ContentPTags\" contains multiple paragraphs, each of which starts and ends with `<p>`. What the \"for pTag in contentPtags[:3]\" does here is: find each paragraph in contentPTags, which, here, we limited to the first three using contentPtags[:3], and then print each paragraph. So, we have three paragraphs. By the way, you can insert `<p>` in juputer notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the text from the page, split up by paragraph. If we wanted to\n",
    "get the section headers or references as well it would require a bit more work,\n",
    "but is doable.\n",
    "\n",
    "There is one more thing we might want to do before sending this text to be\n",
    "processed, remove the references indicators (`[2]`, `[3]` , etc). To do this we\n",
    "can use a short regular expression (regex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       paragraph-text\n",
      "0                                       South Asia \\n\n",
      "1                                       Middle East\\n\n",
      "2                                            Europe\\n\n",
      "3                                     North America\\n\n",
      "4   Content analysis is the study of documents and...\n",
      "5   Practices and philosophies of content analysis...\n",
      "6   Computers are increasingly used in content ana...\n",
      "7   Content analysis is best understood as a broad...\n",
      "8   The simplest and most objective form of conten...\n",
      "9   A further step in analysis is the distinction ...\n",
      "10  Quantitative content analysis highlights frequ...\n",
      "11  Siegfried Kracauer provides a critique of quan...\n",
      "12  With the rise of common computing facilities l...\n",
      "13  By having contents of communication available ...\n",
      "14  Computer-assisted analysis can help with large...\n",
      "15  Robert Weber notes: \"To make valid inferences ...\n",
      "16  There are five types of texts in content analy...\n",
      "17  Content analysis is research using the categor...\n",
      "18  Over the years, content analysis has been appl...\n",
      "19  In recent times, particularly with the advent ...\n",
      "20  Quantitative content analysis has enjoyed a re...\n",
      "21  Content analysis can also be described as stud...\n",
      "22  Manifest content is readily understandable at ...\n",
      "23  Holsti groups fifteen uses of content analysis...\n",
      "24  He also places these uses into the context of ...\n",
      "25  The following table shows fifteen uses of cont...\n",
      "26  As a counterpoint, there are limits to the sco...\n",
      "27  The process of the initial coding scheme or ap...\n",
      "28  With either approach above, immersing oneself ...\n",
      "29                                                 \\n\n"
     ]
    }
   ],
   "source": [
    "contentParagraphs = []\n",
    "for pTag in contentPTags:\n",
    "    #strings starting with r are raw so their \\'s are not modifier characters\n",
    "    #If we didn't start with r the string would be: '\\\\[\\\\d+\\\\]'\n",
    "    contentParagraphs.append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "\n",
    "#convert to a DataFrame\n",
    "contentParagraphsDF = pandas.DataFrame({'paragraph-text' : contentParagraphs})\n",
    "print(contentParagraphsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we learned how to do for loop, you might get what we did here: using contentParagraphs = [], we made an empty list; and then, for each paragraph in contentPTags, we substituted every [\\d+\\] with '', i.e., removed every [\\d+\\], and then appended each paragraph (now without [\\d+\\]) to the empty list. As we can see, we have a dataframe, each row of which is each paragraph of contentPTags, without reference indicators. \n",
    "\n",
    "By the way, what does [\\d+\\] mean? If you are not familiar with regex, it is a way of specifying searches in text.\n",
    "A regex engine takes in the search pattern, in the above case `'\\[\\d+\\]'` and\n",
    "some string, the paragraph texts. Then it reads the input string one character\n",
    "at a time checking if it matches the search. Here the regex `'\\d'` matches\n",
    "number characters (while `'\\['` and `'\\]'` capture the braces on either side)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `DataFrame` containing all relevant text from the page ready to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(36, 37), match='2'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findNumber = r'\\d'\n",
    "regexResults = re.search(findNumber, 'not a number, not a number, numbers 2134567890, not a number')\n",
    "regexResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python the regex package (`re`) usually returns `Match` objects (you can have\n",
    "multiple pattern hits in a a single `Match`), to get the string that matched our\n",
    "pattern we can use the `.group()` method, and as we want the first one we will\n",
    "ask for the 0'th group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(regexResults.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us the first number, if we wanted the whole block of numbers we can\n",
    "add a wildcard `'+'` which requests 1 or more instances of the preceding\n",
    "character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2134567890\n"
     ]
    }
   ],
   "source": [
    "findNumbers = r'\\d+'\n",
    "regexResults = re.search(findNumbers, 'not a number, not a number, numbers 2134567890, not a number')\n",
    "print(regexResults.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the whole block of numbers, there are a huge number of special\n",
    "characters in regex, for the full description of Python's implementation look at\n",
    "the [re docs](https://docs.python.org/3/library/re.html) there is also a short\n",
    "[tutorial](https://docs.python.org/3/howto/regex.html#regex-howto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Exercise 1</font>\n",
    "<font color=\"red\">Construct cells immediately below this that describe and download webcontent relating to your anticipated final project. Use beautiful soup and at least five regular expressions to extract relevant, nontrivial *chunks* of that content (e.g., cleaned sentences, paragraphs, etc.) to a pandas `Dataframe`.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to scrape the first page of the \"Tujia\" forum on Baidu Tieba. Baidu Tieba is the most used Chinese communication platform for people who have a common interest to socially interact. The \"Tujia\", with a total population of over 8 million, are an East Asian ethnic group and the eighth-largest officially recognized ethnic minority in China. Below, I gather the titles of each theme of posts on the first page of the Tujia forum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       theme-titles\n",
      "0           教你如何识别苗族谎言（一）为什么说土家族是汉族\n",
      "1           教你识别苗族谎言（二）潘光旦教授到底说了什么？\n",
      "2            穿着民族服装参加校草大赛，请族人们投我一票！\n",
      "3                   想学习，土家语，求各位族人指路\n",
      "4                     土家族为什么这么像汉族？？\n",
      "5               土家族跟苗族父系Y染色体类型差异巨大！\n",
      "6              请各位擦亮双眼，辨别谣言和不法分子的挑唆\n",
      "7         土家族爱国忠贞侯秦良玉白杆土家军，“要学花木兰，先\n",
      "8                    有没有吧友去做过基因检测啊？\n",
      "9    纪念伟大的爱国诗人屈原，同时也纪念 所有从古至今为国征战的土\n",
      "10   神秘消失巴人的后裔 原来还生活在三峡边缘免责声明:本贴文图来\n",
      "11          湖南的阿科些，这传统的三下锅怎样？第一次做哈。\n",
      "12                  我们把奶奶叫巴巴，爷爷叫公，不\n",
      "13                   我想知道哪里可以买到这个服装\n",
      "14  请不要把汉语北方方言当作土家语！全解那些自以为是土家语的方言词\n",
      "15                 土家族的确是真实存在的一个民族。\n",
      "16   土家族的三大土王之一“惹巴冲”，据说是龙山取的景。五代十国时\n",
      "17                        关于民族服饰的问题\n",
      "18          请问一下有谁知道武汉哪里可以买到土家族衣服的？\n",
      "19              土家族怎么用方言怎么叫自己的哥哥...\n",
      "20   土家族是有重大贡献的民族，土家族的祖先蚌埠氏(彭祖)建立的包\n",
      "21      各个土家族聚居地的土家语地名，不知道有没有感兴趣的吧友\n",
      "22                   祝各位毕兹卡新年快乐！   \n",
      "23                    土家族古代有啥特殊甲冑吗？\n",
      "24                    娶个土家族老婆现在容易吗？\n",
      "25                   从古籍中看土家族之贵州土家族\n",
      "26                        土家族田姓Y染色体\n",
      "27               做了三次基因检测，三次的差别都好大！\n",
      "28                        问下大家向姓的历史\n",
      "29                         给大家看个东西。\n",
      "30              请问有没有朋友知道哪可以买到土家族常服\n",
      "31                          收集的民族服装\n",
      "32                    土家族的咚咚喹哪里可以买到\n",
      "33                  湘西永顺老司城博物馆的一些藏品\n",
      "34                             西兰卡普\n",
      "35                老调重弹土家族土司简史（国中之国）\n",
      "36                      细数沿河县的土家语地名\n",
      "37              川剧大变脸，火眼辨真身，土家贴吧大剧场\n",
      "38                      【罗马字版】标准语教程\n",
      "39                    举报杨政录有没有50W？？\n",
      "40                    有没有人听说过“垚人坟？”\n",
      "41        南楚国时期土家族王，惹巴冲的剧照。英姿飒爽有木有？\n",
      "42                     楚国剧日常的一波剧照分享\n",
      "43                     湘西土家族梯玛神歌（二）\n",
      "44                     湘西土家族梯玛神歌（一）\n",
      "45                       有关湘西的一些照片。\n",
      "46             话说“鼎罐”（圜底釜——渔猎部族的文化）\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "tujia_forum = 'https://tiebac.baidu.com/f?kw=%E5%9C%9F%E5%AE%B6%E6%97%8F'\n",
    "# get the tujia forum's first page\n",
    "r = requests.get(tujia_forum)\n",
    "page = r.text\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "contentPTags = soup.findAll('a', {\"class\": \"j_th_tit\"})\n",
    "# for pTag in contentPTags:\n",
    "#     print(pTag.text)\n",
    "# Now we have our list of post titles from the first page of Tujia forum. \n",
    "# But these titles are pretty messy, and we need to clean them up.\n",
    "# use emoji_pattern to match emoji\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "contentTitles = []\n",
    "for pTag in contentPTags:\n",
    "    # remove both leading and trailing spaces\n",
    "    res_str = re.sub(r'^\\s+|\\s+$', \"\", pTag.text)\n",
    "    # remove all lower case\n",
    "    res_str = re.sub(r'[a-z]', \"\", res_str)\n",
    "    # sub hash tags\n",
    "    res_str = re.sub(r'＃', \"\", res_str)\n",
    "    # remove HTML tags\n",
    "    res_str = re.sub(r'<[^>]+>', \"\", res_str)\n",
    "    # remove @-mentions\n",
    "    res_str = re.sub(r'(?:@[\\w_]+)', \"\", res_str)\n",
    "    # remove emoji\n",
    "    res_str = emoji_pattern.sub(r'', res_str)\n",
    "    # check if a string is empty or contain blank spaces only\n",
    "    # add list items\n",
    "    if res_str and res_str.strip():\n",
    "        contentTitles.append(res_str)\n",
    "# panda dataframe\n",
    "contentTitlesDF = pd.DataFrame({'theme-titles' : contentTitles})\n",
    "print(contentTitlesDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Spidering\n",
    "\n",
    "What if we want to to get a bunch of different pages from wikipedia. We would\n",
    "need to get the url for each of the pages we want. Typically, we want pages that\n",
    "are linked to by other pages and so we will need to parse pages and identify the\n",
    "links. Right now we will be retrieving all links in the body of the content\n",
    "analysis page.\n",
    "\n",
    "To do this we will need to find all the `<a>` (anchor) tags with `href`s\n",
    "(hyperlink references) inside of `<p>` tags. `href` can have many\n",
    "[different](http://stackoverflow.com/questions/4855168/what-is-href-and-why-is-\n",
    "it-used) [forms](https://en.wikipedia.org/wiki/Hyperlink#Hyperlinks_in_HTML) so\n",
    "dealing with them can be tricky, but generally, you will want to extract\n",
    "absolute or relative links. An absolute link is one you can follow without\n",
    "modification, while a relative link requires a base url that you will then\n",
    "append. Wikipedia uses relative urls for its internal links: below is an example\n",
    "for dealing with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://en.wikipedia.org/wiki/Document', 4, 'documents'), ('https://en.wikipedia.org/wiki/Text_(literary_theory)', 5, 'texts'), ('https://en.wikipedia.org/wiki/Coding_(social_sciences)', 5, 'assigned labels (sometimes called codes)'), ('https://en.wikipedia.org/wiki/Semantics', 5, 'meaningful'), ('https://en.wikipedia.org/wiki/Text_(literary_theory)', 5, 'texts'), ('https://en.wikipedia.org/wiki/Quantitative_research', 5, 'quantitatively'), ('https://en.wikipedia.org/wiki/Statistics', 5, 'statistical methods'), ('https://en.wikipedia.org/wiki/Qualitative_research', 5, 'qualitative'), ('https://en.wikipedia.org/wiki/Text_(literary_theory)', 5, 'texts'), ('https://en.wikipedia.org/wiki/Machine_learning', 6, 'Machine learning')]\n"
     ]
    }
   ],
   "source": [
    "#wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "\n",
    "otherPAgeURLS = []\n",
    "#We also want to know where the links come from so we also will get:\n",
    "#the paragraph number\n",
    "#the word the link is in\n",
    "for paragraphNum, pTag in enumerate(contentPTags):\n",
    "    #we only want hrefs that link to wiki pages\n",
    "    tagLinks = pTag.findAll('a', href=re.compile('/wiki/'), class_=False)\n",
    "    for aTag in tagLinks:\n",
    "        #We need to extract the url from the <a> tag\n",
    "        relurl = aTag.get('href')\n",
    "        linkText = aTag.text\n",
    "        #wikipedia_base_url is the base we can use the urllib joining function to merge them\n",
    "        #Giving a nice structured tupe like this means we can use tuple expansion later\n",
    "        otherPAgeURLS.append((\n",
    "            urllib.parse.urljoin(wikipedia_base_url, relurl),\n",
    "            paragraphNum,\n",
    "            linkText,\n",
    "        ))\n",
    "print(otherPAgeURLS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p><b>South Asia </b>\n",
      "</p>, <p><b>Middle East</b>\n",
      "</p>, <p><b>Europe</b>\n",
      "</p>, <p><b>North America</b>\n",
      "</p>, <p><b>Content analysis</b> is the study of <a href=\"/wiki/Document\" title=\"Document\">documents</a> and communication artifacts, which might be texts of various formats, pictures, audio or video. Social scientists use content analysis to examine patterns in communication in a replicable and systematic manner.<sup class=\"reference\" id=\"cite_ref-1\"><a href=\"#cite_note-1\">[1]</a></sup> One of the key advantages of using content analysis to analyse social phenomena is its non-invasive nature, in contrast to simulating social experiences or collecting survey answers.\n",
      "</p>, <p>Practices and philosophies of content analysis vary between academic disciplines. They all involve systematic reading or observation of <a href=\"/wiki/Text_(literary_theory)\" title=\"Text (literary theory)\">texts</a> or artifacts which are <a href=\"/wiki/Coding_(social_sciences)\" title=\"Coding (social sciences)\">assigned labels (sometimes called codes)</a> to indicate the presence of interesting, <a href=\"/wiki/Semantics\" title=\"Semantics\">meaningful</a> pieces of content.<sup class=\"reference\" id=\"cite_ref-2\"><a href=\"#cite_note-2\">[2]</a></sup><sup class=\"reference\" id=\"cite_ref-Tipaldo_2014_42_3-0\"><a href=\"#cite_note-Tipaldo_2014_42-3\">[3]</a></sup> By systematically labeling the content of a set of <a href=\"/wiki/Text_(literary_theory)\" title=\"Text (literary theory)\">texts</a>, researchers can analyse patterns of content <a href=\"/wiki/Quantitative_research\" title=\"Quantitative research\">quantitatively</a> using <a href=\"/wiki/Statistics\" title=\"Statistics\">statistical methods</a>, or use <a href=\"/wiki/Qualitative_research\" title=\"Qualitative research\">qualitative</a> methods to analyse meanings of content within <a href=\"/wiki/Text_(literary_theory)\" title=\"Text (literary theory)\">texts</a>.\n",
      "</p>, <p>Computers are increasingly used in content analysis to automate the labeling (or coding) of documents. Simple computational techniques can provide descriptive data such as word frequencies and document lengths. <a href=\"/wiki/Machine_learning\" title=\"Machine learning\">Machine learning</a> classifiers can greatly increase the number of texts that can be labeled, but the scientific utility of doing so is a matter of debate. Further, numerous computer-aided text analysis (CATA) computer programs are available that analyze text for pre-determined linguistic, semantic, and psychological characteristics.<sup class=\"reference\" id=\"cite_ref-Neuendorf2016_4-0\"><a href=\"#cite_note-Neuendorf2016-4\">[4]</a></sup>\n",
      "</p>, <p>Content analysis is best understood as a broad family of techniques. Effective researchers choose techniques that best help them answer their substantive questions. That said, according to <a href=\"/wiki/Klaus_Krippendorff\" title=\"Klaus Krippendorff\">Klaus Krippendorff</a>, six questions must be addressed in every content analysis:<sup class=\"reference\" id=\"cite_ref-Krippendorff2004_5-0\"><a href=\"#cite_note-Krippendorff2004-5\">[5]</a></sup>\n",
      "</p>, <p>The simplest and most objective form of content analysis considers unambiguous characteristics of the text such as <a class=\"mw-redirect\" href=\"/wiki/Word_frequencies\" title=\"Word frequencies\">word frequencies</a>, the page area taken by a newspaper column, or the duration of a <a href=\"/wiki/Radio\" title=\"Radio\">radio</a> or <a href=\"/wiki/Television\" title=\"Television\">television</a> program. Analysis of simple word frequencies is limited because the meaning of a word depends on surrounding text.  <a href=\"/wiki/Key_Word_in_Context\" title=\"Key Word in Context\">Key Word In Context</a> (KWIC) routines address this by placing words in their textual context. This helps resolve ambiguities such as those introduced by <a href=\"/wiki/Synonym\" title=\"Synonym\">synonyms</a> and <a href=\"/wiki/Homonym\" title=\"Homonym\">homonyms</a>.\n",
      "</p>, <p>A further step in analysis is the distinction between dictionary-based (quantitative) approaches and qualitative approaches. Dictionary-based approaches set up a list of categories derived from the frequency list of words and control the distribution of words and their respective categories over the texts. While methods in quantitative content analysis in this way transform observations of found categories into quantitative statistical data, the qualitative content analysis focuses more on the intentionality and its implications. There are strong parallels between qualitative content analysis and <a href=\"/wiki/Thematic_analysis\" title=\"Thematic analysis\">thematic analysis</a>.<sup class=\"reference\" id=\"cite_ref-6\"><a href=\"#cite_note-6\">[6]</a></sup>\n",
      "</p>, <p>Quantitative content analysis highlights frequency counts and objective analysis of these coded frequencies.<sup class=\"reference\" id=\"cite_ref-:03_7-0\"><a href=\"#cite_note-:03-7\">[7]</a></sup> Additionally, quantitative content analysis begins with a framed hypothesis with coding decided on before the analysis begins. These coding categories are strictly relevant to the researcher's hypothesis. Quantitative analysis also takes a deductive approach.<sup class=\"reference\" id=\"cite_ref-:12_8-0\"><a href=\"#cite_note-:12-8\">[8]</a></sup>\n",
      "</p>, <p><a href=\"/wiki/Siegfried_Kracauer\" title=\"Siegfried Kracauer\">Siegfried Kracauer</a> provides a critique of quantitative analysis, asserting that it oversimplifies complex communications in order to be more reliable. On the other hand, qualitative analysis deals with the intricacies of latent interpretations, whereas quantitative has a focus on manifest meanings. He also acknowledges an \"overlap\" of qualitative and quantitative content analysis.<sup class=\"reference\" id=\"cite_ref-:03_7-1\"><a href=\"#cite_note-:03-7\">[7]</a></sup> Patterns are looked at more closely in qualitative analysis, and based on the latent meanings that the researcher may find, the course of the research could be changed. It is inductive and begins with open research questions, as opposed to a hypothesis.<sup class=\"reference\" id=\"cite_ref-:12_8-1\"><a href=\"#cite_note-:12-8\">[8]</a></sup>\n",
      "</p>, <p>With the rise of common computing facilities like PCs, computer-based methods of analysis are growing in popularity.<sup class=\"reference\" id=\"cite_ref-9\"><a href=\"#cite_note-9\">[9]</a></sup><sup class=\"reference\" id=\"cite_ref-10\"><a href=\"#cite_note-10\">[10]</a></sup><sup class=\"reference\" id=\"cite_ref-11\"><a href=\"#cite_note-11\">[11]</a></sup> Answers to open ended questions, newspaper articles, political party manifestos, medical records or systematic observations in experiments can all be subject to systematic analysis of textual data.\n",
      "</p>, <p>By having contents of communication available in form of machine readable texts, the input is analyzed for frequencies and coded into categories for building up inferences.\n",
      "</p>, <p>Computer-assisted analysis can help with large, electronic data sets by cutting out time and eliminating the need for multiple human coders to establish inter-coder reliability. However, human coders can still be employed for content analysis, as they are often more able to pick out nuanced and latent meanings in text. A study  found that human coders were able to evaluate a broader range and make inferences based on latent meanings.<sup class=\"reference\" id=\"cite_ref-12\"><a href=\"#cite_note-12\">[12]</a></sup>\n",
      "</p>, <p>Robert Weber notes: \"To make valid inferences from the text, it is important that the classification procedure be reliable in the sense of being consistent: Different people should code the same text in the same way\".<sup class=\"reference\" id=\"cite_ref-13\"><a href=\"#cite_note-13\">[13]</a></sup> The validity, inter-coder reliability and intra-coder reliability are subject to intense methodological research efforts over long years.<sup class=\"reference\" id=\"cite_ref-Krippendorff2004_5-1\"><a href=\"#cite_note-Krippendorff2004-5\">[5]</a></sup>\n",
      "Neuendorf suggests that when human coders are used in content analysis at least two independent coders should be used. Reliability of human coding is often measured using a statistical measure of <i>inter-coder reliability</i> or \"the amount of agreement or correspondence among two or more coders\".<sup class=\"reference\" id=\"cite_ref-Neuendorf2016_4-1\"><a href=\"#cite_note-Neuendorf2016-4\">[4]</a></sup> Lacy and Riffe identify the measurement of inter-coder reliability as a strength of quantitative content analysis, arguing that, if content analysts do not measure inter-coder reliability, their data are no more reliable than the subjective impressions of a single reader.<sup class=\"reference\" id=\"cite_ref-14\"><a href=\"#cite_note-14\">[14]</a></sup>\n",
      "</p>, <p>There are five types of texts in content analysis:\n",
      "</p>, <p>Content analysis is research using the categorization and classification of speech, written text, interviews, images, or other forms of communication.  In its beginnings, using the first newspapers at the end of the 19th century, analysis was done manually by measuring the number of columns given a subject. The approach can also be traced back to a university student studying patterns in Shakespeare's literature in 1893.<sup class=\"reference\" id=\"cite_ref-15\"><a href=\"#cite_note-15\">[15]</a></sup>\n",
      "</p>, <p>Over the years, content analysis has been applied to a variety of scopes. <a href=\"/wiki/Hermeneutics\" title=\"Hermeneutics\">Hermeneutics</a> and <a href=\"/wiki/Philology\" title=\"Philology\">philology</a> have long used content analysis to interpret sacred and profane texts and, in many cases, to attribute texts' <a class=\"mw-redirect\" href=\"/wiki/Authorship\" title=\"Authorship\">authorship</a> and <a href=\"/wiki/Authentication\" title=\"Authentication\">authenticity</a>.<sup class=\"reference\" id=\"cite_ref-Tipaldo_2014_42_3-1\"><a href=\"#cite_note-Tipaldo_2014_42-3\">[3]</a></sup><sup class=\"reference\" id=\"cite_ref-Krippendorff2004_5-2\"><a href=\"#cite_note-Krippendorff2004-5\">[5]</a></sup>\n",
      "</p>, <p>In recent times, particularly with the advent of <a href=\"/wiki/Mass_communication\" title=\"Mass communication\">mass communication</a>, content analysis has known an increasing use to deeply analyze and understand media content and <a class=\"new\" href=\"/w/index.php?title=Media_logic&amp;action=edit&amp;redlink=1\" title=\"Media logic (page does not exist)\">media logic</a>. \n",
      "The political scientist <a href=\"/wiki/Harold_Lasswell\" title=\"Harold Lasswell\">Harold Lasswell</a> formulated the core questions of content analysis in its early-mid 20th-century mainstream version: \"Who says what, to whom, why, to what extent and with what effect?\".<sup class=\"reference\" id=\"cite_ref-16\"><a href=\"#cite_note-16\">[16]</a></sup> The strong emphasis for a quantitative approach started up by Lasswell was finally carried out by another \"father\" of content analysis, <a href=\"/wiki/Bernard_Berelson\" title=\"Bernard Berelson\">Bernard Berelson</a>, who proposed a definition of content analysis which, from this point of view, is emblematic: \"a research technique for the objective, systematic and quantitative description of the manifest content of communication\".<sup class=\"reference\" id=\"cite_ref-Berelson1952_17-0\"><a href=\"#cite_note-Berelson1952-17\">[17]</a></sup>\n",
      "</p>, <p>Quantitative content analysis has enjoyed a renewed popularity in recent years thanks to technological advances and fruitful application in of mass communication and personal communication research. Content analysis of textual <a href=\"/wiki/Big_data\" title=\"Big data\">big data</a> produced by <a href=\"/wiki/New_media\" title=\"New media\">new media</a>, particularly <a href=\"/wiki/Social_media\" title=\"Social media\">social media</a> and <a class=\"mw-redirect\" href=\"/wiki/Mobile_devices\" title=\"Mobile devices\">mobile devices</a> has become popular. These approaches take a simplified view of language that ignores the complexity of semiosis, the process by which meaning is formed out of language. Quantitative content analysts have been criticized for limiting the scope of content analysis to simple counting, and for applying the measurement methodologies of the natural sciences without reflecting critically on their appropriateness to social science.<sup class=\"reference\" id=\"cite_ref-:0_18-0\"><a href=\"#cite_note-:0-18\">[18]</a></sup> Conversely, qualitative content analysts have been criticized for being insufficiently systematic and too impressionistic.<sup class=\"reference\" id=\"cite_ref-:0_18-1\"><a href=\"#cite_note-:0-18\">[18]</a></sup> Krippendorff argues that quantitative and qualitative approaches to content analysis tend to overlap, and that there can be no generalisable conclusion as to which approach is superior.<sup class=\"reference\" id=\"cite_ref-:0_18-2\"><a href=\"#cite_note-:0-18\">[18]</a></sup>\n",
      "</p>, <p>Content analysis can also be described as studying <a href=\"/wiki/Trace_evidence\" title=\"Trace evidence\">traces</a>, which are documents from past times, and artifacts, which are non-linguistic documents. Texts are understood to be produced by communication processes in a broad sense of that phrase—often gaining mean through <a href=\"/wiki/Abductive_reasoning\" title=\"Abductive reasoning\">abduction</a>.<sup class=\"reference\" id=\"cite_ref-Tipaldo_2014_42_3-2\"><a href=\"#cite_note-Tipaldo_2014_42-3\">[3]</a></sup><sup class=\"reference\" id=\"cite_ref-19\"><a href=\"#cite_note-19\">[19]</a></sup>\n",
      "</p>, <p>Manifest content is readily understandable at its face value. Its meaning is direct. Latent content is not as overt, and requires interpretation to uncover the meaning or implication.<sup class=\"reference\" id=\"cite_ref-20\"><a href=\"#cite_note-20\">[20]</a></sup>\n",
      "</p>, <p>Holsti groups fifteen uses of content analysis into three basic <a class=\"mw-redirect\" href=\"/wiki/Categorisation\" title=\"Categorisation\">categories</a>:<sup class=\"reference\" id=\"cite_ref-Holsti1969_21-0\"><a href=\"#cite_note-Holsti1969-21\">[21]</a></sup>\n",
      "</p>, <p>He also places these uses into the context of the basic communication <a href=\"/wiki/Paradigm\" title=\"Paradigm\">paradigm</a>.\n",
      "</p>, <p>The following table shows fifteen uses of content analysis in terms of their general purpose, element of the communication paradigm to which they apply, and the general question they are intended to answer.\n",
      "</p>, <p>As a counterpoint, there are limits to the scope of use for the procedures that characterize content analysis. In particular, if access to the goal of analysis can be obtained by direct means without material interference, then direct measurement techniques yield better data.<sup class=\"reference\" id=\"cite_ref-23\"><a href=\"#cite_note-23\">[23]</a></sup> Thus, while content analysis attempts to quantifiably describe <em>communications</em> whose features are primarily categorical——limited usually to a nominal or ordinal scale——via selected conceptual units (the <em>unitization</em>) which are assigned values (the <em>categorization</em>) for <em>enumeration</em> while monitoring <em>intercoder reliability</em>, if instead the target quantity manifestly is already directly measurable——typically on an interval or ratio scale——especially a continuous physical quantity, then such targets usually are not listed among those needing the \"subjective\" selections and formulations of content analysis.<sup class=\"reference\" id=\"cite_ref-24\"><a href=\"#cite_note-24\">[24]</a></sup><sup class=\"reference\" id=\"cite_ref-25\"><a href=\"#cite_note-25\">[25]</a></sup><sup class=\"reference\" id=\"cite_ref-26\"><a href=\"#cite_note-26\">[26]</a></sup><sup class=\"reference\" id=\"cite_ref-27\"><a href=\"#cite_note-27\">[27]</a></sup><sup class=\"reference\" id=\"cite_ref-28\"><a href=\"#cite_note-28\">[28]</a></sup><sup class=\"reference\" id=\"cite_ref-29\"><a href=\"#cite_note-29\">[29]</a></sup><sup class=\"reference\" id=\"cite_ref-30\"><a href=\"#cite_note-30\">[30]</a></sup><sup class=\"reference\" id=\"cite_ref-31\"><a href=\"#cite_note-31\">[31]</a></sup> For example (from mixed research and clinical application), as medical images <em>communicate</em> diagnostic features to physicians, <a href=\"/wiki/Neuroimaging\" title=\"Neuroimaging\">neuroimaging</a>'s <a href=\"/wiki/Stroke\" title=\"Stroke\">stroke</a> (infarct) volume scale called ASPECTS is <em>unitized</em> as 10 qualitatively delineated (unequal) brain regions in the <a href=\"/wiki/Middle_cerebral_artery\" title=\"Middle cerebral artery\">middle cerebral artery</a> territory, which it <em>categorizes</em> as being at least partly versus not at all infarcted in order to <em>enumerate</em> the latter, with published series often assessing <em>intercoder reliability</em> by <a href=\"/wiki/Cohen%27s_kappa\" title=\"Cohen's kappa\">Cohen's kappa</a>. The foregoing <em>italicized operations</em> impose the uncredited <em>form</em> of content analysis onto an estimation of infarct extent, which instead is easily enough and more accurately measured as a volume directly on the images.<sup class=\"reference\" id=\"cite_ref-32\"><a href=\"#cite_note-32\">[32]</a></sup><sup class=\"reference\" id=\"cite_ref-33\"><a href=\"#cite_note-33\">[33]</a></sup> (\"Accuracy ... is the highest form of reliability.\"<sup class=\"reference\" id=\"cite_ref-34\"><a href=\"#cite_note-34\">[34]</a></sup>) The concomitant clinical assessment, however, by the <a href=\"/wiki/National_Institutes_of_Health_Stroke_Scale\" title=\"National Institutes of Health Stroke Scale\">National Institutes of Health Stroke Scale</a> (NIHSS) or the <a href=\"/wiki/Modified_Rankin_Scale\" title=\"Modified Rankin Scale\">modified Rankin Scale</a> (mRS), retains the necessary form of content analysis. Recognizing potential limits of content analysis across the contents of language and images alike, <a href=\"/wiki/Klaus_Krippendorff\" title=\"Klaus Krippendorff\">Klaus Krippendorff</a> affirms that \"comprehen[sion] ... may ... not conform at all to the process of classification and/or counting by which most content analyses proceed,\"<sup class=\"reference\" id=\"cite_ref-35\"><a href=\"#cite_note-35\">[35]</a></sup> suggesting that content analysis might materially distort a message.\n",
      "</p>, <p>The process of the initial coding scheme or approach to coding is contingent on the particular content analysis approach selected. Through a directed content analysis, the scholars draft a preliminary coding scheme from pre-existing theory or assumptions. While with the conventional content analysis approach, the initial coding scheme developed from the data.\n",
      "</p>, <p>With either approach above, immersing oneself into the data to obtain an overall picture is recommendable for researchers to conduct. Furthermore, identifying a consistent and clear unit of coding is vital, and researchers' choices range from a single word to several paragraphs, from texts to iconic symbols. Last, constructing the relationships between codes by sorting out them within specific categories or themes.<sup class=\"reference\" id=\"cite_ref-36\"><a href=\"#cite_note-36\">[36]</a></sup>\n",
      "</p>, <p><br/>\n",
      "</p>]\n"
     ]
    }
   ],
   "source": [
    "print(contentPTags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another excursion: Why do we use enumerate() here? enumerate() takes a collection, enumerates, and returns an enumate object with both the numbers and the collection. For example, contentPTags (the collection we used here) is comprised of paragraphs. We want the paragraph number of each paragraph. And this is what enumerate() does: it returns the paragraph number and the paragraph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be adding these new texts to our DataFrame `contentParagraphsDF` so we\n",
    "will need to add 2 more columns to keep track of paragraph numbers and sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph-text</th>\n",
       "      <th>source</th>\n",
       "      <th>paragraph-number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Asia \\n</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Middle East\\n</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe\\n</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North America\\n</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Content analysis is the study of documents and...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Practices and philosophies of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Computers are increasingly used in content ana...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Content analysis is best understood as a broad...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The simplest and most objective form of conten...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A further step in analysis is the distinction ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Quantitative content analysis highlights frequ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Siegfried Kracauer provides a critique of quan...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>With the rise of common computing facilities l...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>By having contents of communication available ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Computer-assisted analysis can help with large...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Robert Weber notes: \"To make valid inferences ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>There are five types of texts in content analy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Content analysis is research using the categor...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Over the years, content analysis has been appl...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In recent times, particularly with the advent ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Quantitative content analysis has enjoyed a re...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Content analysis can also be described as stud...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Manifest content is readily understandable at ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Holsti groups fifteen uses of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>He also places these uses into the context of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The following table shows fifteen uses of cont...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>As a counterpoint, there are limits to the sco...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The process of the initial coding scheme or ap...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>With either approach above, immersing oneself ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\\n</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paragraph-text  \\\n",
       "0                                       South Asia \\n   \n",
       "1                                       Middle East\\n   \n",
       "2                                            Europe\\n   \n",
       "3                                     North America\\n   \n",
       "4   Content analysis is the study of documents and...   \n",
       "5   Practices and philosophies of content analysis...   \n",
       "6   Computers are increasingly used in content ana...   \n",
       "7   Content analysis is best understood as a broad...   \n",
       "8   The simplest and most objective form of conten...   \n",
       "9   A further step in analysis is the distinction ...   \n",
       "10  Quantitative content analysis highlights frequ...   \n",
       "11  Siegfried Kracauer provides a critique of quan...   \n",
       "12  With the rise of common computing facilities l...   \n",
       "13  By having contents of communication available ...   \n",
       "14  Computer-assisted analysis can help with large...   \n",
       "15  Robert Weber notes: \"To make valid inferences ...   \n",
       "16  There are five types of texts in content analy...   \n",
       "17  Content analysis is research using the categor...   \n",
       "18  Over the years, content analysis has been appl...   \n",
       "19  In recent times, particularly with the advent ...   \n",
       "20  Quantitative content analysis has enjoyed a re...   \n",
       "21  Content analysis can also be described as stud...   \n",
       "22  Manifest content is readily understandable at ...   \n",
       "23  Holsti groups fifteen uses of content analysis...   \n",
       "24  He also places these uses into the context of ...   \n",
       "25  The following table shows fifteen uses of cont...   \n",
       "26  As a counterpoint, there are limits to the sco...   \n",
       "27  The process of the initial coding scheme or ap...   \n",
       "28  With either approach above, immersing oneself ...   \n",
       "29                                                 \\n   \n",
       "\n",
       "                                            source  paragraph-number  \n",
       "0   https://en.wikipedia.org/wiki/Content_analysis                 0  \n",
       "1   https://en.wikipedia.org/wiki/Content_analysis                 1  \n",
       "2   https://en.wikipedia.org/wiki/Content_analysis                 2  \n",
       "3   https://en.wikipedia.org/wiki/Content_analysis                 3  \n",
       "4   https://en.wikipedia.org/wiki/Content_analysis                 4  \n",
       "5   https://en.wikipedia.org/wiki/Content_analysis                 5  \n",
       "6   https://en.wikipedia.org/wiki/Content_analysis                 6  \n",
       "7   https://en.wikipedia.org/wiki/Content_analysis                 7  \n",
       "8   https://en.wikipedia.org/wiki/Content_analysis                 8  \n",
       "9   https://en.wikipedia.org/wiki/Content_analysis                 9  \n",
       "10  https://en.wikipedia.org/wiki/Content_analysis                10  \n",
       "11  https://en.wikipedia.org/wiki/Content_analysis                11  \n",
       "12  https://en.wikipedia.org/wiki/Content_analysis                12  \n",
       "13  https://en.wikipedia.org/wiki/Content_analysis                13  \n",
       "14  https://en.wikipedia.org/wiki/Content_analysis                14  \n",
       "15  https://en.wikipedia.org/wiki/Content_analysis                15  \n",
       "16  https://en.wikipedia.org/wiki/Content_analysis                16  \n",
       "17  https://en.wikipedia.org/wiki/Content_analysis                17  \n",
       "18  https://en.wikipedia.org/wiki/Content_analysis                18  \n",
       "19  https://en.wikipedia.org/wiki/Content_analysis                19  \n",
       "20  https://en.wikipedia.org/wiki/Content_analysis                20  \n",
       "21  https://en.wikipedia.org/wiki/Content_analysis                21  \n",
       "22  https://en.wikipedia.org/wiki/Content_analysis                22  \n",
       "23  https://en.wikipedia.org/wiki/Content_analysis                23  \n",
       "24  https://en.wikipedia.org/wiki/Content_analysis                24  \n",
       "25  https://en.wikipedia.org/wiki/Content_analysis                25  \n",
       "26  https://en.wikipedia.org/wiki/Content_analysis                26  \n",
       "27  https://en.wikipedia.org/wiki/Content_analysis                27  \n",
       "28  https://en.wikipedia.org/wiki/Content_analysis                28  \n",
       "29  https://en.wikipedia.org/wiki/Content_analysis                29  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contentParagraphsDF['source'] = [wikipedia_content_analysis] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['paragraph-number'] = range(len(contentParagraphsDF['paragraph-text']))\n",
    "\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can add two more columns to our `Dataframe` and define a function to\n",
    "parse\n",
    "each linked page and add its text to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentParagraphsDF['source-paragraph-number'] = [None] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['source-paragraph-text'] = [None] * len(contentParagraphsDF['paragraph-text'])\n",
    "\n",
    "def getTextFromWikiPage(targetURL, sourceParNum, sourceText):\n",
    "    #Make a dict to store data before adding it to the DataFrame\n",
    "    parsDict = {'source' : [], 'paragraph-number' : [], 'paragraph-text' : [], 'source-paragraph-number' : [],  'source-paragraph-text' : []}\n",
    "    #Now we get the page\n",
    "    r = requests.get(targetURL)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    #enumerating gives use the paragraph number\n",
    "    for parNum, pTag in enumerate(soup.body.findAll('p')):\n",
    "        #same regex as before\n",
    "        parsDict['paragraph-text'].append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "        parsDict['paragraph-number'].append(parNum)\n",
    "        parsDict['source'].append(targetURL)\n",
    "        parsDict['source-paragraph-number'].append(sourceParNum)\n",
    "        parsDict['source-paragraph-text'].append(sourceText)\n",
    "    return pandas.DataFrame(parsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run it on our list of link tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for urlTuple in otherPAgeURLS[:3]:\n",
    "    #ignore_index means the indices will not be reset after each append\n",
    "    contentParagraphsDF = contentParagraphsDF.append(getTextFromWikiPage(*urlTuple),ignore_index=True)\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color=\"red\">Exercise 2</font>\n",
    "<font color=\"red\">Construct cells immediately below this that spider webcontent from another site with content relating to your anticipated final project. Specifically, identify urls on a core page, then follow and extract content from them into a pandas `Dataframe`. In addition, demonstrate a *recursive* spider, which follows more than one level of links (i.e., follows links from a site, then follows links on followed sites to new sites, etc.), making sure to define a reasonable endpoint so that you do not wander the web forever :-).</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I continue to investigate the Tujia ethnicity in China, so I want to find more information on the WikiPedia page on Tujia people. The website can be found at https://en.wikipedia.org/wiki/Tujia_people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Depth                     Text  Num on that page  \\\n",
      "0          1           Northern Tujia                 0   \n",
      "1          1                      IPA                 0   \n",
      "2          1                  Chinese                 0   \n",
      "3          1                   pinyin                 0   \n",
      "4          1               population                 0   \n",
      "...      ...                      ...               ...   \n",
      "11365    100  Spanish irregular verbs                35   \n",
      "11366    100                  Italian                35   \n",
      "11367    100            minimal pairs                36   \n",
      "11368    100            orthographies                38   \n",
      "11369    100          syllabification                39   \n",
      "\n",
      "                                                    Link  \n",
      "0           https://en.wikipedia.org/wiki/Tujia_language  \n",
      "1      https://en.wikipedia.org/wiki/International_Ph...  \n",
      "2         https://en.wikipedia.org/wiki/Chinese_language  \n",
      "3                   https://en.wikipedia.org/wiki/Pinyin  \n",
      "4               https://en.wikipedia.org/wiki/Population  \n",
      "...                                                  ...  \n",
      "11365  https://en.wikipedia.org/wiki/Spanish_irregula...  \n",
      "11366     https://en.wikipedia.org/wiki/Italian_language  \n",
      "11367         https://en.wikipedia.org/wiki/Minimal_pair  \n",
      "11368          https://en.wikipedia.org/wiki/Orthography  \n",
      "11369      https://en.wikipedia.org/wiki/Syllabification  \n",
      "\n",
      "[11370 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "\n",
    "wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "r = 'https://en.wikipedia.org/wiki/Tujia_people'\n",
    "\n",
    "# get all links on one page\n",
    "def get_links_one_page(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    contentPTags = soup.body.findAll('p')\n",
    "    otherPAgeURLS = []\n",
    "    for Num, pTag in enumerate(contentPTags):\n",
    "        tagLinks = pTag.findAll('a', href=re.compile('/wiki/'), class_=False)\n",
    "        for aTag in tagLinks:\n",
    "            relurl = aTag.get('href')\n",
    "            linkText = aTag.text\n",
    "            otherPAgeURLS.append((\n",
    "            urllib.parse.urljoin(wikipedia_base_url, relurl),\n",
    "            Num,\n",
    "            linkText,\n",
    "        ))\n",
    "    return otherPAgeURLS\n",
    "\n",
    "# make our crawler recursive\n",
    "def get_all_links(num_pages_to_crawl, starting_url):\n",
    "    links_todo = [starting_url]\n",
    "    links_visited = []\n",
    "    res_list = []\n",
    "    while len(links_todo) != 0:\n",
    "        url_to_visit = links_todo.pop(0)\n",
    "        links_visited.append(url_to_visit)\n",
    "        new_links = get_links_one_page(url_to_visit)\n",
    "        res_list.append(new_links)\n",
    "        if new_links:\n",
    "            for link, Num, linkText in new_links:\n",
    "                if link not in links_todo:\n",
    "                    links_todo.append(link)\n",
    "            if len(links_visited) == num_pages_to_crawl:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "    return res_list\n",
    "\n",
    "# make the results save in pd dataframe\n",
    "def write_to_dataframe(res_list):\n",
    "    new_dic = {'Depth': [], 'Text': [], 'Num on that page': [], 'Link': []}\n",
    "    for num_page, lst in enumerate(res_list):\n",
    "        for link, num, text in lst:\n",
    "            new_dic['Depth'].append(num_page+1)\n",
    "            new_dic['Text'].append(text)\n",
    "            new_dic['Num on that page'].append(num)\n",
    "            new_dic['Link'].append(link)\n",
    "    resPD = pd.DataFrame(new_dic)\n",
    "    return print(resPD)\n",
    "\n",
    "# here I set the number of pages to crawl as 100. This may take around 2min. \n",
    "write_to_dataframe(get_all_links(100, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API (Tumblr)\n",
    "\n",
    "Generally website owners do not like you scraping their sites. If done badly,\n",
    "scarping can act like a DOS attack so you should be careful how often you make\n",
    "calls to a site. Some sites want automated tools to access their data, so they\n",
    "create [application programming interface\n",
    "(APIs)](https://en.wikipedia.org/wiki/Application_programming_interface). An API\n",
    "specifies a procedure for an application (or script) to access their data. Often\n",
    "this is though a [representational state transfer\n",
    "(REST)](https://en.wikipedia.org/wiki/Representational_state_transfer) web\n",
    "service, which just means if you make correctly formatted HTTP requests they\n",
    "will return nicely formatted data.\n",
    "\n",
    "A nice example for us to study is [Tumblr](https://www.tumblr.com), they have a\n",
    "[simple RESTful API](https://www.tumblr.com/docs/en/api/v1) that allows you to\n",
    "read posts without any complicated html parsing.\n",
    "\n",
    "We can get the first 20 posts from a blog by making an http GET request to\n",
    "`'http://{blog}.tumblr.com/api/read/json'`, were `{blog}` is the name of the\n",
    "target blog. Lets try and get the posts from [http://lolcats-lol-\n",
    "cat.tumblr.com/](http://lolcats-lol-cat.tumblr.com/) (Note the blog says at the\n",
    "top 'One hour one pic lolcats', but the canonical name that Tumblr uses is in\n",
    "the URL 'lolcats-lol-cat')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var tumblr_api_read = {\"tumblelog\":{\"title\":\"One hour one pic lolcats\",\"description\":\"\",\"name\":\"lolcats-lol-cat\",\"timezone\":\"Europe\\/Paris\",\"cname\":false,\"feeds\":[]},\"posts-start\":0,\"posts-total\":3925,\"posts-type\":false,\"posts\":[{\"id\":\"662815854023655425\",\"url\":\"https:\\/\\/lolcats-lol-cat.tumblr.com\\/post\\/662815854023655425\",\"url-with-slug\":\"https:\\/\\/lolcats-lol-cat.tumblr.com\\/post\\/662815854023655425\",\"type\":\"photo\",\"date-gmt\":\"2021-09-20 04:00:56 GMT\",\"date\":\"Mon, 20 Sep 2021 06:00:56\",\"bookmarklet\":0,\"mobile\":0,\"feed-item\":\"\",\"from-feed-id\":0,\"unix-timestamp\":1632110456,\"format\":\"html\",\"reblog-key\":\"kjH8cg34\",\"slug\":\"\",\"is-submission\":false,\"like-button\":\"<div class=\\\"like_button\\\" data-post-id=\\\"662815854023655425\\\" data-blog-name=\\\"lolcats-lol-cat\\\" id=\\\"like_button_662815854023655425\\\"><iframe id=\\\"like_iframe_662815854023655425\\\" src=\\\"https:\\/\\/assets.tumblr.com\\/assets\\/html\\/like_iframe.html?_v=66c22ab5319d742bca5762b8d18f9d06#name=lolcats-lol-cat&amp;post_id=66281585402365\n"
     ]
    }
   ],
   "source": [
    "tumblrAPItarget = 'http://{}.tumblr.com/api/read/json'\n",
    "\n",
    "r = requests.get(tumblrAPItarget.format('lolcats-lol-cat'))\n",
    "\n",
    "print(r.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might not look very good on first inspection, but it has far fewer angle\n",
    "braces than html, which makes it easier to parse. What we have is\n",
    "[JSON](https://en.wikipedia.org/wiki/JSON) a 'human readable' text based data\n",
    "transmission format based on javascript. Luckily, we can readily convert it to a\n",
    "python `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tumblelog', 'posts-start', 'posts-total', 'posts-type', 'posts'])\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#We need to load only the stuff between the curly braces\n",
    "d = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "print(d.keys())\n",
    "print(len(d['posts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we read the [API specification](https://www.tumblr.com/docs/en/api/v1), we\n",
    "will see there are a lot of things we can get if we add things to our GET\n",
    "request. First we can retrieve posts by their id number. Let's first get post\n",
    "`146020177084`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(tumblrAPItarget.format('lolcats-lol-cat'), params = {'id' : 146020177084})\n",
    "d = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "d['posts'][0].keys()\n",
    "d['posts'][0]['photo-url-1280']\n",
    "\n",
    "with open('lolcat.gif', 'wb') as f:\n",
    "    gifRequest = requests.get(d['posts'][0]['photo-url-1280'], stream = True)\n",
    "    f.write(gifRequest.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lolcat.gif'>\n",
    "\n",
    "Such beauty; such vigor (If you can't see it you have to refresh the page). Now\n",
    "we could retrieve the text from all posts as well\n",
    "as related metadata, like the post date, caption or tags. We could also get\n",
    "links to all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting a max in case the blog has millions of images\n",
    "#The given max will be rounded up to the nearest multiple of 50\n",
    "def tumblrImageScrape(blogName, maxImages = 200):\n",
    "    #Restating this here so the function isn't dependent on any external variables\n",
    "    tumblrAPItarget = 'http://{}.tumblr.com/api/read/json'\n",
    "\n",
    "    #There are a bunch of possible locations for the photo url\n",
    "    possiblePhotoSuffixes = [1280, 500, 400, 250, 100]\n",
    "\n",
    "    #These are the pieces of information we will be gathering,\n",
    "    #at the end we will convert this to a DataFrame.\n",
    "    #There are a few other datums we could gather like the captions\n",
    "    #you can read the Tumblr documentation to learn how to get them\n",
    "    #https://www.tumblr.com/docs/en/api/v1\n",
    "    postsData = {\n",
    "        'id' : [],\n",
    "        'photo-url' : [],\n",
    "        'date' : [],\n",
    "        'tags' : [],\n",
    "        'photo-type' : []\n",
    "    }\n",
    "\n",
    "    #Tumblr limits us to a max of 50 posts per request\n",
    "    for requestNum in range(maxImages // 50):\n",
    "        requestParams = {\n",
    "            'start' : requestNum * 50,\n",
    "            'num' : 50,\n",
    "            'type' : 'photo'\n",
    "        }\n",
    "        r = requests.get(tumblrAPItarget.format(blogName), params = requestParams)\n",
    "        requestDict = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "        for postDict in requestDict['posts']:\n",
    "            #We are dealing with uncleaned data, we can't trust it.\n",
    "            #Specifically, not all posts are guaranteed to have the fields we want\n",
    "            try:\n",
    "                postsData['id'].append(postDict['id'])\n",
    "                postsData['date'].append(postDict['date'])\n",
    "                postsData['tags'].append(postDict['tags'])\n",
    "            except KeyError as e:\n",
    "                raise KeyError(\"Post {} from {} is missing: {}\".format(postDict['id'], blogName, e))\n",
    "\n",
    "            foundSuffix = False\n",
    "            for suffix in possiblePhotoSuffixes:\n",
    "                try:\n",
    "                    photoURL = postDict['photo-url-{}'.format(suffix)]\n",
    "                    postsData['photo-url'].append(photoURL)\n",
    "                    postsData['photo-type'].append(photoURL.split('.')[-1])\n",
    "                    foundSuffix = True\n",
    "                    break\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if not foundSuffix:\n",
    "                #Make sure your error messages are useful\n",
    "                #You will be one of the users\n",
    "                raise KeyError(\"Post {} from {} is missing a photo url\".format(postDict['id'], blogName))\n",
    "\n",
    "    return pandas.DataFrame(postsData)\n",
    "tumblrImageScrape('lolcats-lol-cat', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the urls of a bunch of images and can run OCR on them to gather\n",
    "compelling meme narratives, accompanied by cats.\n",
    "\n",
    "# Files\n",
    "\n",
    "What if the text we want isn't on a webpage? There are a many other sources of\n",
    "text available, typically organized into *files*.\n",
    "\n",
    "## Raw text (and encoding)\n",
    "\n",
    "The most basic form of storing text is as a _raw text_ document. Source code\n",
    "(`.py`, `.r`, etc) is usually raw text as are text files (`.txt`) and those with\n",
    "many other extension (e.g., .csv, .dat, etc.). Opening an unknown file with a\n",
    "text editor is often a great way of learning what the file is.\n",
    "\n",
    "We can create a text file in python with the `open()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_text_file = 'sometextfile.txt'\n",
    "#stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols \\u2421 \\u241B \\u20A0 \\u20A1 \\u20A2 \\u20A3 \\u0D60\\n'\n",
    "stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols ␡ ␛ ₠ ₡ ₢ ₣ ൠ\\n'\n",
    "\n",
    "with open(example_text_file, mode = 'w', encoding='utf-8') as f:\n",
    "    f.write(stringToWrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `encoding='utf-8'` argument, which specifies how we map the bits from\n",
    "the file to the glyphs (and whitespace characters like tab (`'\\t'`) or newline\n",
    "(`'\\n'`)) on the screen. When dealing only with latin letters, arabic numerals\n",
    "and the other symbols on America keyboards you usually do not have to worry\n",
    "about encodings as the ones used today are backwards compatible with\n",
    "[ASCII](https://en.wikipedia.org/wiki/ASCII), which gives the binary\n",
    "representation of 128 characters.\n",
    "\n",
    "Some of you, however, will want to use other characters (e.g., Chinese\n",
    "characters). To solve this there is\n",
    "[Unicode](https://en.wikipedia.org/wiki/Unicode) which assigns numbers to\n",
    "symbols, e.g., 041 is `'A'` and 03A3 is `'Σ'` (numbers starting with 0 are\n",
    "hexadecimal). Often non/beyond-ASCII characters are called Unicode characters.\n",
    "Unicode contains 1,114,112 characters, about 10\\% of which have been assigned.\n",
    "Unfortunately there are many ways used to map combinations of bits to Unicode\n",
    "symbols. The ones you are likely to encounter are called by Python _utf-8_,\n",
    "_utf-16_ and _latin-1_. _utf-8_ is the standard for Linux and Mac OS while both\n",
    "_utf-16_ and _latin-1_ are used by windows. If you use the wrong encoding,\n",
    "characters can appear wrong, sometimes change in number or Python could raise an\n",
    "exception. Lets see what happens when we open the file we just created with\n",
    "different encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(example_text_file, encoding='utf-8') as f:\n",
    "    print(\"This is with the correct encoding:\")\n",
    "    print(f.read())\n",
    "\n",
    "with open(example_text_file, encoding='latin-1') as f:\n",
    "    print(\"This is with the wrong encoding:\")\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with _latin-1_ the unicode characters are mixed up and there are too\n",
    "many of them. You need to keep in mind encoding when obtaining text files.\n",
    "Determining the encoding can sometime involve substantial work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load many text files at once. Lets start by looking at the Shakespeare files in the `data` directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", and Train.]\n",
      "\n",
      "PUCK\n",
      "  If we shadows have offended,\n",
      "  Think but this,--and all is mended,--\n",
      "  That you have but slumber'd here\n",
      "  While these visions did appear.\n",
      "  And this weak and idle theme,\n",
      "  No more yielding but a dream,\n",
      "  Gentles, do not reprehend;\n",
      "  If you pardon, we will mend.\n",
      "  And, as I am an honest Puck,\n",
      "  If we have unearned luck\n",
      "  Now to 'scape the serpent's tongue,\n",
      "  We will make amends ere long;\n",
      "  Else the Puck a liar call:\n",
      "  So, good night unto you all.\n",
      "  Give me your hands, if we be friends,\n",
      "  And Robin shall restore amends.\n",
      "\n",
      "[Exit.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End of Project Gutenberg Etext of A Midsummer Night's Dream by Shakespeare\n",
      "PG has multiple editions of William Shakespeare's Complete Works\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/Shakespeare/midsummer_nights_dream.txt') as f:\n",
    "    midsummer = f.read()\n",
    "print(midsummer[-700:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, depending on your working directory, you might get errors such as: [Errno 2] No such file or directory: '../data/Shakespeare/midsummer_nights_dream.txt.' Don't panic, it's nothing, just check your working directory. \n",
    "\n",
    "Then to load all the files in `./data/Shakespeare` we can use a for loop with `scandir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDir = '../data/Shakespeare' #Change this to your own directory of texts\n",
    "shakespearText = []\n",
    "shakespearFileName = []\n",
    "\n",
    "for file in (file for file in os.scandir(targetDir) if file.is_file() and not file.name.startswith('.')):\n",
    "    with open(file.path, encoding=\"utf-8\") as f:\n",
    "        shakespearText.append(f.read())\n",
    "    shakespearFileName.append(file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can put them all in pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>julius_caesar.txt</th>\n",
       "      <td>Dramatis Personae\\n\\n  JULIUS CAESAR, Roman st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as_you_like_it.txt</th>\n",
       "      <td>AS YOU LIKE IT\\n\\nby William Shakespeare\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempest.txt</th>\n",
       "      <td>The Tempest\\n\\nActus primus, Scena prima.\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phoenix_and_the_turtle.txt</th>\n",
       "      <td>THE PHOENIX AND THE TURTLE\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_lear.txt</th>\n",
       "      <td>The Tragedie of King Lear\\n\\n\\nActus Primus. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passionate_pilgrim.txt</th>\n",
       "      <td>THE PASSIONATE PILGRIM\\n\\nby William Shakespea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cymbeline.txt</th>\n",
       "      <td>The Tragedie of Cymbeline\\n\\nActus Primus. Sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coriolanus.txt</th>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS\\n\\nby William Shakes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two_gentlemen_of_verona.txt</th>\n",
       "      <td>THE TWO GENTLEMEN OF VERONA\\n\\nby William Shak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rape_of_lucrece.txt</th>\n",
       "      <td>THE RAPE OF LUCRECE\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_8.txt</th>\n",
       "      <td>KING HENRY THE EIGHTH\\n\\nby William Shakespear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romeo_and_juliet.txt</th>\n",
       "      <td>ROMEO AND JULIET\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_of_venice.txt</th>\n",
       "      <td>The Merchant of Venice\\n\\nActus primus.\\n\\nEnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonnets.txt</th>\n",
       "      <td>THE SONNETS\\n\\nby William Shakespeare\\n\\n\\n\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthonie_and_cleopatra.txt</th>\n",
       "      <td>The Tragedie of Anthonie, and Cleopatra\\n\\nAct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merry_wives_of_windsor.txt</th>\n",
       "      <td>THE MERRY WIVES OF WINDSOR\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>othello.txt</th>\n",
       "      <td>THE TRAGEDY OF OTHELLO, MOOR OF VENICE\\n\\nby W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much_ado_about_nothing.txt</th>\n",
       "      <td>MUCH ADO ABOUT NOTHING\\n\\nby William Shakspere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taming_of_the_shrew.txt</th>\n",
       "      <td>THE TAMING OF THE SHREW\\n\\nby William Shakespe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winters_tale.txt</th>\n",
       "      <td>THE WINTER'S TALE\\n\\nby William Shakespeare\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pericles_prince_of_tyre.txt</th>\n",
       "      <td>PERICLES PRINCE OF TYRE\\n\\nby William Shakespe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy_of_errors.txt</th>\n",
       "      <td>DRAMATIS PERSONAE\\n\\nSOLINUS, Duke of Ephesus\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_4_p1.txt</th>\n",
       "      <td>The First Part of Henry the Fourth\\n\\nwith the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_4_p2.txt</th>\n",
       "      <td>KING HENRY IV, SECOND PART\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timon_of_athens.txt</th>\n",
       "      <td>THE LIFE OF TIMON OF ATHENS\\n\\nby William Shak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p2.txt</th>\n",
       "      <td>The second Part of Henry the Sixt\\n\\nwith the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alls_well_that_ends_well.txt</th>\n",
       "      <td>All's Well, that Ends Well\\n\\nActus primus. Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p3.txt</th>\n",
       "      <td>The third Part of Henry the Sixt\\n\\nwith the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p1.txt</th>\n",
       "      <td>Dramatis Personae\\n\\nKING HENRY the Sixth\\nDUK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovers_complaint.txt</th>\n",
       "      <td>A LOVER'S COMPLAINT\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titus_andronicus.txt</th>\n",
       "      <td>The Tragedie of Titus Andronicus\\n\\nActus Prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twelth_night.txt</th>\n",
       "      <td>TWELFTH NIGHT;\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loves_labors_lost.txt</th>\n",
       "      <td>LOVE'S LABOUR'S LOST\\n\\nby William Shakespeare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>midsummer_nights_dream.txt</th>\n",
       "      <td>A MIDSUMMER NIGHT'S DREAM\\n\\nby William Shakes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_5.txt</th>\n",
       "      <td>THE LIFE OF KING HENRY THE FIFTH\\n\\nby William...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_john.txt</th>\n",
       "      <td>The life and death of King John\\n\\nActus Primu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macbeth.txt</th>\n",
       "      <td>MACBETH\\n\\nby William Shakespeare\\n\\n\\n\\n\\nPer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>troilus_and_cressida.txt</th>\n",
       "      <td>THE HISTORY OF TROILUS AND CRESSIDA\\n\\nby Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venus_and_adonis.txt</th>\n",
       "      <td>VENUS AND ADONIS\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure_for_measure.txt</th>\n",
       "      <td>MEASURE FOR MEASURE\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamlet.txt</th>\n",
       "      <td>The Tragedie of Hamlet\\n\\nActus Primus. Scoena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_richard_2.txt</th>\n",
       "      <td>DRAMATIS PERSONAE\\n\\n  KING RICHARD THE SECOND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_richard_3.txt</th>\n",
       "      <td>KING RICHARD III\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           text\n",
       "julius_caesar.txt             Dramatis Personae\\n\\n  JULIUS CAESAR, Roman st...\n",
       "as_you_like_it.txt            AS YOU LIKE IT\\n\\nby William Shakespeare\\n\\n\\n...\n",
       "tempest.txt                   The Tempest\\n\\nActus primus, Scena prima.\\n\\nA...\n",
       "phoenix_and_the_turtle.txt    THE PHOENIX AND THE TURTLE\\n\\nby William Shake...\n",
       "king_lear.txt                 The Tragedie of King Lear\\n\\n\\nActus Primus. S...\n",
       "passionate_pilgrim.txt        THE PASSIONATE PILGRIM\\n\\nby William Shakespea...\n",
       "cymbeline.txt                 The Tragedie of Cymbeline\\n\\nActus Primus. Sco...\n",
       "coriolanus.txt                THE TRAGEDY OF CORIOLANUS\\n\\nby William Shakes...\n",
       "two_gentlemen_of_verona.txt   THE TWO GENTLEMEN OF VERONA\\n\\nby William Shak...\n",
       "rape_of_lucrece.txt           THE RAPE OF LUCRECE\\n\\nby William Shakespeare\\...\n",
       "king_henry_8.txt              KING HENRY THE EIGHTH\\n\\nby William Shakespear...\n",
       "romeo_and_juliet.txt          ROMEO AND JULIET\\n\\nby William Shakespeare\\n\\n...\n",
       "merchant_of_venice.txt        The Merchant of Venice\\n\\nActus primus.\\n\\nEnt...\n",
       "sonnets.txt                   THE SONNETS\\n\\nby William Shakespeare\\n\\n\\n\\n ...\n",
       "anthonie_and_cleopatra.txt    The Tragedie of Anthonie, and Cleopatra\\n\\nAct...\n",
       "merry_wives_of_windsor.txt    THE MERRY WIVES OF WINDSOR\\n\\nby William Shake...\n",
       "othello.txt                   THE TRAGEDY OF OTHELLO, MOOR OF VENICE\\n\\nby W...\n",
       "much_ado_about_nothing.txt    MUCH ADO ABOUT NOTHING\\n\\nby William Shakspere...\n",
       "taming_of_the_shrew.txt       THE TAMING OF THE SHREW\\n\\nby William Shakespe...\n",
       "winters_tale.txt              THE WINTER'S TALE\\n\\nby William Shakespeare\\n\\...\n",
       "pericles_prince_of_tyre.txt   PERICLES PRINCE OF TYRE\\n\\nby William Shakespe...\n",
       "comedy_of_errors.txt          DRAMATIS PERSONAE\\n\\nSOLINUS, Duke of Ephesus\\...\n",
       "king_henry_4_p1.txt           The First Part of Henry the Fourth\\n\\nwith the...\n",
       "king_henry_4_p2.txt           KING HENRY IV, SECOND PART\\n\\nby William Shake...\n",
       "timon_of_athens.txt           THE LIFE OF TIMON OF ATHENS\\n\\nby William Shak...\n",
       "king_henry_6_p2.txt           The second Part of Henry the Sixt\\n\\nwith the ...\n",
       "alls_well_that_ends_well.txt  All's Well, that Ends Well\\n\\nActus primus. Sc...\n",
       "king_henry_6_p3.txt           The third Part of Henry the Sixt\\n\\nwith the d...\n",
       "king_henry_6_p1.txt           Dramatis Personae\\n\\nKING HENRY the Sixth\\nDUK...\n",
       "lovers_complaint.txt          A LOVER'S COMPLAINT\\n\\nby William Shakespeare\\...\n",
       "titus_andronicus.txt          The Tragedie of Titus Andronicus\\n\\nActus Prim...\n",
       "twelth_night.txt                                           TWELFTH NIGHT;\\n ...\n",
       "loves_labors_lost.txt         LOVE'S LABOUR'S LOST\\n\\nby William Shakespeare...\n",
       "midsummer_nights_dream.txt    A MIDSUMMER NIGHT'S DREAM\\n\\nby William Shakes...\n",
       "king_henry_5.txt              THE LIFE OF KING HENRY THE FIFTH\\n\\nby William...\n",
       "king_john.txt                 The life and death of King John\\n\\nActus Primu...\n",
       "macbeth.txt                   MACBETH\\n\\nby William Shakespeare\\n\\n\\n\\n\\nPer...\n",
       "troilus_and_cressida.txt      THE HISTORY OF TROILUS AND CRESSIDA\\n\\nby Will...\n",
       "venus_and_adonis.txt          VENUS AND ADONIS\\n\\nby William Shakespeare\\n\\n...\n",
       "measure_for_measure.txt       MEASURE FOR MEASURE\\n\\nby William Shakespeare\\...\n",
       "hamlet.txt                    The Tragedie of Hamlet\\n\\nActus Primus. Scoena...\n",
       "king_richard_2.txt            DRAMATIS PERSONAE\\n\\n  KING RICHARD THE SECOND...\n",
       "king_richard_3.txt            KING RICHARD III\\n\\nby William Shakespeare\\n\\n..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespear_df = pandas.DataFrame({'text' : shakespearText}, index = shakespearFileName)\n",
    "shakespear_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting your text in a format like this is the first step of most analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF\n",
    "\n",
    "Another common way text will be stored is in a PDF file. First we will download\n",
    "a pdf in Python. To do that lets grab a chapter from\n",
    "_Speech and Language Processing_, chapter 21 is on Information Extraction which\n",
    "seems apt. It is stored as a pdf at [https://web.stanford.edu/~jurafsky/slp3/21.\n",
    "pdf](https://web.stanford.edu/~jurafsky/slp3/21.pdf) although we are downloading\n",
    "from a copy just in case Jurafsky changes their website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%PDF-1.3\n",
      "%���������\n",
      "4 0 obj\n",
      "<< /Length 5 0 R /Filter /FlateDecode >>\n",
      "stream\n",
      "x\u0001�]۶�F�}�W�c����T���\u0017C\u000f�i�\u0019<t\u001f�b\u0001\u000fM�f\n",
      "Tn�\u0006<3_�\u000b",
      "�CDf�\u001d",
      "�J�N�i�\u000f�#�%.;.\u0019���\t?\u000f߄��7�]8������ux��}\u001b޾\u000fm����y��bǾ���\u0010�!\u001c",
      "\u000e���$�Ǯ���C�\u0007�F\u0006�����p�\u000f��5��1��1�P<�{�\u0010$�\u001a�/$�P�\f",
      "s�v��P\u001e",
      "gH?�����Q�~�*�:l��ˇ�m�ǰ��C�l����܊\u0017��E��\u001e",
      "���\u000f!�^�y��\u001am�$�Ý���wۡل׼�6w���ī�K�~؞���r��\u0010~\u001b\u001e",
      "?�ˡkO�;6IH�9{ԡ���\u0000]?�E�E�\u0012�~���.l������+��\u001c",
      "W�\u000e\u0002_�\u000e��\u0002\u0002��C��S�|�~\u0005C��N�3ӛB`8�ޚ\b\u0001j9���AZ�\u0004�\u00110�d�l^�\u000e�����SY\u0012\t�Ƨ��>\u000b",
      "q�ۇ&\n",
      "����.�����0���\u0015�;\u0000��>a8�$\f",
      "w�p��p����ST���\u000b",
      ".\u0000�7��@�\u0012���)�\u0013�&1�|���\u0002\u0004WՃ jOv�G2b�L8I��N�@\u0001\u001e",
      "gǍ�\u0004����\u0019�O�C��������IN@@���\u0002��\u0013}�8��+L����a�\u0005&ү\b�o\u0005\u0013�V(\u0019���0\f",
      "���+5\u001b�\n",
      "S\u001d",
      "fS&��<�2���\u001e",
      "��>l�V��&��=4⇤\u0019=\u001a�W��<�J\u0013Mo�\u001c",
      "���\"����d�C����[vY�|K\u001c",
      "{_ܔ\\��\u0017��%\u0001H�/@'�QA�+D�l��c��L�G�.��\t�̎�V�:f>���Aw\u0010K���o$`D\u0007��\u000b",
      "bE45�\u000b",
      "0\b�\u0015%th6h��\u0005���>*�2vQd\u0010\u0015�+M��Y}�Q���u�[���N�o'b\u0010��/u�.r'Z�\u0017��J�\u0019e8�v\u0013\u000b",
      "��;�\u001d",
      "�{T�\t\f",
      "�����^8�\u0014 \u001a\u0018 l<�E�<���b�����C8\f",
      "j��f��xB>\u0001K\u0010���\u0019��|\u001f\u0004w��f�|?�\u0001s̭\u0018��Y�'�Ip&�\"�\u000b",
      "A���f�?�\b!IYi���U�\"��y;�\u0007��#�\u000b",
      "\u000f�e3)�+B�&���\u001d",
      "�<\bE9I�g�/]\"D��yfC;e����Y^�z ��s'�)/�X�-HY��<ˬ�ݰ\n"
     ]
    }
   ],
   "source": [
    "#information_extraction_pdf = 'https://github.com/KnowledgeLab/content_analysis/raw/data/21.pdf'\n",
    "\n",
    "infoExtractionRequest = requests.get(information_extraction_pdf, stream=True)\n",
    "print(infoExtractionRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It says `'pdf'`, so thats a good sign. The rest though looks like we are having\n",
    "issues with an encoding. The random characters are not caused by our encoding\n",
    "being wrong, however. They are cause by there not being an encoding for those\n",
    "parts at all. PDFs are nominally binary files, meaning there are sections of\n",
    "binary that are specific to pdf and nothing else so you need something that\n",
    "knows about pdf to read them. To do that we will be using\n",
    "[`PyPDF2`](https://github.com/mstamy2/PyPDF2), a PDF processing library for\n",
    "Python 3.\n",
    "\n",
    "\n",
    "Because PDFs are a very complicated file format pdfminer requires a large amount\n",
    "of boilerplate code to extract text, we have written a function that takes in an\n",
    "open PDF file and returns the text so you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPDF(pdfFile):\n",
    "    #Based on code from http://stackoverflow.com/a/20905381/4955164\n",
    "    #Using utf-8, if there are a bunch of random symbols try changing this\n",
    "    codec = 'utf-8'\n",
    "    rsrcmgr = pdfminer.pdfinterp.PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    layoutParams = pdfminer.layout.LAParams()\n",
    "    device = pdfminer.converter.TextConverter(rsrcmgr, retstr, laparams = layoutParams, codec = codec)\n",
    "    #We need a device and an interpreter\n",
    "    interpreter = pdfminer.pdfinterp.PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = ''\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "    for page in pdfminer.pdfpage.PDFPage.get_pages(pdfFile, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    device.close()\n",
    "    returnedString = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    return returnedString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to take the response object and convert it into a 'file like'\n",
    "object so that pdfminer can read it. To do this we will use `io`'s `BytesIO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoExtractionBytes = io.BytesIO(infoExtractionRequest.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can give it to pdfminer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department of  Sociology \n",
      "\n",
      "THE UNIVERSITY OF CHICAGO \n",
      "\n",
      "SOCIOLOGY 40133 \n",
      "\n",
      "Computational Content Analysis \n",
      "\n",
      "Friday 1:00 – 3:50pm \n",
      "Winter 2017-2018 \n",
      "Classroom: Harper Memorial 130       \n",
      "http://chalk.uchicago.edu/ \n",
      "\n",
      " \n",
      "\n",
      "                                                                                           \n",
      "\n",
      "          Office: McGiffert 210 \n",
      "                                                    Tel.: 834-3612; jevans@uchicago.edu \n",
      "                                  Office Hours: Thursday 12:30-2:30pm \n",
      "\n",
      "     \n",
      "\n",
      "        James A. Evans            \n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(readPDF(infoExtractionBytes)[:550])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can either look at the full text or fiddle with our PDF reader and\n",
    "get more information about individual blocks of text.\n",
    "\n",
    "## Word Docs\n",
    "\n",
    "The other type of document you are likely to encounter is the `.docx`, these are\n",
    "actually a version of [XML](https://en.wikipedia.org/wiki/Office_Open_XML), just\n",
    "like HTML, and like HTML we will use a specialized parser.\n",
    "\n",
    "For this class we will use [`python-docx`](https://python-\n",
    "docx.readthedocs.io/en/latest/) which provides a nice simple interface for\n",
    "reading `.docx` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "\n",
      "Accessing the Research Computing Center Resources\n",
      "\n",
      "To connect to the midway compute cluster to access your home directory and the macs60000 storage space, and utilize the HPC resources, you will either use a terminal client (with or without X11 forwarding capabilities) or the Linux remote desktop server software client (Thinlinc) to connect to the midway cluster. To submit jobs, monitor jobs, browse directories or do other computing you will need to connect through either the terminal or remote desktop. Setup and utilization of these clients will be discussed below in the context of your local platform’s architecture.\n",
      "SSH Client Setup & Remote Desktop Server\n"
     ]
    }
   ],
   "source": [
    "#example_docx = 'https://github.com/KnowledgeLab/content_analysis/raw/data/example_doc.docx'\n",
    "\n",
    "r = requests.get(example_docx, stream=True)\n",
    "d = docx.Document(io.BytesIO(r.content))\n",
    "for paragraph in d.paragraphs[:7]:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This procedure uses the `io.BytesIO` class again, since `docx.Document` expects\n",
    "a file. Another way to do it is to save the document to a file and then read it\n",
    "like any other file. If we do this we can either delete the file afterwords, or\n",
    "save it and avoid downloading the following time.\n",
    "\n",
    "This function is useful as a part of many different tasks so it and others like it will be added to the helper package `lucem_illud` so we can use it later without having to retype it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadIfNeeded(targetURL, outputFile, **openkwargs):\n",
    "    if not os.path.isfile(outputFile):\n",
    "        outputDir = os.path.dirname(outputFile)\n",
    "        #This function is a more general os.mkdir()\n",
    "        if len(outputDir) > 0:\n",
    "            os.makedirs(outputDir, exist_ok = True)\n",
    "        r = requests.get(targetURL, stream=True)\n",
    "        #Using a closure like this is generally better than having to\n",
    "        #remember to close the file. There are ways to make this function\n",
    "        #work as a closure too\n",
    "        with open(outputFile, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    return open(outputFile, **openkwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will download, save and open `outputFile` as `outputFile` or just\n",
    "open it if `outputFile` exists. By default `open()` will open the file as read\n",
    "only text with the local encoding, which may cause issues if its not a text\n",
    "file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is not a zip file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    d = docx.Document(downloadIfNeeded(example_docx, example_docx_save))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell `open()` to read in binary mode (`'rb'`), this is why we added\n",
    "`**openkwargs`, this allows us to pass any keyword arguments (kwargs) from\n",
    "`downloadIfNeeded` to `open()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "\n",
      "Accessing the Research Computing Center Resources\n",
      "\n",
      "To connect to the midway compute cluster to access your home directory and the macs60000 storage space, and utilize the HPC resources, you will either use a terminal client (with or without X11 forwarding capabilities) or the Linux remote desktop server software client (Thinlinc) to connect to the midway cluster. To submit jobs, monitor jobs, browse directories or do other computing you will need to connect through either the terminal or remote desktop. Setup and utilization of these clients will be discussed below in the context of your local platform’s architecture.\n",
      "SSH Client Setup & Remote Desktop Server\n"
     ]
    }
   ],
   "source": [
    "d = docx.Document(downloadIfNeeded(example_docx, example_docx_save, mode = 'rb'))\n",
    "for paragraph in d.paragraphs[:7]:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read the file with `docx.Document` and not have to wait for it to be\n",
    "downloaded every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Exercise 3</font>\n",
    "<font color=\"red\">Construct cells immediately below this that extract and organize textual content from text, PDF or Word into a pandas dataframe.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font>For this exercise, I want to scrape the text from an online pdf file which introduces the  Tujia  heritage in China. The pdf can be found at https://www.tilburguniversity.edu/sites/default/files/download/TPCS_169_Wang-Kroon_2.pdf. </font>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Paper   \n",
      "\n",
      "The chronotopes of authenticity: \n",
      "\n",
      "Designing the Tujia heritage in China  \n",
      "\n",
      " \n",
      " \n",
      "by \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "Xuan Wang© and Sjaak Kroon © (Tilburg University) \n",
      "\n",
      " \n",
      "\n",
      "x.wang@tilburguniversity.edu \n",
      "\n",
      "s.kroon@tilburguniversity.edu \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "August 2016 \n",
      "\n",
      "This work is licensed under a  \n",
      "Creative Commons Attribution-NoDerivatives 4.0 International License.  \n",
      "To view a copy of this license, visit http://creativecommons.org/licenses/by-nd/4.0/  \n",
      "\n",
      "\f",
      "The Chronotopes of Authenticity: Designing the Tujia Heritage in \n",
      "\n",
      "China \n",
      "\n",
      " \n",
      "\n",
      "Xuan Wang & Sjaak Kroon  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "1.  Mapping out Heritage Tourism in Peripheral Globalization  \n",
      "\n",
      " \n",
      "\n",
      "19 August 2013 was no ordinary day for the Enshi Tujia and Miao Autonomous Prefecture, a \n",
      "\n",
      "rural minority region located in the deep mountains of Hubei Province in Central China. It \n",
      "\n",
      "was the day that marked the thirtieth anniversary of the founding of Enshi, the last officially \n",
      "\n",
      "recognized ethnic minority prefecture (of the Tujia, the Miao and twenty-six other smaller \n",
      "\n",
      "groups) in the People’s Republic of China. For the local communities, this day was not only a \n",
      "\n",
      "reminder of the historic moment when an entirely different and significant political-cultural \n",
      "\n",
      "identity, of minority, was given to them by the state, but also a formal occasion to showcase \n",
      "\n",
      "and celebrate the particular(ized) cultural heritage they have assumed since that moment, to \n",
      "\n",
      "perform and re-enact that heritage in a present-day context, and, more importantly, to market-\n",
      "\n",
      "ize aspects of authenticity in relation to their identity and heritage — whether prescribed or \n",
      "\n",
      "ascribed — in order to set their foot in the new economy of heritage tourism and become part \n",
      "\n",
      "of the globalization processes in China. In the fortnight leading up to the special day, dozens \n",
      "\n",
      "of major events and activities were organized in various parts of Enshi (of which one will be \n",
      "\n",
      "analyzed in detail later), combining commemoration, showcasing, celebration, performing, \n",
      "\n",
      "reenactment and marketization, with the Tujia, the largest indigenous ethnic group of the pre-\n",
      "\n",
      "fecture, playing the leading role.  \n",
      "\n",
      " \n",
      "\n",
      "From a sociolinguistic viewpoint, what we are witnessing is a remarkable instance — a chro-\n",
      "\n",
      "notopic invocation — of globalization in the periphery. We will qualify what we mean by this \n",
      "\n",
      "theoretically and empirically in this study. For now, suffice it to say that events and activities \n",
      "\n",
      "such as those of Enshi merit careful examination. In the periphery — being geopolitical and \n",
      "\n",
      "sociocultural minority in the case of Enshi — just as in the “center”, unprecedented economic \n",
      "\n",
      "1 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "and cultural transformations as well as renewed local awareness and identity politics are to \n",
      "\n",
      "various extents taking place. For the people in Enshi, similar to disenfranchized ethnic and \n",
      "\n",
      "small-culture groups elsewhere, heritage tourism provides niched albeit crucial access to and \n",
      "\n",
      "infrastructure of globalization through which opportunities of economic and identity reposi-\n",
      "\n",
      "tioning become available and explored (Wang et al., 2014; see also Heller, 2003, 2010 and \n",
      "\n",
      "papers in Pietikäinen & Kelly-Holmes, 2013), and such dynamics, as we will see later, are \n",
      "\n",
      "sociolinguistically densely substantiated in key moments such as the founding anniversary of \n",
      "\n",
      "Enshi. What we will observe in moments like these, also as the central argument we would \n",
      "\n",
      "like to bring from this study, is that, it is through multiple chronotopic organizations of semi-\n",
      "\n",
      "otic and discursive manoeuvring that peripheral groups arrive at a sense of authenticity that \n",
      "\n",
      "fulfils heritage tourism as both an economic and identity project instated by globalization.   \n",
      "\n",
      " \n",
      "\n",
      "In this sense, investigation of heritage tourism in places like Enshi and its complex processes \n",
      "\n",
      "and implications constitutes an integral part of sociolinguistics from the periphery (Wang et \n",
      "\n",
      "al., 2014; Pietikäinen et al., 2016), and, as such, sociolinguistics of globalization (Blommaert, \n",
      "\n",
      "2003, 2010; Coupland, 2010a). While this point may in itself be elementary and unequivocal, \n",
      "\n",
      "further thematic points central to this study on heritage tourism and peripheral globalization \n",
      "\n",
      "need to be unpacked.   \n",
      "\n",
      " \n",
      "\n",
      "Our basic starting point is that, for the purpose of this study, we position ourselves away from \n",
      "\n",
      "a certain “urban bias” that may exist in studies of globalization (see Wang et al., 2014 for a \n",
      "\n",
      "critique), of which metropolitan centers tend to serve as the default epitome of empirical oc-\n",
      "\n",
      "curences and interpretive framework. This bias can easily lead us into the pitfall of failing to \n",
      "\n",
      "detect or take serious enough the kind of “banal globalization” (Thurlow & Jaworski, 2010) in \n",
      "\n",
      "the periphery — the “ordinariness” in “unexpected places” (Pennycook, 2012) — which is \n",
      "\n",
      "largely rooted in seemingly slow, passive (i.e. orienting towards centers), small-scale, and \n",
      "\n",
      "non-superdiverse semiotic realizations when contrasting to the “center”. Recent scholarship \n",
      "\n",
      "has challenged such assumptions and made evident that sociolinguistics from the periphery \n",
      "\n",
      "can enrich our understanding of the shifting and complexifying center-periphery dynamics, \n",
      "\n",
      "and patterns of diversification and reconfiguration of language, community, and identity in \n",
      "\n",
      "late modernity (as documented in e.g. Heller, 2003, 2010, 2014a; Blommaert, 2008, 2010; \n",
      "\n",
      "Pardue, 2011; Pietikäinen & Kelly-Holmes, 2013; Sultana, Dovinch & Pennycook, 2013; \n",
      "\n",
      "2 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "Juffermans, 2015; Pietikäinen et al., 2016). Moreover, these works lend forceful support to a \n",
      "\n",
      "critical and ethnographically grounded approach by emphasizing attention to and monitoring \n",
      "\n",
      "of “knowledge from below” (Van der Aa & Blommaert, 2015) in order for more nuanced and \n",
      "\n",
      "precise representation and theorization of the increasingly decentralized, complexifying reali-\n",
      "\n",
      "ties and subaltern voices arising from the grassroots and peripheries. In this study, we follow \n",
      "\n",
      "this line of argument and engage with Enshi as periphery through the consideration of the \n",
      "\n",
      "“local” (e.g. Canagarajah, 2005; Makoni & Pennycook, 2007; Higgins, 2009; Blommaert, \n",
      "\n",
      "2010; Pennycook, 2007, 2010), that is, the local re-contextualization and re-embedding of \n",
      "\n",
      "global flows (such as heritage tourism), within the local history, ecology and ideology of \n",
      "\n",
      "meaning making, from the perspective of the periphery itself.  \n",
      "\n",
      " \n",
      "\n",
      "Following on, the case of Enshi focuses our gaze on specific aspects of peripherality, notably \n",
      "\n",
      "heritage, a notion intrinsic to ethnic and cultural identity and at the core of the local globaliza-\n",
      "\n",
      "tion processes, lodged in the new economy of heritage (thus identity) tourism. As pointed out \n",
      "\n",
      "by Pujolar (2014: 56), “heritage is indexical of peripherality within the framework of moder-\n",
      "\n",
      "nity”, and it is through the reproduction of the modernist ideology and discourse of antiquari-\n",
      "\n",
      "anism and linguistic nationalism (as described in Bauman & Briggs, 2003) that particular \n",
      "\n",
      "forms of the past and ways of life — i.e. history and tradition — are evoked, “invented” \n",
      "\n",
      "(Hobsbawn & Ranger, 1983), and projected onto specific spaces and people, creating “imag-\n",
      "\n",
      "ined communities” (Anderson, 1991) such as the nation-state and distinct ethnocultural \n",
      "\n",
      "groups. Thus, heritage, with the particular(ized) cultural and identity forms and meanings it \n",
      "\n",
      "exudes, is a product of modernity as a self-fulfilling project, in which the latter is articulated \n",
      "\n",
      "through constructing tradition as its own (perceived) defining complement and contrasting \n",
      "\n",
      "Other, and “the root pair can be elaborated into a whole lexicon of dichotomous adjectives: \n",
      "\n",
      "ancient and modern, indigenous and cosmopolitan, hidden and transparent, mysterious and \n",
      "\n",
      "known, obscure and legible, pure and impure, substantial and ephemeral, and most of all au-\n",
      "\n",
      "thentic and inauthentic” (Upton, 2001: 298-299). In this sense, heritage encompasses multiple \n",
      "\n",
      "intersecting (e.g. geographical, economic, political, and social) dimensions of peripherality.  \n",
      "\n",
      " \n",
      "\n",
      "Perhaps it is in modern nation-building that the “ethno” layer of making heritage through the \n",
      "\n",
      "counterpart Other finds its most poignant expression. There, heritage is deployed as an in-\n",
      "\n",
      "strument for the conceiving of nationhood and national identity, from which groups of eth-\n",
      "\n",
      "3 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "nocultural minorities are made visible — often from the perspective of the majority groups \n",
      "\n",
      "and set off against them, representing the alterity while also being an indispensible part of a \n",
      "\n",
      "(supposedly) shared memory and history — so as to rationalize and legitimatize the hegemo-\n",
      "\n",
      "ny of the majorities and to promote the nationalist course of unity, cohesion, and homogeneity \n",
      "\n",
      "from within. The effect of such processes is not only the invention of ethnicities, what Roos-\n",
      "\n",
      "ens (1989) terms “ethnogenesis”, but, necessarily, the minorization and marginalization of \n",
      "\n",
      "these groups on the basis of their geography, economic power, cultural pattern, language, etc., \n",
      "\n",
      "enunciated in set descriptors such as the “remote”, “local”, “agrarian”, “primordial”, “outdat-\n",
      "\n",
      "ed”, and “subordinate”, which are in turn circulated as historical truths.  \n",
      "\n",
      " \n",
      "\n",
      "The way in which ethnocultural heritage works as a political instrument and (controlled) \n",
      "\n",
      "knowledge basis of an ethnotaxonomy for forging and maintaining nation-states and multicul-\n",
      "\n",
      "tural societies, manifests itself in various geopolitical contexts (see e.g.  Rex, 1996; Bennett, \n",
      "\n",
      "1998; Povinelli, 2002; Bendix, Eggert & Peselmann, 2012). China is a case in point, wherein \n",
      "\n",
      "the state ideology and discourse of a “unified, multinational country” has resulted in the offi-\n",
      "\n",
      "cial classification of fifty-six ethnic nationalities (with the Han being the majority and consti-\n",
      "\n",
      "tuting more than ninety percent of the Chinese population) shortly after the founding of the \n",
      "\n",
      "People’s Republic in 1949 (see Mullaney (2012) for a historical account). This self-imagined \n",
      "\n",
      "diversity is managed through the duality of political regulation and acculturation of the “bar-\n",
      "\n",
      "baric” minorities by the “advanced” Han majority (Ma, 2016), and state-sponsored multicul-\n",
      "\n",
      "turalism is such that the ethnocultural identity and diversity are routinely represented in the \n",
      "\n",
      "juxtaposition of fifty-six equal but — with the exception of the Han — uniquely and exotical-\n",
      "\n",
      "ly dressed individuals. Together, in their ethnicized and semioticized physical appearances, \n",
      "\n",
      "these individuals symbolize and embody at once the fifty-six different ethnic groups and one \n",
      "\n",
      "harmonious whole. Such an image arguably belongs to the kind of compartmentalized multi-\n",
      "\n",
      "culturalism in which particular(ized) clothings (and bodies) become the essential(ized) em-\n",
      "\n",
      "blematic token of ethnocultural diversity and heritage, resonating with Gladney’s (1994, 2004; \n",
      "\n",
      "see also Blum, 2001; McCarthy, 2009) exposition of the construction of subaltern subjects and \n",
      "\n",
      "peripheral citizens by virtue of the exoticization of the minorities in Chinese ethnopolitics (see \n",
      "\n",
      "Wang, 2015 for a discussion). Hence, heritage in the Chinese multiculturalism, comparable to \n",
      "\n",
      "scenes elsewhere, is a politically loaded construct that seeks out the (exotic, dissembling, vis-\n",
      "\n",
      "ible) minority from the (normative, invisible) majority from within the nation in order to sus-\n",
      "\n",
      "4 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "tain and authenticate its core political economy. Its logic of using cultural items, be it cloth-\n",
      "\n",
      "ing, language, or something else, to mark out social positions and differences closely resem-\n",
      "\n",
      "bles Bourdieu’s (1979) notion of “distinction”, fraught with hegemony, inequality and periph-\n",
      "\n",
      "erality.  \n",
      "\n",
      " \n",
      "\n",
      "In the context of globalization, the need for articulating and promoting heritage seems height-\n",
      "\n",
      "ened (in centers and peripheries). On the one hand, afforded by unprecedented mobility, the \n",
      "\n",
      "translocal flows of people, cultural practices, and other previously local and sedentary aspects \n",
      "\n",
      "of our life are experiencing deterritorialization, displacement, and cultural disjunctures and \n",
      "\n",
      "differences (Appadurai, 1996), as well as, more fundamentally, time-space distantiation (Har-\n",
      "\n",
      "vey, 1989), disrupting and fragmenting the sense of historical linearity and continuity in \n",
      "\n",
      "which we tend to locate ourselves in relation to the world we live in. According to Giddens \n",
      "\n",
      "(1991), late modern conditions induce a drastic sense of anxiety over loss, loss of predictabil-\n",
      "\n",
      "ity, security, and “enregistered” (Agha, 2005) frames of reference, accompanied by loss of \n",
      "\n",
      "shared experiences, tradition, community, and identity. In this context, re-discovering and re-\n",
      "\n",
      "establishing local attachment and identity through the preservation and rejuvenation of history \n",
      "\n",
      "and heritage, both tangible and intangible, have become all the more important. On the other \n",
      "\n",
      "hand, in a different vein, the emergence of heritage tourism as part of the globalized new \n",
      "\n",
      "economy has created niche (tertiary) markets for the production and consumption of heritage \n",
      "\n",
      "(and its associated artefacts and experiences). As demonstrated by Heller (e.g. 2003, 2010, \n",
      "\n",
      "2014a, 2014b), the rise of the new economy in late capitalism (after the receding and reorgan-\n",
      "\n",
      "ization of the primary and secondary sectors in the center) rests largely on the commodifica-\n",
      "\n",
      "tion of the periphery and the transaction of the added value of symbolic distinctions between \n",
      "\n",
      "the periphery and the center (typified in the form of identity tourism). Driven by this new \n",
      "\n",
      "economic pattern, heritage tourism becomes a primary stage on which discourses, images, and \n",
      "\n",
      "objects of such center-periphery distinctions — framed as heritage — are produced, per-\n",
      "\n",
      "formed, circulated, and consumed. This form of globalization, as mentioned earlier, is crucial \n",
      "\n",
      "to the disenfranchized ethnic and small-culture groups, from whom a surge in heritage-based \n",
      "\n",
      "tourism activities sprouts, noticeably in the ethnocultural peripheries of China (e.g. Sue & \n",
      "\n",
      "Tao, 2009; Gao, 2014; see Wang, 2015 for the Tujia in Enshi).  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "5 \n",
      "\n",
      "\f",
      "Our discussion so far underscores the conceptualization of heritage in relation to the condi-\n",
      "\n",
      "tions of modernity and globalization, which unveils the systemic peripherality heritage index-\n",
      "\n",
      "es as well as the globalized economic, political, and cultural motifs in which it operates. In so \n",
      "\n",
      "doing, what we are actually problematizing, is the underlying issue of “authenticity”. Given \n",
      "\n",
      "that authenticity is pivotal to both heritage as identity making and heritage as tourism com-\n",
      "\n",
      "modification, probing into this issue will help address the extent to which the heritage (tour-\n",
      "\n",
      "ism) project, such as that of Enshi, gauges with the global and local regimes of meaning mak-\n",
      "\n",
      "ing and enables itself a tenable position in both the tourism market and the cultural politics of \n",
      "\n",
      "recognition. In other words, we need to examine how the Tujia in Enshi, through heritage \n",
      "\n",
      "tourism as a new opportunity, can be considered authentic simultaneously for the existing \n",
      "\n",
      "state multiculturalism, the new tourist market, and the place itself: authenticity as a polycen-\n",
      "\n",
      "tric challenge. As we now turn to discuss the way authenticity is conceptually constituted in \n",
      "\n",
      "heritage tourism and peripheral globalization, we will also move towards the Bakhtinian \n",
      "\n",
      "(1981) notion of “chronotope” as a useful heuristic for detecting and understanding the inter-\n",
      "\n",
      "connectedness and interplays of different aspects of and for authenticity.  \n",
      "\n",
      " \n",
      "\n",
      "2. Framing Heritage Authenticity and Chronotopic Identities  \n",
      "\n",
      " \n",
      "\n",
      "As Giddens (1991) has reminded us, with the world of late modernity being ridden with sens-\n",
      "\n",
      "es of crisis, the politics of identity and, along with it, the ideology of authenticity, become \n",
      "\n",
      "pervasive. In an era when traditional morality has more or less lost its authority, feeling true to \n",
      "\n",
      "oneself emerges as a crucial part of the reflexive project of self-actualization in searching for \n",
      "\n",
      "a renewed understanding of self and society (ibid; see also Erikson, 1995). This nevertheless \n",
      "\n",
      "goes hand in hand with evaluations from the others in relation to the “horizons of signifi-\n",
      "\n",
      "cance”, namely, within the relevant contexts and frameworks of meaning making (Taylor, \n",
      "\n",
      "1991). Taking into account the social, political, cultural, and psychological perspectives, au-\n",
      "\n",
      "thenticity can be encapsulated as “an assumedly common enterprise whose social functioning \n",
      "\n",
      "is a driving force of each individual’s behavior and is evaluated according to cultural contexts \n",
      "\n",
      "and mediated by and expressed in language” (Lacoste, Leimgruber & Breyer, 2014a:1).  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "6 \n",
      "\n",
      "\f",
      "The way authenticity is sociolinguistically materialized, indexed, negotiated, and performed \n",
      "\n",
      "has been systematically examined in the works of Coupland (e.g. 2003, 2010b, 2014) and oth-\n",
      "\n",
      "ers (see e.g. Thornborrow & Van Leeuwen, 2001; Bucholtz, 2003; Pennycook, 2007; Blom-\n",
      "\n",
      "maert & Varis, 2013; Wilce & Fenigsen, 2014; Locaste, Leimbruger &Breyer, 2014b). We \n",
      "\n",
      "take the converging arguments in these works as follows (see Coupland, 2014 for an over-\n",
      "\n",
      "view): (1) authenticity is always expressed through the deployment of linguistic, discursive \n",
      "\n",
      "and/or semiotic resources; (2) in globalization, meanings of authenticity are increasingly em-\n",
      "\n",
      "bedded in both local and translocal frames of reference; (3) authenticity is better understood \n",
      "\n",
      "as the effect of “authentication”, that is, the tensions and dynamics between normative con-\n",
      "\n",
      "straints and agentive production — with the goal to establish and reach a benchmark of (often \n",
      "\n",
      "multi-layered) “enoughness”; (4) the emphasis on de-essentializing authenticity and on its \n",
      "\n",
      "performative dimension points us towards new potentials of interpreting (seemingly inauthen-\n",
      "\n",
      "tic) cultural and identity behaviors.   \n",
      "\n",
      " \n",
      "\n",
      "While we locate our analysis of the case of Enshi in the framework outlined above, for the \n",
      "\n",
      "purpose of this study we draw particular attention to the mechanisms of authenticity in herit-\n",
      "\n",
      "age tourism and peripheral globalization. As said, heritage emerges as a modernist construct, \n",
      "\n",
      "with its normative parameters — “orders of authenticity” (Wang, 2012) — centering on geo-\n",
      "\n",
      "political and sociocultural peripherality and serving to sustain the political economy of the \n",
      "\n",
      "nation-state. This can be seen, for example, in the essentialized othering through exoticitiza-\n",
      "\n",
      "tion of ethnocultural heritage in Chinese multiculturalism, which is largely based on the state-\n",
      "\n",
      "prescribed ethnotaxonomy from the perspective of the Han majority. Heritage tourism capital-\n",
      "\n",
      "izes on exactly the kind of asymmetrical distinction created by dichotomizing the majority \n",
      "\n",
      "versus the minority, the advanced versus the barbaric, the urban versus the rural, the modern \n",
      "\n",
      "versus the traditional, the global versus the local, etc.. Its core business, therefore, is both the \n",
      "\n",
      "semiotization and commodification of authenticity (Heller, 2003, 2014b; Jaworski & \n",
      "\n",
      "Pritchard, 2005; Waterton & Watson, 2014) which, on the part of the periphery-supplier, in-\n",
      "\n",
      "volves selecting specific cultural resources and communicating them in highly specific ways \n",
      "\n",
      "for specific audiences on specific occasions. Such processes, necessarily “inauthentic” due to \n",
      "\n",
      "modification and commodification, arguably generate alternative revenues of “inauthentic \n",
      "\n",
      "authenticity” (Wang, 2015). As Heller (2014b: 154) asserts, in understanding authenticity in \n",
      "\n",
      "the periphery, “[c]ommodification affords us a window into ongoing change, allowing us to \n",
      "\n",
      " \n",
      "\n",
      "7 \n",
      "\n",
      "\f",
      "link up individual subjectivity, interactional processes, and the conditions of the symbolic \n",
      "\n",
      "market”. \n",
      "\n",
      " \n",
      "\n",
      "How, then, can we study the actual forms taken by this sociolinguistic process of commodifi-\n",
      "\n",
      "cation, caught in the polycentric challenge of authenticity described earlier? How can we, in \n",
      "\n",
      "answering the previous question, also account for the inevitable “inauthenticity” connoted in \n",
      "\n",
      "the act of commodification (and associated performativity), and the way the paradoxical inau-\n",
      "\n",
      "thentic authenticity is oragnized as a sustainable and coherent part into a shared lifeworld? \n",
      "\n",
      "Here, Bakhtin’s seminal idea of “chronotope” and its recent sociolinguistic uptakes (e.g. \n",
      "\n",
      "Agha, 2007; Lampert & Perrino, 2007; Woolard, 2013; Blommaert & De Fina, 2016) offer us \n",
      "\n",
      "a great source of inspiration. \n",
      "\n",
      " \n",
      "\n",
      "In Bakhtin’s literary analysis, “chronotope” was used for addressing “the intrinsic connected-\n",
      "\n",
      "ness of temporal and spatial relationships that are artistically expressed” in novels (Bakhtin, \n",
      "\n",
      "1981: 84), namely, the timespace specificity from which discourse of plot, history, and identi-\n",
      "\n",
      "ty emerges.  For Bakhtin, time and space are inseperable in constructing narratives and char-\n",
      "\n",
      "acters; they function as a fused, concrete whole — identifiable as chronotope — which is \n",
      "\n",
      "structured and encoded in specific ways, generating historical and semiotic conditions of \n",
      "\n",
      "meaning making. This conceptualization makes it possible to dissect and describe the multiple \n",
      "\n",
      "timespace configurations that co-occur, not only in literary (en)textuality, in terms of novelis-\n",
      "\n",
      "tic chronotopes through which readers can extract and connect multiple social meanings and \n",
      "\n",
      "agencies represented in a story, but more generally, as cultural chronotopes: “depiction of \n",
      "\n",
      "place-time-and-personhood to which social interactants orient when they engage each other \n",
      "\n",
      "through discursive signs of any kind” (Agha, 2007: 320).   \n",
      "\n",
      " \n",
      "\n",
      "This cultural potential of chronotopes is formulated as “invokable histories” in Blommaert’s \n",
      "\n",
      "(2015: 110) attempt to bring together the notion of chronotope and those of context and scale \n",
      "\n",
      "for accounting for the complexity of language in society. Drawing on the central argument of \n",
      "\n",
      "discourse in history, Blommaert (2015: 108) is able to consider chronotope as an important \n",
      "\n",
      "aspect of contextualization in which “meaning as value effects [is] derived from local enact-\n",
      "\n",
      "ments of historically loaded semiotic resources” (see also Gumperz , 2003; Silverstein, 2003; \n",
      "\n",
      "8 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "Agha, 2005; Blommaert, 2005). From the perspective of historicity, all interactive events can \n",
      "\n",
      "be seen as chronotopically organized, situated in timespace, occuring as here-and-now while \n",
      "\n",
      "indexing a myriad of “historically configured and ordered tropes” (Blommaert, 2015: 111). \n",
      "\n",
      "These tropes, or culturally recognizable systems of meanings and values, are applied and \n",
      "\n",
      "made understandable through genres, by means of ideologized, normative, and enregistered \n",
      "\n",
      "features and styles that index and codify specific time-space relations. In this sense, each \n",
      "\n",
      "chronotope installs its own discursive frames and orders of indexicality (and, thus, of authen-\n",
      "\n",
      "ticity); invocation of time-space also constitutes ascription of genres, registers, indexicals, and \n",
      "\n",
      "other chronotopically relevant norms, and, as such, enactment of specific intentions, manoeu-\n",
      "\n",
      "vres, and effects (which are in turn open for interpretation through the lens of Goffman’s \n",
      "\n",
      "(1974) frame analysis).   \n",
      "\n",
      " \n",
      "\n",
      "The historical dimension of chronotope highlights its presupposed multiplicity and polycen-\n",
      "\n",
      "tricity. As already posited by Bakhtin (1981: 252), within any given literary or communicative \n",
      "\n",
      "output, the (assimilation of) spatial-temporal reality involves “major chronotopes”, each may \n",
      "\n",
      "include within it “an unlimited number of minor chronotopes” and “complex interactions \n",
      "\n",
      "among them”. Such chronotopic organizations (of fractality) are of course nonrandom, for the \n",
      "\n",
      "timespace multiplicity and polycentricity are inherently embedded in the translocal contexts \n",
      "\n",
      "of what we say and do, the historically construed and shared structures of meanings attached \n",
      "\n",
      "to the communicative resources we use, and the dialogically evolving ideas, voices, and iden-\n",
      "\n",
      "tities — what Bakhtin (1981) has termed “heteroglossia”. Building on this interpretation, \n",
      "\n",
      "chronotope can be fruitfully combined with scale, another timespace metaphor (Blommaert, \n",
      "\n",
      "2007, 2010; Collins et al., 2009) that illustrates the social stratification in which language re-\n",
      "\n",
      "sources are (unevenly) distributed and acts of communication are (unequally) materialized \n",
      "\n",
      "and evaluated against normative complexes and orders of indexicality, with hierarchically \n",
      "\n",
      "attributed meanings and values. Through the notion of scale, argues Blommaert (2015: 111), \n",
      "\n",
      "we are able to critically examine the chronotopic organizations of language resources in terms \n",
      "\n",
      "of “the degrees of availability and accessibility of adequate contexts creatively invoked in \n",
      "\n",
      "discourse” as well as “the scalar effects of recognizability”. Scale points us towards “the \n",
      "\n",
      "scope of understandability [… and] scope of creativity” (ibid) of the discursive enactment of \n",
      "\n",
      "timespace, and, we may add, the interrelations of co-occuring chronotopes within that enact-\n",
      "\n",
      "ment (as, for instance, distinguished by Bakhtin as “major” and “minor”) that keep different \n",
      "\n",
      "9 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "orders of authenticity in balance. The issues at stake in chronotopes, thus, are about distinc-\n",
      "\n",
      "tions in power, authority, agency, and voice — issues that are part and parcel of the sociolin-\n",
      "\n",
      "guistic critique on language and inequalities in the works of Bourdieu (1991), Hymes (1996) \n",
      "\n",
      "and others.      \n",
      "\n",
      " \n",
      "\n",
      "Blommaert’s intervention of chronotope by connecting it with the notions of context and \n",
      "\n",
      "scale, is aimed at a less reductive approach to the complexity presented in “the total linguistic \n",
      "\n",
      "fact” (Silverstein, 1985), a challenge faced by sociolinguistics on how to account for  \n",
      "\n",
      "“a complex construction of multiple historicities compressed into one synchronized \n",
      "\n",
      "act of performance, projecting different forms of factuality and truth, all of them ideo-\n",
      "\n",
      "logically configured and thus indexically deployed and all of them determined by the \n",
      "\n",
      "concrete sociolinguistic conditions of their production and uptake, endowing them \n",
      "\n",
      "with a scaled communicability at each moment of enactment.”  (Blommaert, 2015: \n",
      "\n",
      "113-114) \n",
      "\n",
      " \n",
      "\n",
      "To this end, it may well be feasible to suggest that all communicative behaviors can be exam-\n",
      "\n",
      "ined as chronotopically organized cultural practices in which the timespace configurations \n",
      "\n",
      "reveal not only the nano politics of identity at the personal level, but also more far-reaching \n",
      "\n",
      "sociocultural changes in cultural globalization (Blommaert & De Fina, 2016). On reflection of \n",
      "\n",
      "this (theoretical) potential, we are reminded of the point on cultural chronotopes raised by \n",
      "\n",
      "Agha (2007: 321) who argues for the scope of generalizability by defining chronotope as “a \n",
      "\n",
      "semiotic representation of time and space peopled by certain social types” (our emphasis). \n",
      "\n",
      "The agentive dimension of chronotope is made translucent, as Agha (2007: 321) states further: \n",
      "\n",
      "“The act of producing or construing a chronotoptic representation itself has a chronotopic \n",
      "\n",
      "organization (of time, space and personhood) which may be transformed by that act.” The \n",
      "\n",
      "capacity to actualize recognizable meaning, personhood, and social reality through chrono-\n",
      "\n",
      "tope points to its performative dimension — by orienting toward multiple, polycentric \n",
      "\n",
      "timespace frames and scaled normativities specified therein (Bayham, 2015). Such timespace \n",
      "\n",
      "orientations are essentially acts of identity and realizations of “recombinant selves” (Agha, \n",
      "\n",
      "2007: 324), which in return may in their very processes generate new meanings and changes, \n",
      "\n",
      "thus, pushing the boundaries of authenticity.  \n",
      "\n",
      " \n",
      "\n",
      "10 \n",
      "\n",
      "\f",
      " \n",
      "\n",
      "Linking the above understanding of chronotope with our earlier discussions on heritage and \n",
      "\n",
      "authenticity, it is not difficult to see that the concept has much to offer to investigating herit-\n",
      "\n",
      "age tourism and identity construction in peripheral globalization at both descriptive and ana-\n",
      "\n",
      "lytical levels. Heritage itself is a chronotopic notion, located in a particular(ized) image of an \n",
      "\n",
      "eternalized past attached to a certain place (and group). And the use of the term, as we have \n",
      "\n",
      "established, activates a whole package of associated ways of talking, signing, dressing, and \n",
      "\n",
      "behaving. In the context of globalization, the chronotope of heritage, with its orders of authen-\n",
      "\n",
      "ticity centering on peripherality, maps onto that of the global center-periphery distinction am-\n",
      "\n",
      "plified by late capitalism; while as an offshoot of globalization, it also merges with the chro-\n",
      "\n",
      "notope of tourism driven by the commodification of authenticity. All of these are organized \n",
      "\n",
      "into the specific chronotopes in which heritage tourism is locally taken up: in our case, in \n",
      "\n",
      "Enshi as a geopolitical and sociocultural periphery of China’s modernization and globaliza-\n",
      "\n",
      "tion. Within this chronotope, importantly, is nested another chronotope of the state multicul-\n",
      "\n",
      "turalism in China, emerged from its nation-building process, in which the Tujia as yet another \n",
      "\n",
      "chronotope is situated. The chronotopic nature of our object of study cannot be more patent. \n",
      "\n",
      "But how are these different chronotopes semiotically materialized? How might the “invokable \n",
      "\n",
      "histories” be configured into a “recombinant” new act of self?  To what extent is the chrono-\n",
      "\n",
      "topic oragnization understood as “authentic”, and to whom? Let us now bring these questions \n",
      "\n",
      "into the empirical field of observation by returning to the scene, or chronotopic setting, that \n",
      "\n",
      "we opened this paper with.  \n",
      "\n",
      " \n",
      "\n",
      "3. Dissecting Chronotopes of Authenticity  \n",
      "\n",
      " \n",
      "\n",
      "That chronotopic setting is 19 August 2013, Enshi. As explained earlier, the thirtieth anniver-\n",
      "\n",
      "sary of Enshi as the last officially recognized minority prefecture in China punctuates a cru-\n",
      "\n",
      "cial and sociolinguistically dense moment of identity making. It serves as a memorial of the \n",
      "\n",
      "local ethnic minority status given by the state. It opens a stage for performing and reiterating \n",
      "\n",
      "the heritage assumed by that status for the local people. It also inserts a need to promote the \n",
      "\n",
      "local heritage tourism. The list goes on. Put in the terms we have developed above, this chro-\n",
      "\n",
      "notopic setting is constituted into a combination of chronotopes that are called into intricate \n",
      "\n",
      "play on a locally contrived occasion. We will now home in on the complex details and dynam-\n",
      "\n",
      "11 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "ics in the chronotopic configuration of the setting through a sustained look at one snapshot \n",
      "\n",
      "example.  \n",
      "\n",
      " \n",
      "\n",
      "3.1 Chronotopic Organization in Heritage Performance \n",
      "\n",
      " \n",
      "\n",
      "The example is taken from one of the many events and activities organized locally in different \n",
      "\n",
      "parts of  Enshi during the fortnight proceeding the actual anniversary day. Our ethnographic \n",
      "\n",
      "attention, access, and selection of data here are necessarily reflexively shaped our personal \n",
      "\n",
      "and subjective encounter and experience in the field, be it sometimes “incidental” (Pinsky, \n",
      "\n",
      "2015). In this case, this has led us (through local acquaintances) to the small village of Shui \n",
      "\n",
      "Tian Ba, on 17 August 2013, two days before the official festival date of the Prefecture. Shui \n",
      "\n",
      "Tian Ba village was, until that moment, a remote and yet-to-know hamlet in the constituent \n",
      "\n",
      "county Xuan’en, the poorest county of Enshi. On that day, however, this peripheral village \n",
      "\n",
      "was turned into the center of an open air culture festival. Several different heritage-related \n",
      "\n",
      "activities were taking place from dawn to dusk, including an outdoor stage performance of \n",
      "\n",
      "ethnic art, a national mountain bike tournament, and the opening of a local Tujia folk muse-\n",
      "\n",
      "um, attracting tens of thousands of participants and visitors from near and far (such as Eu-\n",
      "\n",
      "rope). A précis of the event and its multiplex timespace composition is offered by the follow-\n",
      "\n",
      "ing image (see Figure 1 below).     \n",
      "\n",
      " \n",
      "\n",
      "What we see is part of the outdoor stage performance, set in the heart of the village. In a broad \n",
      "\n",
      "sense, we can identify two immediately observable time-space frames: one of the stage, and \n",
      "\n",
      "one of the village in which the stage is set (both then merge into a third one created through \n",
      "\n",
      "the camera lens of the ethnographer). Each of them, as we will see, entails several more chro-\n",
      "\n",
      "notopes which are brought in and materialized semiotically, driven by certain ideology of \n",
      "\n",
      "identity — targeted locally as heritage authenticity.  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "12 \n",
      "\n",
      "\f",
      "Figure 1: A chronotopic organization of “authentic” Tujia in Enshi © Xuan Wang 2013 \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "We turn first to the stage as one chronotopic unit. We start with its semiotic framing in the \n",
      "\n",
      "format of the stage background design, which is in itself a chronotopic semiotization. The \n",
      "\n",
      "background design sets the overall chronotope of the event by announcing the thematic title of \n",
      "\n",
      "the event, in big red characters: The Prefectural Day Celebration — Walk into A Thousand \n",
      "\n",
      "Tujia Households. Underneath, in yellow color and smaller size, are the four sub-thematic \n",
      "\n",
      "titles: (1) A Thousand Tujia Households country leisure and tourism opening ceremony; (2) \n",
      "\n",
      "the first national mountain bike invitation tournament; (3) intangible cultural heritage show; \n",
      "\n",
      "(4) A Thousand Tujia Households Ecological Beauty photography competition. This is fol-\n",
      "\n",
      "lowed by a clear signature of time and space — Xuan’en, Hubei, 19 August 2013 — and \n",
      "\n",
      "completed with names of the main organizers, participant groups, and sponsors.  \n",
      "\n",
      " \n",
      "\n",
      "Already we can see that the major chronotope here — which is in itself of dual focus — is \n",
      "\n",
      "composed of several sub-chronotopes. The core message delivered in the major chronotope is \n",
      "\n",
      "about The Prefectural Day Celebration, the official anniversary of the local minority status \n",
      "\n",
      "given by the state, while it converts this into a new local agenda engendered by and in turn \n",
      "\n",
      "reinforcing that status: the local heritage tourism, developed in Shui Tian Ba village as the \n",
      "\n",
      "13 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "project of A Thousand Tujia Household (more will be said about this project). The expression \n",
      "\n",
      "“walk into” is a public invitation, paraphrasing “welcome”, indexing a tourism marketing \n",
      "\n",
      "discourse. The centrality of the double message, of the locally implemented but state-directed \n",
      "\n",
      "political, economic, and cultural priority, is indexed in the (red) color and (large) size of the \n",
      "\n",
      "writing, perhaps even in its font: with the thematic title mainly written in the font Fang Zheng \n",
      "\n",
      "(literally “clear and square”), a print font with a serious and meticulous appearance indicating \n",
      "\n",
      "formality, only leaving out the name of the local heritage project, A Thousand Tujia House-\n",
      "\n",
      "holds, which adopts a calligraphy font, a more flowy handwriting style to set it off against the \n",
      "\n",
      "rest of the line, perhaps to imply a degree of possibility for manoeuvring and creativity (while \n",
      "\n",
      "indexing the traditional and authentic).  \n",
      "\n",
      " \n",
      "\n",
      "This major chronotope is further developed into four sub-chronotopes. Each points to a dis-\n",
      "\n",
      "tinct element of the heritage project that was taking place and open for sampling in Shui Tian \n",
      "\n",
      "Ba village on that day, while bringing into play four interrelated yet different strands of the \n",
      "\n",
      "local interpretation and enactment of heritage tourism. These involve (corresponding with the \n",
      "\n",
      "sequence of the sub-thematic titles presented earlier) the local being chronotopically orga-\n",
      "\n",
      "nized as a destination (1) of rural tourism, experienced in its ethnicized primordial, idyllic \n",
      "\n",
      "lifestyle; (2) of extreme tourism, explorable as a remote and dangerous place through modern \n",
      "\n",
      "adventure sports, such as mountain biking; (3) of cultural tourism, inhabited by the ethnic \n",
      "\n",
      "Other, crystallized and exhibited in certain (intangible) forms of tradition; and (4) of ecotour-\n",
      "\n",
      "ism, as a space undisturbed by modern living, with uncontaminated natural beauty (note the \n",
      "\n",
      "involvement of photography, which creates new chronotopes and new layers of image, reality, \n",
      "\n",
      "and interpretation through the tourist gaze). Taken together, these (sub)chronotopic strands \n",
      "\n",
      "index and put into practice the logic of heritage tourism and its tropes (multilayered, but all \n",
      "\n",
      "revolving around peripherality), co-constructing an “authentic” local through the commodifi-\n",
      "\n",
      "cation of its profound peripherality.  \n",
      "\n",
      " \n",
      "\n",
      "The intertwining of these chronotopes sanctions and “orders” the deployment of more semiot-\n",
      "\n",
      "ic indexicals into that same stage background design, in the form of a collage of different im-\n",
      "\n",
      "ages on which all the aforementioned thematic titles are inscribed. In this collage, Shui Tian \n",
      "\n",
      "Ba village is seen lying peacefully in the gentle cradle of beautiful mountains. The centre of \n",
      "\n",
      "the panoramic view is occupied by a stretch of lushly green tea fields (tea is a well-known \n",
      "\n",
      "14 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "produce of Xuan’en since two centuries ago). On the left and right edge of the fields, along \n",
      "\n",
      "the mountains, sit small, tidy clusters of “traditional” farm houses (which were in fact newly \n",
      "\n",
      "built as part of the local A Thousand Tujia Households project). In the bottom right corner of \n",
      "\n",
      "the collage, we also find a superimposed image of fully geared (urban) cyclists in action. Un-\n",
      "\n",
      "doubtedly, these images are carefully selected and chronotopically re-organized into the col-\n",
      "\n",
      "laged chronotope of the stage background design. The aesthetic depiction of the village ech-\n",
      "\n",
      "oes and informationally complements the (rural, adventure, cultural, and eco-) forms of herit-\n",
      "\n",
      "age tourism inscribed in the thematic titles of the occasion. In this they also reaffirm ideologi-\n",
      "\n",
      "cally the local multiple orientations to the translocal (heritage) authenticity simultaneously \n",
      "\n",
      "invoked in these titles – we are observing what Blommaert (2005) called “layered simultanei-\n",
      "\n",
      "ty” here. Shui Tian Ba village is authentic, as it seems, because of the confluence of all of \n",
      "\n",
      "these elements in that historical-synchronic moment of enactment and observation. The chro-\n",
      "\n",
      "notopically invoked words, images, and ideas of heritage-as-tourism, as evidenced so far, all \n",
      "\n",
      "point to authenticity as a romanticized, exoticized, and commodified version of peripherality. \n",
      "\n",
      "This version of peripherality, as we will see next, is embedded in and mobilized in support of \n",
      "\n",
      "the overall heritage (thus identity) project of Enshi: the construction of an authentic minority \n",
      "\n",
      "identity, of the Tujia.   \n",
      "\n",
      " \n",
      "\n",
      "Let us now look at the second aspect of the stage performance, the actual show unfolding \n",
      "\n",
      "within that chronotope. What is being performed is a dramatized dance called Ten Sisters, \n",
      "\n",
      "which re-enacts the Tujia tradition of “wedding lament”. This performance is yet another \n",
      "\n",
      "chronotopic organization, richly semiotized through music, singing, costumes, body move-\n",
      "\n",
      "ments and storytelling. We see that all dancers are dressed in supposedly Tujia-style costumes \n",
      "\n",
      "(the “authentic” Tujia costumes are hard to identify; see Wang, 2015). The bride and the \n",
      "\n",
      "groom are wearing matching red. With her head covered under a red veil, the bride is being \n",
      "\n",
      "carried away by the groom on his back. The bridesmaids, the other nine of the ten sisters, are \n",
      "\n",
      "in identical pink dresses. They are lined up behind the couple, crying and waving farewell to \n",
      "\n",
      "the bride with red handkerchiefs. One of them seems to find it difficult to see off the bride: \n",
      "\n",
      "she stands by the couple, holding a red umbrella over the bride to shelter her from the sun. \n",
      "\n",
      "The music is sad and grieving, and the lyrics speak about the bride’s reluctance to leave home \n",
      "\n",
      "and her gratitude to her mother.  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "15 \n",
      "\n",
      "\f",
      "The “invokable histories” of this chronotopic organization, taking the form of dance show, are \n",
      "\n",
      "indexically linked to the state ideology of multiculturalism in China and its imperative for \n",
      "\n",
      "ethnic(ized) minorities presented as the primitive, exotic Other (from the perspective of the \n",
      "\n",
      "Han majority). As discussed earlier, this ideology derives from an essentialized ethnotaxono-\n",
      "\n",
      "my, claiming certain (and sometimes imagined or caricatured) aspects of the past or distinc-\n",
      "\n",
      "tions as “traditions” and ethnically “unique” heritage, and circulating these as knowledge and \n",
      "\n",
      "truth that transcend timespace. This order of authenticity centering on ethnicity overarches the \n",
      "\n",
      "entire heritage making in Enshi. Although the wedding lament is a (dated) custom once prac-\n",
      "\n",
      "ticed in many (Han and other ethnic) communities in China (and elsewhere), it has been offi-\n",
      "\n",
      "cially attached to the Tujia as part of the group’s assumed timeless, ethnically unique features \n",
      "\n",
      "and cultural heritage. The ritual is re-enacted and chronotopically incorporated into various \n",
      "\n",
      "identity moments to indicate authenticity, such as here on the stage in Shui Tian Ba village, \n",
      "\n",
      "for the thirtieth anniversary of Enshi. In fact, the wedding lament has become a Tujia “clas-\n",
      "\n",
      "sic”; the ritual — or, rather, the idea of it — has been enregistered as part of the local identity \n",
      "\n",
      "repertoire even though the vast majority of the local people have never seen it in its “authen-\n",
      "\n",
      "tic” form themselves.  \n",
      "\n",
      " \n",
      "\n",
      "The dance performance of Ten Sisters in Shui Tian Ba village is one of the numerous reinter-\n",
      "\n",
      "preted versions of the Tujia wedding lament ritual. Within its own timespace frame as a dance, \n",
      "\n",
      "it artistically and intertextually recycles the official discourse of the “authentic” Tujia. Mean-\n",
      "\n",
      "while, the dance serves as a focal point of the chronotope generated on the stage: it ties in \n",
      "\n",
      "with the theme “intangible cultural heritage show” written in the stage background design; it \n",
      "\n",
      "delivers that theme through selected multimodal semiosis and, via the stage, opens its semio-\n",
      "\n",
      "tization of authenticity to multiple audiences and interpretations. The dancers on this stage are \n",
      "\n",
      "what we might call the “heritagized” body. By being members of the local communities, \n",
      "\n",
      "wearing Tujia-style clothing, and doing the ritual of wedding lament through dancing, the \n",
      "\n",
      "dancers have themselves become the most “authentic” embodiment of Tujia authenticity. The \n",
      "\n",
      "bodies per se and what they can do and represent, in this sense, are called upon as an ele-\n",
      "\n",
      "mental form of chronotopic resource for achieving that authenticity, thus, an elemental part of \n",
      "\n",
      "the Tujia heritage. This bodily resource is in fact the semiotic axis to all the chronotopes at \n",
      "\n",
      "work. In the same way that it indexes and embodies the essence of Enshi’s heritage project on \n",
      "\n",
      "the whole, i.e. heritage-as-ethnicity, the insertion of the heritagized body onto the stage sets \n",
      "\n",
      "16 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "the footing of the event in Shui Tian Ba village on the local people doing being the authentic \n",
      "\n",
      "Tujia, thus, bringing together all the chronotopes which are organized locally into the front-\n",
      "\n",
      "stage activity of dancing, the stage background design, the heritage-based tourism activities, \n",
      "\n",
      "and, ultimately, the moment of celebration in the village, with the co-presence of performers, \n",
      "\n",
      "audiences, and respondents.  \n",
      "\n",
      " \n",
      "\n",
      "This brings us to the village of Shui Tian Ba as a chronotopic unit in which the celebration \n",
      "\n",
      "event we are examining takes place. As shown in Figure 1, the stage performance described \n",
      "\n",
      "above is part of this chronotope. The mountains of Shui Tian Ba village depicted in the visual \n",
      "\n",
      "collage of the stage background design are right behind it — an authenticating effect to what \n",
      "\n",
      "is happening on the stage and, by extension, to the Tujia heritage projected from that stage. So \n",
      "\n",
      "are the tea fields, the traditional farm houses, and the cyclists. The spatial-temporal locality \n",
      "\n",
      "provides the foundational framework for everything. However, locality is not merely the \n",
      "\n",
      "backdrop outside of things that are happening, it is also designed and brought into the chrono-\n",
      "\n",
      "topic organization as a resource.  \n",
      "\n",
      " \n",
      "\n",
      "A Thousand Tujia Households is the local heritage project that has turned Shui Tian Ba village \n",
      "\n",
      "into the ideal(ized) locality for the big celebration. The project was mainly funded by the \n",
      "\n",
      "county government of Xuan’en. Its goal was to make a model village out of Shui Tian Ba \n",
      "\n",
      "showcasing the natural beauty of the mountainous region, the idyllic agrarian lifestyle, and the \n",
      "\n",
      "unique Tujia way of life, focusing on housing — all in all, an “authentic” package of heritage \n",
      "\n",
      "features under the umbrella term of Tujia, which feeds directly into the heritage tourism mar-\n",
      "\n",
      "ket and its commodification of Tujia authenticity. We have seen all of these semiotically rep-\n",
      "\n",
      "resented in the stage background design. Not readily visible in that synchronicity is the pro-\n",
      "\n",
      "cess of (chronotopic) organization. To achieve the goal, the village has been spatially trans-\n",
      "\n",
      "formed. The previous paddy fields (the name Shui Tian Ba refers to paddy fields) were re-\n",
      "\n",
      "placed with tea fields, concentrated in the centre of the village. New roads and paths were \n",
      "\n",
      "built, with a featuring Dong-style (another ethnic minority group found in Enshi) bridge \n",
      "\n",
      "crossing over the little river that runs through the village. The location and size of the local \n",
      "\n",
      "farm houses were also reorganized, so that they would look tidier and more uniformly recog-\n",
      "\n",
      "nizable. More interestingly, a proportion of the project funding was spent on revamping these \n",
      "\n",
      "houses to give them an ethnically authentic appearance. This involved re-plastering the exter-\n",
      "\n",
      "17 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "nal walls of many houses to hide their originally tiled facades (an urban trend in Enshi at the \n",
      "\n",
      "time), replacing the aluminum window frames with carved wooden ones, and adding artistic \n",
      "\n",
      "ethnic features to the roofs and eaves of the houses. All these efforts have contributed to the \n",
      "\n",
      "“authentic” locality and are visually connected to “authentic” products found in Shui Tian Ba \n",
      "\n",
      "village.  \n",
      "\n",
      " \n",
      "\n",
      "It may be argued that the production of locality may have paradoxically triggered “artificial \n",
      "\n",
      "authenticity”, therefore, inauthenticity. However, what counts as the original? Is the original \n",
      "\n",
      "the authentic? At what point does an intentional adjustment turn its object into something in-\n",
      "\n",
      "authentic? Answers to such questions are contentious and complex. We prefer to consider the \n",
      "\n",
      "A Thousand Tujia Households project as an example in which the semiotic modification of a \n",
      "\n",
      "chronotopic setting is part of the wider process of striving for a sense of authenticity at differ-\n",
      "\n",
      "ent scale-levels; it therefore belongs to the production of authenticity.   \n",
      "\n",
      " \n",
      "\n",
      "To summarize, the example from Shui Tian Ba village illustrates complex chronotopic organi-\n",
      "\n",
      "zations of different aspects of the Tujia heritage in action. In the format of a stage perfor-\n",
      "\n",
      "mance, different timespace frames are mobilized to represent the “authentic” Tujia for the \n",
      "\n",
      "political and the economic purposes. The stage itself becomes multi-chronotopic, in the sense \n",
      "\n",
      "that it generates a nexus of chronotopes, with the Tujia dance performance as its focal point, \n",
      "\n",
      "and the stage background design semiotically mirroring the corporeal surrounding and activi-\n",
      "\n",
      "ties of the occasion. Each of these chronotopic organization brings along its own historical \n",
      "\n",
      "meanings and these chronotopes and meanings merge into a fused whole through the stage \n",
      "\n",
      "setting. In fact, the entire event is chronotopically contextualized by the stage, on which the \n",
      "\n",
      "Tujia heritage is performed — in a double sense of the word: as a theatrical performance, and \n",
      "\n",
      "as an agentive process of semiotization. This performativity aspect, as we have seen, involves \n",
      "\n",
      "notable efforts of “semiotic design” (Wang (2015) illustrates this process with reference to \n",
      "\n",
      "Tujia ethnic costumes in Enshi). Chronotopes examined here are necessarily part of the larger \n",
      "\n",
      "chronotopes of heritage in Enshi, in China, and in globalization. They show that the perfor-\n",
      "\n",
      "mance of heritage authenticity, or any identity claim, is organized in relation to multiple \n",
      "\n",
      "timespace frames of meaning making.   \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "18 \n",
      "\n",
      "\f",
      "3.2 Chronotopic Scaling and Authenticity  \n",
      "\n",
      " \n",
      "\n",
      "We have suggested earlier that scale is a notion that can be used to describe the scope of \n",
      "\n",
      "communicability of chronotopically organized and semiotized behaviors (Blommaert, 2015). \n",
      "\n",
      "If heritage can be observed as such a phenomenon, following our discussion so far, tourism \n",
      "\n",
      "offers a scale at which heritage can be articulated, negotiated, and understood. The scale of \n",
      "\n",
      "tourism mobilizes specific norms, genres, and expectations toward which communication on \n",
      "\n",
      "heritage and its authenticity orients — we have seen these in the case of Enshi being “trans-\n",
      "\n",
      "lated” into the globalized formats of rural, adventure, ethnic, and eco tourism and respective \n",
      "\n",
      "spatiotemporal configurations of local engagements. There are other scales that are prevalent, \n",
      "\n",
      "such as the state’s ethnopolitics of multiculturalism, or the local histories and conditions. All \n",
      "\n",
      "these scales inform and shape the way heritage can be performed and developed in an “au-\n",
      "\n",
      "thentic” way. This suggests that heritage is a profoundly multi-scalar and polycentric process, \n",
      "\n",
      "in which different scales interact with one another, but not always on equal footings. They \n",
      "\n",
      "may come into play at a semiotic, ideological, or discursive level. They may work in parallel, \n",
      "\n",
      "conjoint, competing, or conflicting relations with one another, and in turn involve different \n",
      "\n",
      "contributors and evaluators. The outcome is heteroglossic, a package of multiple meanings \n",
      "\n",
      "and voices. For us, such dynamics and the opportunities, tensions, and transactions they insti-\n",
      "\n",
      "gate qualify “heritage” as a verb (to echo Street (1993) and Blommaert (2013)).  \n",
      "\n",
      " \n",
      "\n",
      "From this perspective, heritage can be understood as a scaled collective process of meaning \n",
      "\n",
      "making in a given timespace. “Heritaging”, we might say, is a matter of scaling: manoeuvring \n",
      "\n",
      "with the dialectic interplays of the relevant scales to arrive at a sense of authenticity through \n",
      "\n",
      "chronotopically organized “synchronized” activities. This understanding may go some way to \n",
      "\n",
      "explaining our remaining questions on the issue of heritage authenticity we have encountered \n",
      "\n",
      "in Enshi, an issue that appears to be largely about responding to the orders of authenticity at \n",
      "\n",
      "the scale of the globalized heritage tourism and the scale of the state heritage politics. \n",
      "\n",
      "Through the example given above, we have gained insight into the intricate chronotopic or-\n",
      "\n",
      "ganizations of heritage authenticity, and understood that it is within a complex regime of nor-\n",
      "\n",
      "mativities that a range of chronotopes are brought together to explore an important identity \n",
      "\n",
      "opportunity for Enshi. The questions we are left with are: In what way can we actually inter-\n",
      "\n",
      "pret the local uptake of heritage tourism under these conditions still as an agentive process of \n",
      "\n",
      "19 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "heritaging and, in the end, self-realized authenticity for the community itself? In what way \n",
      "\n",
      "can we keep a balanced view between the conformative and the performative, the staged and \n",
      "\n",
      "the everyday, the authentic and the inauthentic, in order to better account for meaning making \n",
      "\n",
      "in the periphery? To answer these questions we have to return to the genesis of Enshi Tujia \n",
      "\n",
      "and Miao Autonomous Prefecture.  \n",
      "\n",
      " \n",
      "\n",
      "The establishment of Enshi’s minority status through its ethnic population of the Tujia was a \n",
      "\n",
      "convoluted story. In the process of nation building after 1949, the Chinese government im-\n",
      "\n",
      "plemented ethnic classification in order to give recognition to minority groups and to integrate \n",
      "\n",
      "them into a “unified, multinational country”. A large number of the fifty-five minority groups \n",
      "\n",
      "we now know in China were officially identified in the 1950s. Each ethnic group, called min-\n",
      "\n",
      "zu, (supposedly) has its own territory, common history, unique language, culture and tradition. \n",
      "\n",
      "However, as Mullaney (2011) shows in his account of this part of Chinese history, the ethno-\n",
      "\n",
      "taxonomy applied at the time had its epistemological, ontological and methodological founda-\n",
      "\n",
      "tions in Western modernist social scientific beliefs in disciplines such as linguistics and eth-\n",
      "\n",
      "nology (and, we could add, its political conversion into a “model state”, the Soviet Union). It \n",
      "\n",
      "was unable to clearly define all ethnic groups according to pre-assumed, fixed categories such \n",
      "\n",
      "as language or specific cultural traits. The Tujia group was not recognized until 1957 because \n",
      "\n",
      "the group had been mixing and living together with other groups; they lacked the obvious \n",
      "\n",
      "cultural features that would make them visibly different from the other groups. Its classifica-\n",
      "\n",
      "tion was prompted accidentally when a minority representative of Miao from a town border-\n",
      "\n",
      "ing Hunan and Hubei provinces pleaded with the central government to “reclassify” her and \n",
      "\n",
      "her people in Hunan as the Tujia, since their language differed from that of the Miao. \n",
      "\n",
      " \n",
      "\n",
      "However, whereas areas in Western Hunan were officially recognized in 1957 as Tujia territo-\n",
      "\n",
      "ries, based on the local communities’ self identification and fieldwork conducted by Chinese \n",
      "\n",
      "ethnologists in those areas, their neighbors in Enshi, Western Hubei, did not receive the same \n",
      "\n",
      "recognition. The ethnic classification was soon brought to a halt with the change of political \n",
      "\n",
      "climate in China prefiguring the Great Proletarian Cultural Revolution, when claiming any \n",
      "\n",
      "different identity risked being seen as counter-revoluntionary factionism. It was not until after \n",
      "\n",
      "the Cultural Revolution that the ethnic classification was resumed, to address some of the is-\n",
      "\n",
      "sues left over from two decades ago. Enshi’s case reopened. \n",
      "\n",
      "20 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      " \n",
      "\n",
      "Brown (2002) records that when the status re-classification and restoration of the Tujia started \n",
      "\n",
      "in Enshi in the early 1980s, many of the local people were unwilling to “become” Tujia since \n",
      "\n",
      "they “did not have Tujia consciousness” (ibid: 375) and preferred to consider themselves Han. \n",
      "\n",
      "She argues that the categories of ethnic boundary and distinction created by the local govern-\n",
      "\n",
      "ment — mainly by genealogical information and history of residence — did not reflect the \n",
      "\n",
      "actual cultural practice and socio-political experience of the individuals; it was a “manipula-\n",
      "\n",
      "tion”’ of population statistics based on an artificial dichotomy between Tujia and Han, a tactic \n",
      "\n",
      "of authentication by the local government that was “both economically beneficial and politi-\n",
      "\n",
      "cally safe” for the local populace as a whole (ibid: 389). The disjunction between the state \n",
      "\n",
      "recognition and the local sense of self observed here, illustrates the sensitivity and power dy-\n",
      "\n",
      "namics of authenticity in relation to ethnic identity in China — particularly so for Enshi — in \n",
      "\n",
      "which the influence of the state prevails.  \n",
      "\n",
      " \n",
      "\n",
      "In the light of this historical trajectory, we may understand that for Enshi, what heritaging \n",
      "\n",
      "initially invokes is perhaps an uncomfortable sense of inauthenticity rather than authenticity \n",
      "\n",
      "and, consequently, anxiety about how to become authentic. This question is hardly meaningful \n",
      "\n",
      "in terms of daily life at the local scale, since being a Tujia, a Miao, or else was an abstract \n",
      "\n",
      "political status largely detached from the local personal realities in which nearly all the fea-\n",
      "\n",
      "tures and evidence of “authenticity”, such as ethnic language, clothing, and customs, are ab-\n",
      "\n",
      "sent, including people’s own ethnic consciousness. The question, until recently, has only been \n",
      "\n",
      "relevant and important at the national scale: how to be seen as authentic in the eyes of the \n",
      "\n",
      "state, of the majorities, and of other minorities. The chronotopes of the local group identity \n",
      "\n",
      "were separated and confined in two disjointed scales of meaning making in terms of heritage. \n",
      "\n",
      "When called upon by the state as a minority, people shift into a “heritage” mode or chrono-\n",
      "\n",
      "tope of communication, deploying “authentic”, heritage-related semiotic resources. The mo-\n",
      "\n",
      "ment this duty is done, they shift out of it, picking up a different, “inauthentic” set of re-\n",
      "\n",
      "sources to continue with life at the local level. The contrast and disjunction and the essential-\n",
      "\n",
      "izing accusation of inauthenticity they often produce only accentuate the peripheral status of \n",
      "\n",
      "Enshi.  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "21 \n",
      "\n",
      "\f",
      "This predicament, however, is now brought in a different light, with globalization and heritage \n",
      "\n",
      "tourism opening up new economic, political, and cultural opportunities for Enshi. Tourism \n",
      "\n",
      "began to take shape in Enshi in the late 1980s, after its reintegration and recognition as a mi-\n",
      "\n",
      "nority region, but only came into full swing less than a decade ago. The old question of “how \n",
      "\n",
      "to play the minzu card” began to merge with the new economic demand, leading to the local \n",
      "\n",
      "strategizing of heritage tourism, with the Tujia (now the largest minority group of Enshi) be-\n",
      "\n",
      "ing positioned as its spearhead. The entrée of a new heritage discourse from the global scale \n",
      "\n",
      "begins to reshape the meaning of authenticity in Enshi. Its natural scenery of steep mountains \n",
      "\n",
      "and local culture have been politically reframed and economically repackaged, turning from \n",
      "\n",
      "an image of wilderness and underdevelopment into one of rare beauty, ecological privilege, \n",
      "\n",
      "nostalgic leisure and bucolic life. This indicates a symbolic shift in the order of authenticity \n",
      "\n",
      "that has historically stigmatized Enshi.  \n",
      "\n",
      " \n",
      "\n",
      "The global template of heritage tourism simultaneously authenticates and de-authenticates \n",
      "\n",
      "heritage. On the one hand, it seeks the “real” local in order to commodify it; on the other \n",
      "\n",
      "hand, it disrupts and “contaminates” the local way of life through translocal encounters and \n",
      "\n",
      "involvements – tourists are by definition not local, “not from here”. This creates scaled chro-\n",
      "\n",
      "notopic patterns that re-organize heritage into the (authentic) “timeless-here” in mixture and \n",
      "\n",
      "coordination with the (inauthentic) commodification and re-scrambling of timespace and re-\n",
      "\n",
      "sources, as we have seen in the example of Enshi. There, it seems, the new order of authen-\n",
      "\n",
      "ticity at the global scale-level offers scope and chronotopic opportunities to simultaneously \n",
      "\n",
      "articulate heritage authenticity at the national and the local scale-levels: people can fit their \n",
      "\n",
      "previously disjointed “on” and “off” modes of heritage within the one chronotope of heritage \n",
      "\n",
      "tourism. By moving up and mixing scales, they manage to obtain a degree of coherence and \n",
      "\n",
      "sustainability in their dilemma of inauthentic authenticity – heritage is now chronotopically \n",
      "\n",
      "niched.   \n",
      "\n",
      " \n",
      "\n",
      "More important to our understanding about Enshi is the emerging agency involved in this re-\n",
      "\n",
      "organization. The absorption into globalization processes through heritage tourism is subtly \n",
      "\n",
      "transforming the identity making processes for Enshi. The opportunities put forward to the \n",
      "\n",
      "local communities have enabled them to engage with their “given” heritage and the question \n",
      "\n",
      "of “how to become authentic” in a more autonomously active way. This is evidenced in \n",
      "\n",
      "22 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "Enshi’s full orientation toward tourism as a heritage strategy and the political and economic \n",
      "\n",
      "investments it makes accordingly. It is also evidenced in the local commitment to identity \n",
      "\n",
      "opportunities like the one we discussed, through the detailed, layered semiotic manoeuvres to \n",
      "\n",
      "better perform Tujia authenticity; and it is evidenced in the scaling of heritage practices ac-\n",
      "\n",
      "cumulated from such opportunities toward authenticity of optimal potential of recognizability. \n",
      "\n",
      "The efforts are about appropriating these opportunities, as much as about developing an order \n",
      "\n",
      "of authenticity that is locally enacted and translocally meaningful, both stimulate and rely on \n",
      "\n",
      "active semiotic design. It is in these facts that we begin to see an inception of ethnic con-\n",
      "\n",
      "sciousness in Enshi. In this sense, what we are also witnessing is a contemporary process of \n",
      "\n",
      "ethnogenesis, that is, the invention of the Tujia and of its heritage.     \n",
      "\n",
      " \n",
      "\n",
      "4. Conclusion  \n",
      "\n",
      " \n",
      "\n",
      "Meaning making in the global periphery is infused with complexity. To adequately address \n",
      "\n",
      "that complexity is one the main challenges we are faced with in sociolinguistic studies. \n",
      "\n",
      "Through the case of the Tujia in Enshi, China, it is clear that any critical understanding about \n",
      "\n",
      "the complexity cannot disengage with the structural conditions of peripherality and inequality \n",
      "\n",
      "in which accessibility, communicability, and validity of semiotic resources and their use are \n",
      "\n",
      "embedded. For ethnic minorities such as the Tujia, heritage is a compelling identity discourse \n",
      "\n",
      "with historically loaded and regimented meanings and values. It came with the minority status \n",
      "\n",
      "that was “given” by the state to people in Enshi, marking out their (invented) cultural alterity \n",
      "\n",
      "and geopolitical peripherality. Therefore, what their “own” heritage invokes is not only an \n",
      "\n",
      "unfamiliar (sometimes absent) set of semiotic norms and resources, but also the perpetual \n",
      "\n",
      "ambivalence of (in)authenticity.  \n",
      "\n",
      " \n",
      "\n",
      "This ambivalence re-emerges through heritage tourism as the Tujia engage in processes of \n",
      "\n",
      "globalization. Heritage tourism opens for Enshi an opportunity to commodify their peripheral-\n",
      "\n",
      "ity — which has now become a resource — while addressing the issue of authenticity. By \n",
      "\n",
      "incorporating the notion of chronotope, we are able to ethnographically contextualize and \n",
      "\n",
      "dissect the local identity acts demanded by heritage tourism, but performed simultaneously at \n",
      "\n",
      "multiple scale-levels. It transpires that these acts entail careful semiotization of timespace in \n",
      "\n",
      "23 \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "which authenticity is communicated in a spatially and temporally re-organized, re-rationalized \n",
      "\n",
      "order. In this new order of authenticity, the Tujia are able to design and deliver what may be \n",
      "\n",
      "considered authentic for different audiences while gaining economic and political purchase. \n",
      "\n",
      "They are heritaging in ways that, previously were mainly meaningful to others, but now are \n",
      "\n",
      "also meaningful for themselves. In this sense, they are becoming Tujia, and their heritaging is \n",
      "\n",
      "“producing authenticity” (Cavanaugh & Shankar, 2014).   \n",
      "\n",
      " \n",
      "\n",
      "Furthermore, heritage in a globalizing era is better understood as something chronotopically \n",
      "\n",
      "niched. The assumption of heritage as a singular chronotope of “timeless-here” (in crystal-\n",
      "\n",
      "lized forms of language, clothing, and other cultural traits) can no longer sufficiently explain \n",
      "\n",
      "what counts as authentic or inauthentic (see also Woolard, 2013). That binary view is under \n",
      "\n",
      "challenge in an increasingly polycentric environment in which heritaging now operates. The \n",
      "\n",
      "authenticity claims it can make are not simply against the essentialized norm imposed from \n",
      "\n",
      "one centre, but through a complex process that involves semiotic manoeuvring targeting rec-\n",
      "\n",
      "ognizability for multiple centers and scales. Through chronotopic manoeuvring, “fake” acts \n",
      "\n",
      "(which, paradoxically, are often produced for those who consider them as such), such as stage \n",
      "\n",
      "peforming, designing, and commodification, are able to find their own place and validity in \n",
      "\n",
      "heritaging, making themselves a coherent and sustainable part of a co-constructed lifeworld. \n",
      "\n",
      "In this way, heritage is renewed, revised, and re-inserted in contemporary life — as part of the \n",
      "\n",
      "ongoing “invention of tradition” in human society (Hobsbawn & Ranger, 1983).  \n",
      "\n",
      " \n",
      "\n",
      "This, to some extent, makes authenticity a politically more viable course for those in the pe-\n",
      "\n",
      "riphery. As shown in the case of the Tujia, through their agency, peripheral groups are able to \n",
      "\n",
      "— even if symbolically — reclaim authenticity over certain ground, thus, a degree of auton-\n",
      "\n",
      "omy over their own identity making. In minute semiotic details of performing heritage, we \n",
      "\n",
      "detect that the centre-periphery relation is being locally contested and reworked, from which \n",
      "\n",
      "cultural change is emerging. However, we must also avoid the over-generalization that those \n",
      "\n",
      "in the periphery are free from the structural inequality that circumscribes their authenticity. As \n",
      "\n",
      "our study suggests, the production of a new order of authenticity is still largely situated in a \n",
      "\n",
      "peripheral cultural and political economy, based on patterns and resources defined by the cen-\n",
      "\n",
      "ter. Its own authenticity, therefore, has not escaped “the cunning of recognition” (Povinelli, \n",
      "\n",
      "2002) within globalization.  \n",
      "\n",
      " \n",
      "\n",
      "24 \n",
      "\n",
      "\f",
      "References \n",
      "\n",
      " \n",
      "\n",
      "Agha, A. 2005. Voice, Footing, Enregisterment. Journal of Linguistic Anthropology, 15: 38-\n",
      "\n",
      "59. \n",
      "\n",
      " \n",
      "\n",
      "Agha, A. 2007. Recombinant Selves in Mass Mediated Spacetime. Language & Communica-\n",
      "\n",
      "tion, 27: 320-335.  \n",
      "\n",
      " \n",
      "\n",
      "Anderson, B. 1991. Imagined Communities: Reflections on the Origin and Spread of Nation-\n",
      "\n",
      "alism. London: Verso.  \n",
      "\n",
      " \n",
      "\n",
      "Appadurai, A. 1996. Modernity at Large: Cultural Dimensions of Globalization. Minneapolis \n",
      "\n",
      "and London: University of Minnesota Press.  \n",
      "\n",
      " \n",
      "\n",
      "Bakhtin, M.M. 1981. Forms of Time and of the Chronotope in the Novel. In M. Holquist \n",
      "\n",
      "(ed.), The Dialogic Imagination. Austin: University of Texas Press, 84-258.  \n",
      "\n",
      " \n",
      "\n",
      "Bauman, R. & Briggs, C. 2003. Voices of Modernity: Language Ideologies and the Politics of \n",
      "\n",
      "Inequality. Cambridge: Cambridge University Press.  \n",
      "\n",
      " \n",
      "\n",
      "Bayham, M. 2015. Narrative and Space/Time. In A. De Fina and A. Georgakopoulou (eds.), \n",
      "\n",
      "The Handbook of Narrative Analysis. Chichester: John Wiley & Sons, 119-139.  \n",
      "\n",
      " \n",
      "\n",
      "Bendix, R. F., Eggert, A. & Peselmann, A. (eds.). 2012. Heritage Regimes and the Stage. Göt-\n",
      "\n",
      "tingen Studies in Cultural Property, Volume 6. Göttingen: Universitätsverlag Göttingen.  \n",
      "\n",
      " \n",
      "\n",
      "Bennett, D. (ed.) 1998. Multicultural States: Rethinking Difference and Identity. London and \n",
      "\n",
      "New York: Routledge. \n",
      "\n",
      " \n",
      "\n",
      "Blommaert, J. 2003. Commentary: A Sociolinguistics of Globalization. Journal of Sociolin-\n",
      "\n",
      "guistics, 7(4): 607-623.  \n",
      "\n",
      " \n",
      "\n",
      "Blommaert, J. 2007. Sociolinguistic Scales. Intercultural Pragmatics, 4/1: 1-19.  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "25 \n",
      "\n",
      "\f",
      "Blommaert, J. 2008. Grassroots Literacy: Writing, Identity and Voice in Central Africa. Oxon: \n",
      "\n",
      "Routledge.  \n",
      "\n",
      " \n",
      "\n",
      "Blommaert, J. 2010. The Sociolinguistics of Globalization. Cambridge: Cambridge University \n",
      "\n",
      "Press.  \n",
      "\n",
      " \n",
      "\n",
      "Blommaert, J. 2013. Complexity, Accent, and Conviviality: Concluding Comments. Applied \n",
      "\n",
      "Linguistics, 34/5: 613-622.  \n",
      "\n",
      " \n",
      "\n",
      "Blommaert, J. 2015. Chronotopes, Scales, and Complexity in the Study of Language in Socie-\n",
      "\n",
      "ty. Annual Review of Anthropology, 44: 105-116.  \n",
      "\n",
      " \n",
      "\n",
      "Blommaert, J. & Varis, P. 2013. Enough is Enough: The Heuristics of Authenticity in Super-\n",
      "\n",
      "diversity. In J. Duarte & I. Gogolin (eds.), Linguistic Superdiversity in Urban Areas: Research \n",
      "\n",
      "Approaches. Amsterdam: John Benjamins, 143-159.  \n",
      "\n",
      " \n",
      "\n",
      "Blommaert, J. & De Fina, A. 2016. Chronotopic Identities: On the Timespace Organization of \n",
      "Who We Are. Tilburg Papers in Culture Studies, Paper 153. \n",
      "https://www.tilburguniversity.edu/upload/ba249987-6ece-44d2-b96b-\n",
      "3fc329713d59_TPCS_153_Blommaert-DeFina.pdf \n",
      "\n",
      " \n",
      "\n",
      "Blum, S. D. 2001. Portraits of Primitives: Ordering Human Kinds in the Chinese Nation. \n",
      "\n",
      "Lanham: Rowman & Littlefield.  \n",
      "\n",
      " \n",
      "\n",
      "Bourdieu, P. 1984. Distinction: A Social Critique of the Judgement of Taste. London: \n",
      "\n",
      "Routledge.  \n",
      "\n",
      " \n",
      "\n",
      "Bourdieu, P. 1991. Language and Symbolic Power. Cambridge, MA: Harvard University \n",
      "\n",
      "Press. \n",
      "\n",
      " \n",
      "\n",
      "Brown, M. 2002. Local Government Agency: Manipulating Tujia Identity. Modern China, \n",
      "\n",
      "28/3: 362-395.  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "26 \n",
      "\n",
      "\f",
      "Bucholtz, M. 2003. Sociolinguistic Nostalgia and the Authentication of Identity. Journal of \n",
      "\n",
      "Sociolinguistics, 7/3: 398-416.  \n",
      "\n",
      " \n",
      "\n",
      "Canagarajah, S. 2005. Reclaiming the Local in Language Policy and Practice. Oxon & New \n",
      "\n",
      "York: Routledge.  \n",
      "\n",
      " \n",
      "\n",
      "Cavanaugh, J. R. & Shankar, S. 2014. Producing Authenticity in Global Capitalism: Lan-\n",
      "\n",
      "guage, Materiality, and Value. American Anthropologist, 116/1: 51-64.  \n",
      "\n",
      " \n",
      "\n",
      "Collins, J., Slembrouck, J. & Baynham, M. (eds.). 2009. Globalization and Languages in \n",
      "\n",
      "Contact: Scale, Migration, and Communicative Practices. London: Continuum.  \n",
      "\n",
      " \n",
      "\n",
      "Coupland, N. 2003. Sociolinguistic Authenticities. Journal of Sociolinguistics, 7/3: 417-431. \n",
      "\n",
      " \n",
      "\n",
      "Coupland, N. (ed.). 2010a. Handbook of Language and Globalization. Chichester: Wiley-\n",
      "\n",
      "Blackwell.  \n",
      "\n",
      " \n",
      "\n",
      "Coupland, N. 2010b. The Authentic Speaker and the Speech Community. In C. Llamas & D. \n",
      "\n",
      "Watts (eds.), Language and Identities. Edinburgh: Edinburgh University Press, 99-112.  \n",
      "\n",
      " \n",
      "\n",
      "Coupland, N. 2014. Language, Society and Authenticity: Themes and Perspectives. In V. La-\n",
      "\n",
      "coste, J. Leimgruber & T. Breyer (eds.), Indexing Authenticity: Sociolinguistic Perspectives. \n",
      "\n",
      "Berlin: Walter de Gruyter, 14-42.  \n",
      "\n",
      " \n",
      "\n",
      "Erikson, R. J. 1995. The Importance of Authenticity in Self and Society. Symbolic Interaction, \n",
      "\n",
      "18/2: 121-144.  \n",
      "\n",
      " \n",
      "\n",
      "Gao, S. 2014. Aspirations to Be Global: Language, Mobilities, and Social Change in A Tour-\n",
      "\n",
      "ism Village in China. PhD Thesis, King’s College London.  \n",
      "\n",
      " \n",
      "\n",
      "Gladney, D. 1994. Representing Nationality in China: Refiguring Majority/Minority Identi-\n",
      "\n",
      "ties. Journal of Asian Studies, 53/1: 92-123.  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "27 \n",
      "\n",
      "\f",
      "Gladney, D. 2004. Dislocating China: Muslims, Minorities and Other Subaltern Subjects. \n",
      "\n",
      "Chicago: University of Chicago Press.  \n",
      "\n",
      " \n",
      "\n",
      "Giddens, A. 1991. Modernity and Self-Identity: Self and Society in the Late Modern Age. \n",
      "\n",
      "Cambridge: Polity.  \n",
      "\n",
      " \n",
      "\n",
      "Goffman, E. 1974. Frame Analysis: An Essay on the Organization of Experience. New York: \n",
      "\n",
      "Harper & Row.  \n",
      "\n",
      " \n",
      "\n",
      "Gumperz, J. 2003. Response Essay. In S. Eerdmans, C. Previgniano & P. Thilbault (eds.), \n",
      "\n",
      "Language and Interaction: Discussion with John J. Gumperz. Amsterdam: John Benjamins, \n",
      "\n",
      "105-126.  \n",
      "\n",
      " \n",
      "\n",
      "Hymes, D. 1996. Ethnography, Linguistics, Narrative Inequality: Toward an Understanding \n",
      "\n",
      "of Voice. London: Taylor and Francis.  \n",
      "\n",
      " \n",
      "\n",
      "Jaworski, A. & Pritchard, A. (eds.) 2005. Discourse, Communication and Tourism. Bristol: \n",
      "\n",
      "Channel View Publications.  \n",
      "\n",
      " \n",
      "\n",
      "Juffermans, K. 2015. Local Languaging: Literacy and Multilingualism in a West African So-\n",
      "\n",
      "ciety. Bristol: Multilingual Matters. \n",
      "\n",
      " \n",
      "\n",
      "Harvey, D. 1989. The Conditions of Postmodernity: An Enquiry into the Origins of Cutural \n",
      "\n",
      "Change. Oxford: Wiley-Blackwell.  \n",
      "\n",
      " \n",
      "\n",
      "Hobsbawn, E. & Ranger, T. (eds.). 1983. The Invention of Tradition. Cambridge: Cambridge \n",
      "\n",
      "University Press.  \n",
      "\n",
      " \n",
      "\n",
      "Heller, M. 2003. Globalization, the New Economy, and the Commodification of Language \n",
      "\n",
      "and Identity. Journal of Sociolinguistics, 7: 473-498.  \n",
      "\n",
      " \n",
      "\n",
      "Heller, M. 2010. Language as Resource in the Globalized New Economy. In N. Coupland \n",
      "\n",
      "(ed.), The Handbook of Language and Globalisation. Chichester: Wiley-Blackwell, 349-365.   \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "28 \n",
      "\n",
      "\f",
      "Heller, M. 2014a. Repositioning the Multilingual Periphery: Class, Language, and Transna-\n",
      "\n",
      "tional Markets in Francophone Canada. In S. Pietikäinen & H. Kelly-Holmes (eds.), Multilin-\n",
      "\n",
      "gual and the Periphery. Oxford: Oxford University Press, 17-34.  \n",
      "\n",
      " \n",
      "\n",
      "Heller, M. 2014b. The Commodification of Authenticity. In V. Lacoste, J. Leimgruber & T. \n",
      "\n",
      "Breyer (eds.), Indexing Authenticity: Sociolinguistic Perspectives. Berlin: Walter de Gruyter, \n",
      "\n",
      "112-136.  \n",
      "\n",
      " \n",
      "\n",
      "Higgins, C. 2009. English as a Local Language. Bristol: Multilingual Matters.  \n",
      "\n",
      " \n",
      "\n",
      "Lacoste, V., Leimgruber, J. & Breyer, T. 2014a. Authenticity: A View from Inside and Outside \n",
      "\n",
      "Sociolinguistics. In V. Lacoste, J. Leimgruber & T. Breyer (eds.), Indexing Authenticity: Soci-\n",
      "\n",
      "olinguistic Perspectives. Berlin: Walter de Gruyter, 1-13.  \n",
      "\n",
      " \n",
      "\n",
      "Lacoste, V., Leimgruber, J. & Breyer, T. (eds.). 2014b. Indexing Authenticity: Sociolinguistic \n",
      "\n",
      "Perspectives. Berlin: Walter de Gruyter.  \n",
      "\n",
      " \n",
      "\n",
      "Lampert, M. & Perrino, S. (eds.). 2007. Entextualisation and Temporality. Special Issue, Lan-\n",
      "\n",
      "guage & Communication, 27: 205-335.  \n",
      "\n",
      " \n",
      "\n",
      "Ma, R. 2016. “Culturalism” and “Nationalism” in Modern China. In M. Guibernau & J. Rex, \n",
      "\n",
      "(eds.), The Ethnic Reader: Nationalism, Multiculturalism and Migration. Cambridge: Polity: \n",
      "\n",
      "299-307.   \n",
      "\n",
      " \n",
      "\n",
      "Makoni, S. & Pennycook, A. (eds.). 2007. Disinventing and Reconstructing Languages. \n",
      "\n",
      "Clevedon: Multilingual Matters.  \n",
      "\n",
      " \n",
      "\n",
      "McCarthy, S. K. 2009. Communist Multiculturalism: Ethnic Revival in Southwest China. Se-\n",
      "\n",
      "attle: University of Washington Press.  \n",
      "\n",
      " \n",
      "\n",
      "Mullaney, T. S. 2012. Coming to Terms with the Nation: Ethnic Classification in Modern Chi-\n",
      "\n",
      "na. Berkeley: University of California Press.  \n",
      "\n",
      " \n",
      "\n",
      "Pardue, D. 2011. Brazilian Hip Hoppers Speak from the Margins: We’s on tape. New York: \n",
      "\n",
      "Palgrave Macmillan.  \n",
      "\n",
      " \n",
      "\n",
      "29 \n",
      "\n",
      "\f",
      " \n",
      "\n",
      "Pennycook, A. 2007. Language, Localization, and the Real: Hip-Hop and the Global Spread \n",
      "\n",
      "of Authenticity. Journal of Language, Identity and Education, 6/2: 101-115.  \n",
      "\n",
      " \n",
      "\n",
      "Pennycook, A. 2010. Language as a Local Practice. New York: Routledge.  \n",
      "\n",
      " \n",
      "\n",
      "Pennycook, A. 2012. Language and Mobility: Unexpected Places. Bristol: Multilingual Mat-\n",
      "\n",
      "ters.  \n",
      "\n",
      " \n",
      "\n",
      "Pietikäinen, S. & Kelly-Holmes, H. (eds.). 2013. Multilingualism and the Periphery. Oxford: \n",
      "\n",
      "Oxford University Press.  \n",
      "\n",
      " \n",
      "\n",
      "Pietikäinen, S., Kelly-Holmes, H., Jaffe, A. & Coupland, N. 2016. Sociolinguistics from the \n",
      "\n",
      "Periphery: Small Languages in New Circumstances. Cambridge: Cambridge University Press.  \n",
      "\n",
      " \n",
      "\n",
      "Pinksy, D. 2015. The Sustained Snapshot: Incidental Ethnographic Encounters in Qualitative \n",
      "\n",
      "Interview Studies. Qualitative Research, 15/3: 281-295.  \n",
      "\n",
      " \n",
      "\n",
      "Povinelli, E. A. 2002. The Cunning of Recognition: Indigenous Alterities and the Making of \n",
      "\n",
      "Australian Multiculturalism. Durham and London: Duke University Press.  \n",
      "\n",
      " \n",
      "\n",
      "Rex, J. 1996. Ethnic Minorities in the Modern Nation State: Working Papers in the Theory of \n",
      "\n",
      "Multicultural and Political Integration. Basingstoke: Macmillan.  \n",
      "\n",
      " \n",
      "\n",
      "Roosens, E. 1989. Creating Ethnicity: The Process of Ethnogenesis. London: Sage.  \n",
      "\n",
      " \n",
      "\n",
      "Silverstein, M. 1985. Language and the Culture of Gender. In E. Mertz & R. Parmentier (eds.) \n",
      "\n",
      "Semiotic Mediation. New York: Academic, 219-259. \n",
      "\n",
      " \n",
      "\n",
      "Street, B. 1993. Culture is a Verb: Anthropological Aspects of Language and Cultural Process. \n",
      "\n",
      "In D. Graddol, L. Thompson & M. Byram (eds.), Language and Culture. Clevedon: British \n",
      "\n",
      "Association of Applied Linguistics.  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "30 \n",
      "\n",
      "\f",
      "Su, X. & Teo, P. 2009. The Politics of Heritage Tourism in China: A View from Lijiang. Lon-\n",
      "\n",
      "don: Routledge.  \n",
      "\n",
      " \n",
      "\n",
      "Sultana, S., Dovchin, S. & Pennycook, A. 2013. Styling the Periphery: Linguistic and Cultural \n",
      "\n",
      "Takeup in Bangladesh and Mongolia. Journal of Sociolinguistics, 17/5: 687-710.  \n",
      "\n",
      " \n",
      "\n",
      "Taylor, C. The Ethics of Authenticity. Cambridge, MA: Harvard University Pres.  \n",
      "\n",
      " \n",
      "\n",
      "Thornborrow, J. & Van Leeuwen, T. (eds.) 2001. Authenticity in Media Discourse. Special \n",
      "\n",
      "issue, Discourse Studies, 3/4: 391-497.  \n",
      "\n",
      " \n",
      "\n",
      "Thurlow, C. & Jaworski, A. 2010. Tourism Discourse: Language and Global Mobility. Ba-\n",
      "\n",
      "singstoke: Palgrave Macmillan. \n",
      "\n",
      " \n",
      "\n",
      "Upton, D. 2001. “Authentic” Anxieties. In N. Alsayyad (ed.), Consuming Tradition, Manufac-\n",
      "\n",
      "turing Heritage: Global Norms and Urban Forms in the Age of Tourism. London & New \n",
      "\n",
      "York: Routledge, 298-306.  \n",
      "\n",
      " \n",
      "\n",
      "Van der Aa, J. & Blommaert, J. 2015. Ethnographic Monitoring and the Study of Complexity. \n",
      "\n",
      "Tilburg Papers in Culture Studies, Paper 123. \n",
      "\n",
      "https://www.tilburguniversity.edu/upload/24266e94-2d00-41fc-b488-\n",
      "\n",
      "60e3845fc383_TPCS_123_VdrAa-Blommaert.pdf \n",
      "\n",
      " \n",
      "\n",
      "Wang, X. 2012. “I am not a qualified dialect rapper”: Constructing Hip-Hop Authenticity in \n",
      "\n",
      "China. Sociolinguistic Studies, 6/2: 153-191.  \n",
      "\n",
      " \n",
      "\n",
      "Wang, X. 2015. Inauthentic Authenticity: Semiotic Design and Globalization in the Margins \n",
      "\n",
      "of China. Semiotica, 203: 227-248.  \n",
      "\n",
      " \n",
      "\n",
      "Wang, X., Spotti, M., Juffermans, M., Cornips, L., Kroon, S., & Blommaert, J. 2014. Globali-\n",
      "\n",
      "zation in the Margins: Toward a Re-Evaluation of Language and Mobility. Applied Linguistics \n",
      "\n",
      "Review: 5/1: 23-44.  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "31 \n",
      "\n",
      "\f",
      "Waterton, E. & Watson, S. 2014. The Semiotics of Heritage Tourism. Bristol: Channel View \n",
      "Publications.  \n",
      "\n",
      " \n",
      "\n",
      "Wilce, J. & Fenigsen, J. (eds.). 2014. De-Essentialising Authenticity: A Semiotic Approach. \n",
      "\n",
      "Special Issue, Semiotica, 203: 137-248.  \n",
      "\n",
      " \n",
      "\n",
      "Woolard, K. 2013. Is the personal political? Chronotopes and Changing Stances toward Cata-\n",
      "\n",
      "lan Language and Identity. International Journal of Bilingual Education and Bilingualism, \n",
      "\n",
      "16/2: 210-224.  \n",
      "\n",
      " \n",
      "\n",
      "32 \n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #import the required module\n",
    "\n",
    "pdf_link = 'https://www.tilburguniversity.edu/sites/default/files/download/TPCS_169_Wang-Kroon_2.pdf'\n",
    "info = requests.get(pdf_link, stream=True)\n",
    "# based on the function provided above\n",
    "def readPDF(pdfFile):\n",
    "    #Based on code from http://stackoverflow.com/a/20905381/4955164\n",
    "    #Using utf-8, if there are a bunch of random symbols try changing this\n",
    "    codec = 'utf-8'\n",
    "    rsrcmgr = pdfminer.pdfinterp.PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    layoutParams = pdfminer.layout.LAParams()\n",
    "    device = pdfminer.converter.TextConverter(rsrcmgr, retstr, laparams = layoutParams, codec = codec)\n",
    "    #We need a device and an interpreter\n",
    "    interpreter = pdfminer.pdfinterp.PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = ''\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "    for page in pdfminer.pdfpage.PDFPage.get_pages(pdfFile, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    device.close()\n",
    "    returnedString = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    return returnedString\n",
    "\n",
    "infoBytes = io.BytesIO(info.content)\n",
    "print(readPDF(infoBytes)) #est. 40s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After converting PDF file to txt format and read data, I use the “.findall()” function of regular expressions to extract keywords. I then save list of extracted keywords in a DataFrame. I apply the concept of TF-IDF for calculating weights of each keyword. Finally, I save results in a DataFrame and use “.sort_values()” to arrange keywords in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>number_of_times_word_appeared</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>in</td>\n",
       "      <td>1272</td>\n",
       "      <td>0.017024</td>\n",
       "      <td>-7.148346</td>\n",
       "      <td>-0.121697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>the</td>\n",
       "      <td>1017</td>\n",
       "      <td>0.013612</td>\n",
       "      <td>-6.924612</td>\n",
       "      <td>-0.094255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>an</td>\n",
       "      <td>976</td>\n",
       "      <td>0.013063</td>\n",
       "      <td>-6.883463</td>\n",
       "      <td>-0.089917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>it</td>\n",
       "      <td>823</td>\n",
       "      <td>0.011015</td>\n",
       "      <td>-6.712956</td>\n",
       "      <td>-0.073944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>on</td>\n",
       "      <td>818</td>\n",
       "      <td>0.010948</td>\n",
       "      <td>-6.706862</td>\n",
       "      <td>-0.073428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>en</td>\n",
       "      <td>788</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>-6.669498</td>\n",
       "      <td>-0.070341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>al</td>\n",
       "      <td>761</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>-6.634633</td>\n",
       "      <td>-0.067575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>ic</td>\n",
       "      <td>691</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>-6.538140</td>\n",
       "      <td>-0.060467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>nd</td>\n",
       "      <td>660</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>-6.492240</td>\n",
       "      <td>-0.057349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>re</td>\n",
       "      <td>614</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>-6.419995</td>\n",
       "      <td>-0.052758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>es</td>\n",
       "      <td>614</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>-6.419995</td>\n",
       "      <td>-0.052758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>at</td>\n",
       "      <td>602</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>-6.400257</td>\n",
       "      <td>-0.051568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>of</td>\n",
       "      <td>578</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>-6.359574</td>\n",
       "      <td>-0.049197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>and</td>\n",
       "      <td>517</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>-6.248043</td>\n",
       "      <td>-0.043234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>is</td>\n",
       "      <td>505</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>-6.224558</td>\n",
       "      <td>-0.042071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>or</td>\n",
       "      <td>492</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>-6.198479</td>\n",
       "      <td>-0.040817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>ed</td>\n",
       "      <td>469</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>-6.150603</td>\n",
       "      <td>-0.038608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>to</td>\n",
       "      <td>464</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>-6.139885</td>\n",
       "      <td>-0.038130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>ent</td>\n",
       "      <td>431</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>-6.066108</td>\n",
       "      <td>-0.034992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>ing</td>\n",
       "      <td>427</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>-6.056784</td>\n",
       "      <td>-0.034614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>se</td>\n",
       "      <td>396</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>-5.981414</td>\n",
       "      <td>-0.031702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>co</td>\n",
       "      <td>388</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>-5.961005</td>\n",
       "      <td>-0.030955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tion</td>\n",
       "      <td>347</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>-5.849325</td>\n",
       "      <td>-0.027166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>ty</td>\n",
       "      <td>342</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>-5.834811</td>\n",
       "      <td>-0.026708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>de</td>\n",
       "      <td>338</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>-5.823046</td>\n",
       "      <td>-0.026342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keywords  number_of_times_word_appeared        tf       idf    tf_idf\n",
       "318        in                           1272  0.017024 -7.148346 -0.121697\n",
       "811       the                           1017  0.013612 -6.924612 -0.094255\n",
       "353        an                            976  0.013063 -6.883463 -0.089917\n",
       "278        it                            823  0.011015 -6.712956 -0.073944\n",
       "58         on                            818  0.010948 -6.706862 -0.073428\n",
       "1455       en                            788  0.010547 -6.669498 -0.070341\n",
       "1932       al                            761  0.010185 -6.634633 -0.067575\n",
       "1228       ic                            691  0.009248 -6.538140 -0.060467\n",
       "971        nd                            660  0.008833 -6.492240 -0.057349\n",
       "621        re                            614  0.008218 -6.419995 -0.052758\n",
       "1499       es                            614  0.008218 -6.419995 -0.052758\n",
       "1988       at                            602  0.008057 -6.400257 -0.051568\n",
       "1555       of                            578  0.007736 -6.359574 -0.049197\n",
       "2197      and                            517  0.006920 -6.248043 -0.043234\n",
       "1703       is                            505  0.006759 -6.224558 -0.042071\n",
       "234        or                            492  0.006585 -6.198479 -0.040817\n",
       "821        ed                            469  0.006277 -6.150603 -0.038608\n",
       "1840       to                            464  0.006210 -6.139885 -0.038130\n",
       "1002      ent                            431  0.005769 -6.066108 -0.034992\n",
       "1500      ing                            427  0.005715 -6.056784 -0.034614\n",
       "1058       se                            396  0.005300 -5.981414 -0.031702\n",
       "1942       co                            388  0.005193 -5.961005 -0.030955\n",
       "252      tion                            347  0.004644 -5.849325 -0.027166\n",
       "230        ty                            342  0.004577 -5.834811 -0.026708\n",
       "40         de                            338  0.004524 -5.823046 -0.026342"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on https://towardsdatascience.com/how-to-extract-keywords-from-pdfs-and-arrange-in-order-of-their-weights-using-python-841556083341\n",
    "text = readPDF(infoBytes).lower() #Lowercasing each word\n",
    "keywords = re.findall(r'[a-zA-Z]\\w+',text)\n",
    "df = pd.DataFrame(list(set(keywords)),columns=['keywords'])\n",
    "\n",
    "def weightage(word,text,number_of_documents=1):\n",
    "    word_list = re.findall(word,text)\n",
    "    number_of_times_word_appeared =len(word_list)\n",
    "    tf = number_of_times_word_appeared/float(len(text))\n",
    "    idf = np.log((number_of_documents)/float(number_of_times_word_appeared))\n",
    "    tf_idf = tf*idf\n",
    "    return number_of_times_word_appeared,tf,idf ,tf_idf  \n",
    "\n",
    "df['number_of_times_word_appeared'] = df['keywords'].apply(lambda x: weightage(x,text)[0])\n",
    "df['tf'] = df['keywords'].apply(lambda x: weightage(x,text)[1])\n",
    "df['idf'] = df['keywords'].apply(lambda x: weightage(x,text)[2])\n",
    "df['tf_idf'] = df['keywords'].apply(lambda x: weightage(x,text)[3])\n",
    "df = df.sort_values('tf_idf',ascending=True)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Exercise 4</font>\n",
    "\n",
    "<font color=\"red\">In the two cells immediately following, describe a possible project (e.g., it might end up being your final project, but need not be if you are still searching): **WHAT** you will analyze--the texts you will select and the social game, world and actors you intend to learn about through your analysis (<100 words); **WHY** you will analyze these texts to learn about that context--justify the rationale behind your proposed sample design for this project, based on the readings. What is the social game, social work, or social actors about whom you are seeking to make inferences? What are the virtues of your proposed sample with respect to your research questions? What are its limitations? What are alternatives? What would be a reasonable path to \"scale up\" your sample for further analysis (i.e., high-profile publication)? (<150 words)? [**Note**: your individual or collective project will change over the course of the quarter as new data and/or analysis opportunities arise or if old ones fade away.] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***What?*** \n",
    "<100 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do text analysis on a set of Chinese online forums (Baidu Tieba), where different ethnic minority groups in China discuss a range of issues in their corresponding forums. Baidu Tieba uses forums called bars as a place for users to socially interact. Specifically, I will analyze five to six Baidu Tieba to better understand ethnic minorities' attitutes and views on the society, policies, and political institutions. Baidu Tieba has accumulated over 300 million monthly active users by 2015. This is a ideal platforms for us to study ethnic minorities in China. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Why?***\n",
    "<150 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My research aims to investigate ethnic minority groups’ views on political issues as well as their interests and perceived social status. A methodology problem often arises when researchers directly ask people to describe their feelings and thoughts. While surveys contain more representative and detailed information over a ﬁxed time interval, public opinion analyses with social media data add a more abundant, timely, and accurate picture of public sentiments and discourse.\n",
    "\n",
    "By taking a closer look at the discussion of ethnic minority users on the online forums, I want to make inferences about the whole ethnic minority group in China. Analyzing the social media data helps us avoid any “preference falsiﬁcation,” but this approach also presents some limitations. We should note that the sample may not be as representative as survey data, because most online users are people who are relatively young and love to use digital devices. Large-scale computing can help us analyse a large amount of data, and therefore may make the inference more reliable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources:\n",
    "\n",
    "Other popular sources for internet data:\n",
    "\n",
    "[reddit](https://www.reddit.com/) - https://praw.readthedocs.io/en/v2.1.21/\n",
    "\n",
    "[twitter](https://twitter.com/) - https://pypi.org/project/python-twitter/\n",
    "\n",
    "[project gutenburg](https://www.gutenberg.org/) - https://github.com/ageitgey/Gutenberg \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
